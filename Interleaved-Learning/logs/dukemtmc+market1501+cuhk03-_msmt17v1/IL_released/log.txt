==========
Args:Namespace(BNNeck=True, BNtype='sample', Preprocessor='normal', arch='resnet50', back_num=1, baseline='real', batch_size=64, data_dir='/home/zhifeng/jiayu/data/reidData/', dataset='msmt17v1', dataset_src1='dukemtmc', dataset_src2='market1501', dataset_src3='cuhk03', dropout=0, epochs=70, eval_step=1, evaluate=False, features=0, head='Memory', height=256, iters=200, logs_dir='logs/', lr=0.00035, margin=0.3, metaType='', momentum=0.2, num_camera=33, num_instances=4, p=1.0, print_freq=5, resume='', sampler='tri', seed=1, step_size=20, style_input='shuffle', style_layer='1', style_method='UBS', style_type='dir_bat', temp=0.05, test_batch_size=128, trainStyle=False, training_set='mix_dataset', updateStyle=True, useGeM=False, version='IL_released', weight_decay=0.0005, width=128, with_ibn=False, workers=4)
==========
==> Load datasets
This dataset has been downloaded.
=> DukeMTMC-reID loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   702 |    16522 |         8
  query    |   702 |     2228 |         8
  gallery  |  1110 |    17660 |         8
  mix      |  1812 |    36410 |         8
  ----------------------------------------
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   751 |    12936 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  mix      |  1501 |    29419 |         6
  ----------------------------------------
Note: if root path is changed, the previously generated json files need to be re-generated (delete them first)
Split index = 0
=> CUHK03 (detected) loaded
Dataset statistics:
  ------------------------------
  subset   | # ids | # images
  ------------------------------
  train    |   767 |     7365
  query    |   700 |     1400
  gallery  |   700 |     5332
  mix      |  1467 |    14097
  ------------------------------
  total    |  1467 |     8765
  ------------------------------
Using downloaded file: /home/zhifeng/jiayu/data/reidData/msmt17/MSMT17_V1
MSMT17_V1 v1~~~ dataset loaded
  ---------------------------
  subset   | # ids | # images
  ---------------------------
  train    |  1041 |    32621
  query    |  3060 |    11659
  gallery  |  3060 |    82161
  mix      |  4101 |   126441
  ---------------------------
 number classes =  [1812, 1501, 1467]
 each source camera number= [8, 6, 2]
It is real baseline setting!
Using train set and test set for training!
Using triple sampler!
Using triple sampler!
Using triple sampler!
Insert style layer in  ['layer1']
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (feat_bn0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (style): UBS(p=1.0,rho=3.0)
  )
)
Model size: 23.51213M
==> Initialize source-domain class centroids and memories 
Extract Features: [50/285]	Time 0.091 (0.298)	Data 0.000 (0.017)	
Extract Features: [100/285]	Time 0.096 (0.200)	Data 0.000 (0.011)	
Extract Features: [150/285]	Time 0.101 (0.169)	Data 0.000 (0.009)	
Extract Features: [200/285]	Time 0.197 (0.154)	Data 0.000 (0.008)	
Extract Features: [250/285]	Time 0.091 (0.144)	Data 0.000 (0.007)	
Extract Features: [50/230]	Time 0.090 (0.111)	Data 0.000 (0.013)	
Extract Features: [100/230]	Time 0.091 (0.104)	Data 0.000 (0.007)	
Extract Features: [150/230]	Time 0.092 (0.103)	Data 0.000 (0.005)	
Extract Features: [200/230]	Time 0.091 (0.101)	Data 0.000 (0.003)	
Extract Features: [50/111]	Time 0.091 (0.131)	Data 0.000 (0.032)	
Extract Features: [100/111]	Time 0.212 (0.119)	Data 0.000 (0.019)	
==> start training epoch 0 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [0][5/200]	Time 0.736 (2.478)	Total loss 7.101 (6.975)
Epoch: [0][10/200]	Time 0.755 (1.618)	Total loss 7.079 (7.028)
Epoch: [0][15/200]	Time 0.748 (1.326)	Total loss 7.174 (7.043)
Epoch: [0][20/200]	Time 0.743 (1.183)	Total loss 6.938 (7.032)
Epoch: [0][25/200]	Time 0.769 (1.103)	Total loss 7.032 (7.032)
Epoch: [0][30/200]	Time 0.787 (1.047)	Total loss 7.191 (7.043)
Epoch: [0][35/200]	Time 0.740 (1.008)	Total loss 6.962 (7.045)
Epoch: [0][40/200]	Time 0.828 (0.979)	Total loss 7.184 (7.056)
Epoch: [0][45/200]	Time 0.809 (0.954)	Total loss 7.208 (7.067)
Epoch: [0][50/200]	Time 0.759 (0.938)	Total loss 7.306 (7.083)
Epoch: [0][55/200]	Time 0.771 (0.922)	Total loss 7.157 (7.091)
Epoch: [0][60/200]	Time 0.757 (0.911)	Total loss 7.095 (7.097)
Epoch: [0][65/200]	Time 0.757 (0.900)	Total loss 7.233 (7.107)
Epoch: [0][70/200]	Time 0.756 (0.892)	Total loss 7.269 (7.117)
Epoch: [0][75/200]	Time 0.792 (0.885)	Total loss 7.163 (7.124)
Epoch: [0][80/200]	Time 0.785 (0.878)	Total loss 7.286 (7.133)
Epoch: [0][85/200]	Time 0.727 (0.872)	Total loss 7.261 (7.141)
Epoch: [0][90/200]	Time 0.731 (0.864)	Total loss 7.397 (7.150)
Epoch: [0][95/200]	Time 0.828 (0.880)	Total loss 6.468 (7.133)
Epoch: [0][100/200]	Time 0.867 (0.877)	Total loss 6.691 (7.100)
Epoch: [0][105/200]	Time 0.763 (0.871)	Total loss 6.653 (7.076)
Epoch: [0][110/200]	Time 0.741 (0.867)	Total loss 6.404 (7.046)
Epoch: [0][115/200]	Time 0.772 (0.870)	Total loss 5.848 (7.010)
Epoch: [0][120/200]	Time 0.784 (0.868)	Total loss 5.995 (6.963)
Epoch: [0][125/200]	Time 0.891 (0.865)	Total loss 6.143 (6.928)
Epoch: [0][130/200]	Time 0.744 (0.861)	Total loss 5.992 (6.887)
Epoch: [0][135/200]	Time 0.768 (0.859)	Total loss 6.027 (6.857)
Epoch: [0][140/200]	Time 0.770 (0.855)	Total loss 5.743 (6.827)
Epoch: [0][145/200]	Time 0.813 (0.854)	Total loss 6.043 (6.801)
Epoch: [0][150/200]	Time 0.913 (0.857)	Total loss 6.061 (6.773)
Epoch: [0][155/200]	Time 0.801 (0.854)	Total loss 5.910 (6.747)
Epoch: [0][160/200]	Time 0.727 (0.852)	Total loss 5.868 (6.726)
Epoch: [0][165/200]	Time 0.747 (0.850)	Total loss 5.718 (6.705)
Epoch: [0][170/200]	Time 0.795 (0.848)	Total loss 6.300 (6.684)
Epoch: [0][175/200]	Time 0.904 (0.846)	Total loss 6.057 (6.668)
Epoch: [0][180/200]	Time 0.729 (0.845)	Total loss 5.952 (6.653)
Epoch: [0][185/200]	Time 0.878 (0.848)	Total loss 6.172 (6.635)
Epoch: [0][190/200]	Time 0.778 (0.850)	Total loss 5.286 (6.607)
Epoch: [0][195/200]	Time 0.786 (0.848)	Total loss 5.658 (6.578)
Epoch: [0][200/200]	Time 0.754 (0.847)	Total loss 5.245 (6.550)
==> start training epoch 1 	 ==> learning rate = 6.65e-05
Epoch: [1][5/200]	Time 0.768 (0.815)	Total loss 5.357 (5.446)
Epoch: [1][10/200]	Time 0.848 (0.801)	Total loss 5.219 (5.463)
Epoch: [1][15/200]	Time 0.733 (0.793)	Total loss 5.818 (5.525)
Epoch: [1][20/200]	Time 0.754 (0.791)	Total loss 5.516 (5.541)
Epoch: [1][25/200]	Time 0.765 (0.789)	Total loss 5.712 (5.546)
Epoch: [1][30/200]	Time 0.767 (0.824)	Total loss 5.143 (5.510)
Epoch: [1][35/200]	Time 0.761 (0.818)	Total loss 5.282 (5.476)
Epoch: [1][40/200]	Time 0.809 (0.816)	Total loss 5.291 (5.437)
Epoch: [1][45/200]	Time 0.753 (0.812)	Total loss 5.289 (5.407)
Epoch: [1][50/200]	Time 0.771 (0.806)	Total loss 5.142 (5.385)
Epoch: [1][55/200]	Time 0.753 (0.804)	Total loss 5.437 (5.371)
Epoch: [1][60/200]	Time 0.799 (0.802)	Total loss 5.177 (5.355)
Epoch: [1][65/200]	Time 0.763 (0.801)	Total loss 5.119 (5.326)
Epoch: [1][70/200]	Time 0.868 (0.800)	Total loss 5.254 (5.313)
Epoch: [1][75/200]	Time 0.783 (0.810)	Total loss 4.792 (5.304)
Epoch: [1][80/200]	Time 1.619 (0.819)	Total loss 5.151 (5.291)
Epoch: [1][85/200]	Time 0.779 (0.817)	Total loss 4.939 (5.271)
Epoch: [1][90/200]	Time 0.762 (0.816)	Total loss 5.129 (5.247)
Epoch: [1][95/200]	Time 0.779 (0.814)	Total loss 4.715 (5.219)
Epoch: [1][100/200]	Time 0.809 (0.813)	Total loss 5.214 (5.200)
Epoch: [1][105/200]	Time 0.745 (0.812)	Total loss 4.937 (5.182)
Epoch: [1][110/200]	Time 0.738 (0.810)	Total loss 4.865 (5.168)
Epoch: [1][115/200]	Time 0.778 (0.810)	Total loss 5.034 (5.152)
Epoch: [1][120/200]	Time 0.813 (0.809)	Total loss 4.604 (5.137)
Epoch: [1][125/200]	Time 0.728 (0.807)	Total loss 4.388 (5.126)
Epoch: [1][130/200]	Time 0.865 (0.806)	Total loss 4.821 (5.123)
Epoch: [1][135/200]	Time 0.758 (0.804)	Total loss 5.025 (5.120)
Epoch: [1][140/200]	Time 1.624 (0.809)	Total loss 4.478 (5.106)
Epoch: [1][145/200]	Time 0.744 (0.808)	Total loss 4.592 (5.092)
Epoch: [1][150/200]	Time 0.797 (0.808)	Total loss 4.333 (5.071)
Epoch: [1][155/200]	Time 0.862 (0.807)	Total loss 4.691 (5.056)
Epoch: [1][160/200]	Time 0.779 (0.806)	Total loss 4.873 (5.040)
Epoch: [1][165/200]	Time 1.621 (0.810)	Total loss 4.694 (5.028)
Epoch: [1][170/200]	Time 0.796 (0.809)	Total loss 4.702 (5.011)
Epoch: [1][175/200]	Time 0.783 (0.813)	Total loss 4.466 (4.997)
Epoch: [1][180/200]	Time 0.728 (0.812)	Total loss 4.393 (4.979)
Epoch: [1][185/200]	Time 0.754 (0.810)	Total loss 3.952 (4.961)
Epoch: [1][190/200]	Time 0.728 (0.810)	Total loss 4.567 (4.946)
Epoch: [1][195/200]	Time 0.769 (0.809)	Total loss 4.179 (4.929)
Epoch: [1][200/200]	Time 0.779 (0.808)	Total loss 4.454 (4.916)
==> start training epoch 2 	 ==> learning rate = 9.800000000000001e-05
Epoch: [2][5/200]	Time 0.857 (0.823)	Total loss 4.221 (4.327)
Epoch: [2][10/200]	Time 0.775 (0.807)	Total loss 3.989 (4.401)
Epoch: [2][15/200]	Time 0.747 (0.806)	Total loss 4.099 (4.333)
Epoch: [2][20/200]	Time 0.802 (0.797)	Total loss 4.175 (4.340)
Epoch: [2][25/200]	Time 0.730 (0.796)	Total loss 4.345 (4.312)
Epoch: [2][30/200]	Time 0.742 (0.789)	Total loss 4.411 (4.335)
Epoch: [2][35/200]	Time 0.783 (0.786)	Total loss 4.213 (4.352)
Epoch: [2][40/200]	Time 0.923 (0.787)	Total loss 4.439 (4.363)
Epoch: [2][45/200]	Time 0.761 (0.786)	Total loss 4.295 (4.360)
Epoch: [2][50/200]	Time 0.774 (0.785)	Total loss 4.546 (4.364)
Epoch: [2][55/200]	Time 0.785 (0.799)	Total loss 4.566 (4.361)
Epoch: [2][60/200]	Time 0.764 (0.811)	Total loss 4.249 (4.348)
Epoch: [2][65/200]	Time 0.733 (0.808)	Total loss 4.155 (4.340)
Epoch: [2][70/200]	Time 0.799 (0.816)	Total loss 4.250 (4.312)
Epoch: [2][75/200]	Time 0.751 (0.813)	Total loss 3.979 (4.286)
Epoch: [2][80/200]	Time 0.787 (0.812)	Total loss 4.115 (4.264)
Epoch: [2][85/200]	Time 0.791 (0.811)	Total loss 3.754 (4.241)
Epoch: [2][90/200]	Time 0.749 (0.809)	Total loss 4.301 (4.234)
Epoch: [2][95/200]	Time 0.813 (0.807)	Total loss 3.905 (4.210)
Epoch: [2][100/200]	Time 0.749 (0.806)	Total loss 3.762 (4.199)
Epoch: [2][105/200]	Time 0.787 (0.805)	Total loss 4.342 (4.197)
Epoch: [2][110/200]	Time 0.765 (0.804)	Total loss 4.203 (4.189)
Epoch: [2][115/200]	Time 0.874 (0.803)	Total loss 3.767 (4.177)
Epoch: [2][120/200]	Time 0.758 (0.803)	Total loss 4.285 (4.174)
Epoch: [2][125/200]	Time 0.784 (0.801)	Total loss 3.935 (4.167)
Epoch: [2][130/200]	Time 0.801 (0.801)	Total loss 3.917 (4.158)
Epoch: [2][135/200]	Time 0.787 (0.801)	Total loss 3.718 (4.148)
Epoch: [2][140/200]	Time 0.748 (0.800)	Total loss 4.264 (4.145)
Epoch: [2][145/200]	Time 0.733 (0.798)	Total loss 3.845 (4.142)
Epoch: [2][150/200]	Time 0.751 (0.803)	Total loss 3.449 (4.125)
Epoch: [2][155/200]	Time 0.782 (0.802)	Total loss 4.206 (4.120)
Epoch: [2][160/200]	Time 0.774 (0.806)	Total loss 3.765 (4.113)
Epoch: [2][165/200]	Time 0.765 (0.805)	Total loss 4.267 (4.108)
Epoch: [2][170/200]	Time 0.755 (0.809)	Total loss 4.201 (4.102)
Epoch: [2][175/200]	Time 0.880 (0.808)	Total loss 3.750 (4.090)
Epoch: [2][180/200]	Time 0.761 (0.807)	Total loss 3.561 (4.081)
Epoch: [2][185/200]	Time 0.749 (0.806)	Total loss 3.782 (4.072)
Epoch: [2][190/200]	Time 0.782 (0.805)	Total loss 3.252 (4.064)
Epoch: [2][195/200]	Time 0.780 (0.804)	Total loss 3.884 (4.057)
Epoch: [2][200/200]	Time 0.897 (0.804)	Total loss 4.093 (4.047)
==> start training epoch 3 	 ==> learning rate = 0.0001295
Epoch: [3][5/200]	Time 0.757 (0.785)	Total loss 3.673 (3.522)
Epoch: [3][10/200]	Time 0.752 (0.779)	Total loss 3.686 (3.617)
Epoch: [3][15/200]	Time 0.781 (0.774)	Total loss 3.584 (3.663)
Epoch: [3][20/200]	Time 0.736 (0.772)	Total loss 3.756 (3.698)
Epoch: [3][25/200]	Time 0.755 (0.768)	Total loss 3.446 (3.690)
Epoch: [3][30/200]	Time 0.763 (0.770)	Total loss 3.837 (3.698)
Epoch: [3][35/200]	Time 0.739 (0.773)	Total loss 3.648 (3.711)
Epoch: [3][40/200]	Time 0.808 (0.795)	Total loss 3.566 (3.704)
Epoch: [3][45/200]	Time 0.772 (0.794)	Total loss 3.466 (3.694)
Epoch: [3][50/200]	Time 0.784 (0.790)	Total loss 3.715 (3.671)
Epoch: [3][55/200]	Time 0.770 (0.804)	Total loss 3.294 (3.661)
Epoch: [3][60/200]	Time 0.751 (0.805)	Total loss 3.860 (3.663)
Epoch: [3][65/200]	Time 0.783 (0.803)	Total loss 3.820 (3.673)
Epoch: [3][70/200]	Time 0.836 (0.804)	Total loss 3.855 (3.681)
Epoch: [3][75/200]	Time 0.769 (0.802)	Total loss 3.770 (3.680)
Epoch: [3][80/200]	Time 0.749 (0.811)	Total loss 3.674 (3.676)
Epoch: [3][85/200]	Time 0.733 (0.808)	Total loss 3.531 (3.667)
Epoch: [3][90/200]	Time 0.757 (0.807)	Total loss 3.352 (3.663)
Epoch: [3][95/200]	Time 0.766 (0.805)	Total loss 3.586 (3.657)
Epoch: [3][100/200]	Time 0.819 (0.804)	Total loss 3.668 (3.649)
Epoch: [3][105/200]	Time 0.760 (0.803)	Total loss 3.162 (3.642)
Epoch: [3][110/200]	Time 0.744 (0.802)	Total loss 3.903 (3.644)
Epoch: [3][115/200]	Time 0.804 (0.802)	Total loss 3.997 (3.643)
Epoch: [3][120/200]	Time 0.859 (0.801)	Total loss 3.640 (3.643)
Epoch: [3][125/200]	Time 0.781 (0.799)	Total loss 3.400 (3.638)
Epoch: [3][130/200]	Time 0.734 (0.806)	Total loss 3.293 (3.631)
Epoch: [3][135/200]	Time 0.767 (0.804)	Total loss 3.145 (3.621)
Epoch: [3][140/200]	Time 0.741 (0.803)	Total loss 3.411 (3.615)
Epoch: [3][145/200]	Time 1.705 (0.808)	Total loss 3.487 (3.611)
Epoch: [3][150/200]	Time 0.767 (0.807)	Total loss 3.435 (3.606)
Epoch: [3][155/200]	Time 0.727 (0.807)	Total loss 3.574 (3.605)
Epoch: [3][160/200]	Time 0.770 (0.805)	Total loss 3.124 (3.596)
Epoch: [3][165/200]	Time 0.755 (0.804)	Total loss 3.214 (3.594)
Epoch: [3][170/200]	Time 0.749 (0.803)	Total loss 3.122 (3.585)
Epoch: [3][175/200]	Time 0.773 (0.802)	Total loss 3.440 (3.579)
Epoch: [3][180/200]	Time 0.770 (0.802)	Total loss 3.326 (3.576)
Epoch: [3][185/200]	Time 0.736 (0.800)	Total loss 3.367 (3.574)
Epoch: [3][190/200]	Time 0.801 (0.799)	Total loss 3.347 (3.569)
Epoch: [3][195/200]	Time 0.746 (0.803)	Total loss 3.331 (3.565)
Epoch: [3][200/200]	Time 0.761 (0.802)	Total loss 3.459 (3.559)
==> start training epoch 4 	 ==> learning rate = 0.000161
Epoch: [4][5/200]	Time 0.773 (0.810)	Total loss 3.303 (3.214)
Epoch: [4][10/200]	Time 0.745 (0.777)	Total loss 3.365 (3.259)
Epoch: [4][15/200]	Time 0.742 (0.777)	Total loss 3.571 (3.287)
Epoch: [4][20/200]	Time 1.712 (0.814)	Total loss 3.440 (3.293)
Epoch: [4][25/200]	Time 0.727 (0.806)	Total loss 3.373 (3.301)
Epoch: [4][30/200]	Time 0.740 (0.797)	Total loss 2.902 (3.280)
Epoch: [4][35/200]	Time 0.732 (0.789)	Total loss 3.257 (3.289)
Epoch: [4][40/200]	Time 0.773 (0.811)	Total loss 3.423 (3.289)
Epoch: [4][45/200]	Time 0.733 (0.805)	Total loss 3.413 (3.300)
Epoch: [4][50/200]	Time 0.723 (0.801)	Total loss 3.139 (3.290)
Epoch: [4][55/200]	Time 0.744 (0.796)	Total loss 3.286 (3.283)
Epoch: [4][60/200]	Time 0.753 (0.795)	Total loss 3.599 (3.295)
Epoch: [4][65/200]	Time 0.828 (0.793)	Total loss 3.705 (3.300)
Epoch: [4][70/200]	Time 0.742 (0.790)	Total loss 3.689 (3.300)
Epoch: [4][75/200]	Time 0.747 (0.788)	Total loss 3.187 (3.291)
Epoch: [4][80/200]	Time 0.756 (0.786)	Total loss 3.232 (3.296)
Epoch: [4][85/200]	Time 0.803 (0.787)	Total loss 3.236 (3.290)
Epoch: [4][90/200]	Time 0.894 (0.787)	Total loss 3.705 (3.301)
Epoch: [4][95/200]	Time 0.752 (0.786)	Total loss 3.252 (3.301)
Epoch: [4][100/200]	Time 0.758 (0.785)	Total loss 3.057 (3.295)
Epoch: [4][105/200]	Time 1.565 (0.790)	Total loss 3.524 (3.296)
Epoch: [4][110/200]	Time 0.715 (0.789)	Total loss 3.064 (3.285)
Epoch: [4][115/200]	Time 0.752 (0.796)	Total loss 3.061 (3.279)
Epoch: [4][120/200]	Time 0.747 (0.794)	Total loss 2.971 (3.275)
Epoch: [4][125/200]	Time 0.737 (0.793)	Total loss 3.308 (3.276)
Epoch: [4][130/200]	Time 0.732 (0.791)	Total loss 3.722 (3.283)
Epoch: [4][135/200]	Time 0.755 (0.796)	Total loss 2.996 (3.278)
Epoch: [4][140/200]	Time 0.722 (0.795)	Total loss 3.103 (3.266)
Epoch: [4][145/200]	Time 0.783 (0.794)	Total loss 3.159 (3.262)
Epoch: [4][150/200]	Time 0.749 (0.792)	Total loss 3.069 (3.260)
Epoch: [4][155/200]	Time 0.737 (0.792)	Total loss 3.001 (3.260)
Epoch: [4][160/200]	Time 0.849 (0.791)	Total loss 3.112 (3.257)
Epoch: [4][165/200]	Time 0.749 (0.791)	Total loss 3.332 (3.255)
Epoch: [4][170/200]	Time 0.771 (0.790)	Total loss 3.122 (3.250)
Epoch: [4][175/200]	Time 0.835 (0.789)	Total loss 3.055 (3.242)
Epoch: [4][180/200]	Time 0.758 (0.789)	Total loss 3.150 (3.237)
Epoch: [4][185/200]	Time 0.854 (0.789)	Total loss 3.260 (3.234)
Epoch: [4][190/200]	Time 0.746 (0.788)	Total loss 3.208 (3.234)
Epoch: [4][195/200]	Time 0.785 (0.788)	Total loss 2.964 (3.231)
Epoch: [4][200/200]	Time 0.763 (0.788)	Total loss 3.013 (3.227)
==> start training epoch 5 	 ==> learning rate = 0.00019250000000000002
Epoch: [5][5/200]	Time 0.778 (1.000)	Total loss 3.124 (3.118)
Epoch: [5][10/200]	Time 0.764 (0.881)	Total loss 3.180 (3.050)
Epoch: [5][15/200]	Time 0.745 (0.843)	Total loss 2.818 (3.005)
Epoch: [5][20/200]	Time 0.859 (0.862)	Total loss 3.331 (3.029)
Epoch: [5][25/200]	Time 0.762 (0.867)	Total loss 3.217 (3.057)
Epoch: [5][30/200]	Time 0.744 (0.848)	Total loss 3.433 (3.049)
Epoch: [5][35/200]	Time 0.769 (0.834)	Total loss 3.316 (3.054)
Epoch: [5][40/200]	Time 0.773 (0.827)	Total loss 3.195 (3.063)
Epoch: [5][45/200]	Time 0.739 (0.818)	Total loss 3.011 (3.052)
Epoch: [5][50/200]	Time 0.746 (0.812)	Total loss 3.327 (3.062)
Epoch: [5][55/200]	Time 0.783 (0.809)	Total loss 3.256 (3.055)
Epoch: [5][60/200]	Time 0.772 (0.806)	Total loss 2.813 (3.051)
Epoch: [5][65/200]	Time 0.786 (0.805)	Total loss 3.107 (3.052)
Epoch: [5][70/200]	Time 0.741 (0.802)	Total loss 3.067 (3.053)
Epoch: [5][75/200]	Time 0.731 (0.799)	Total loss 3.010 (3.061)
Epoch: [5][80/200]	Time 0.852 (0.797)	Total loss 2.787 (3.061)
Epoch: [5][85/200]	Time 0.725 (0.794)	Total loss 3.086 (3.066)
Epoch: [5][90/200]	Time 0.746 (0.793)	Total loss 3.004 (3.067)
Epoch: [5][95/200]	Time 0.756 (0.801)	Total loss 3.030 (3.058)
Epoch: [5][100/200]	Time 0.756 (0.800)	Total loss 2.960 (3.054)
Epoch: [5][105/200]	Time 0.854 (0.799)	Total loss 2.763 (3.056)
Epoch: [5][110/200]	Time 0.749 (0.797)	Total loss 3.131 (3.060)
Epoch: [5][115/200]	Time 0.820 (0.796)	Total loss 3.246 (3.055)
Epoch: [5][120/200]	Time 0.769 (0.801)	Total loss 2.869 (3.046)
Epoch: [5][125/200]	Time 0.803 (0.800)	Total loss 3.003 (3.044)
Epoch: [5][130/200]	Time 0.731 (0.798)	Total loss 2.712 (3.044)
Epoch: [5][135/200]	Time 0.750 (0.803)	Total loss 2.989 (3.043)
Epoch: [5][140/200]	Time 0.861 (0.802)	Total loss 2.849 (3.035)
Epoch: [5][145/200]	Time 0.757 (0.801)	Total loss 2.935 (3.032)
Epoch: [5][150/200]	Time 0.751 (0.800)	Total loss 3.222 (3.032)
Epoch: [5][155/200]	Time 0.741 (0.799)	Total loss 2.989 (3.031)
Epoch: [5][160/200]	Time 0.737 (0.797)	Total loss 3.249 (3.028)
Epoch: [5][165/200]	Time 0.748 (0.796)	Total loss 2.657 (3.022)
Epoch: [5][170/200]	Time 0.744 (0.796)	Total loss 2.850 (3.018)
Epoch: [5][175/200]	Time 0.751 (0.795)	Total loss 2.615 (3.013)
Epoch: [5][180/200]	Time 0.738 (0.794)	Total loss 2.736 (3.013)
Epoch: [5][185/200]	Time 0.792 (0.798)	Total loss 2.676 (3.012)
Epoch: [5][190/200]	Time 0.760 (0.797)	Total loss 2.789 (3.011)
Epoch: [5][195/200]	Time 0.743 (0.797)	Total loss 2.935 (3.008)
Epoch: [5][200/200]	Time 0.846 (0.796)	Total loss 2.538 (3.005)
==> start training epoch 6 	 ==> learning rate = 0.000224
Epoch: [6][5/200]	Time 0.776 (0.772)	Total loss 2.396 (2.684)
Epoch: [6][10/200]	Time 1.512 (0.840)	Total loss 2.635 (2.788)
Epoch: [6][15/200]	Time 0.744 (0.811)	Total loss 2.734 (2.843)
Epoch: [6][20/200]	Time 0.754 (0.794)	Total loss 2.874 (2.855)
Epoch: [6][25/200]	Time 0.772 (0.791)	Total loss 2.991 (2.850)
Epoch: [6][30/200]	Time 0.739 (0.786)	Total loss 2.889 (2.867)
Epoch: [6][35/200]	Time 0.860 (0.785)	Total loss 2.835 (2.882)
Epoch: [6][40/200]	Time 0.718 (0.779)	Total loss 2.986 (2.889)
Epoch: [6][45/200]	Time 0.771 (0.794)	Total loss 3.297 (2.905)
Epoch: [6][50/200]	Time 0.823 (0.791)	Total loss 2.919 (2.901)
Epoch: [6][55/200]	Time 0.768 (0.790)	Total loss 2.926 (2.882)
Epoch: [6][60/200]	Time 0.773 (0.790)	Total loss 2.970 (2.892)
Epoch: [6][65/200]	Time 0.757 (0.790)	Total loss 2.769 (2.895)
Epoch: [6][70/200]	Time 0.741 (0.789)	Total loss 2.757 (2.887)
Epoch: [6][75/200]	Time 1.660 (0.799)	Total loss 2.832 (2.892)
Epoch: [6][80/200]	Time 0.735 (0.797)	Total loss 2.720 (2.891)
Epoch: [6][85/200]	Time 0.818 (0.796)	Total loss 2.926 (2.887)
Epoch: [6][90/200]	Time 0.759 (0.796)	Total loss 2.967 (2.893)
Epoch: [6][95/200]	Time 0.730 (0.793)	Total loss 3.006 (2.890)
Epoch: [6][100/200]	Time 0.718 (0.791)	Total loss 2.463 (2.879)
Epoch: [6][105/200]	Time 0.739 (0.799)	Total loss 2.769 (2.868)
Epoch: [6][110/200]	Time 0.747 (0.797)	Total loss 2.949 (2.868)
Epoch: [6][115/200]	Time 0.804 (0.798)	Total loss 2.866 (2.862)
Epoch: [6][120/200]	Time 0.869 (0.797)	Total loss 2.940 (2.867)
Epoch: [6][125/200]	Time 0.769 (0.796)	Total loss 3.065 (2.862)
Epoch: [6][130/200]	Time 0.779 (0.796)	Total loss 2.597 (2.855)
Epoch: [6][135/200]	Time 0.796 (0.795)	Total loss 3.038 (2.857)
Epoch: [6][140/200]	Time 0.743 (0.795)	Total loss 2.791 (2.855)
Epoch: [6][145/200]	Time 0.779 (0.794)	Total loss 2.241 (2.851)
Epoch: [6][150/200]	Time 0.734 (0.794)	Total loss 3.148 (2.856)
Epoch: [6][155/200]	Time 0.740 (0.793)	Total loss 2.931 (2.859)
Epoch: [6][160/200]	Time 0.741 (0.797)	Total loss 2.460 (2.859)
Epoch: [6][165/200]	Time 0.719 (0.796)	Total loss 2.913 (2.859)
Epoch: [6][170/200]	Time 0.743 (0.800)	Total loss 3.088 (2.859)
Epoch: [6][175/200]	Time 0.786 (0.800)	Total loss 2.763 (2.858)
Epoch: [6][180/200]	Time 0.825 (0.799)	Total loss 2.880 (2.854)
Epoch: [6][185/200]	Time 0.769 (0.798)	Total loss 2.592 (2.854)
Epoch: [6][190/200]	Time 0.734 (0.797)	Total loss 3.082 (2.849)
Epoch: [6][195/200]	Time 0.730 (0.795)	Total loss 2.602 (2.848)
Epoch: [6][200/200]	Time 0.759 (0.799)	Total loss 2.488 (2.843)
==> start training epoch 7 	 ==> learning rate = 0.0002555
Epoch: [7][5/200]	Time 0.766 (0.789)	Total loss 2.511 (2.578)
Epoch: [7][10/200]	Time 0.743 (0.780)	Total loss 3.269 (2.677)
Epoch: [7][15/200]	Time 0.893 (0.783)	Total loss 3.005 (2.747)
Epoch: [7][20/200]	Time 0.747 (0.779)	Total loss 2.912 (2.770)
Epoch: [7][25/200]	Time 0.751 (0.779)	Total loss 2.721 (2.756)
Epoch: [7][30/200]	Time 0.777 (0.774)	Total loss 2.443 (2.733)
Epoch: [7][35/200]	Time 0.756 (0.775)	Total loss 3.134 (2.758)
Epoch: [7][40/200]	Time 0.844 (0.775)	Total loss 2.696 (2.777)
Epoch: [7][45/200]	Time 0.759 (0.774)	Total loss 2.782 (2.781)
Epoch: [7][50/200]	Time 0.735 (0.776)	Total loss 2.687 (2.779)
Epoch: [7][55/200]	Time 0.728 (0.772)	Total loss 2.672 (2.768)
Epoch: [7][60/200]	Time 0.787 (0.790)	Total loss 2.844 (2.773)
Epoch: [7][65/200]	Time 0.818 (0.790)	Total loss 2.734 (2.774)
Epoch: [7][70/200]	Time 1.618 (0.799)	Total loss 2.850 (2.775)
Epoch: [7][75/200]	Time 0.765 (0.798)	Total loss 2.328 (2.770)
Epoch: [7][80/200]	Time 0.743 (0.795)	Total loss 2.522 (2.769)
Epoch: [7][85/200]	Time 0.729 (0.794)	Total loss 3.032 (2.770)
Epoch: [7][90/200]	Time 0.750 (0.800)	Total loss 2.640 (2.770)
Epoch: [7][95/200]	Time 0.730 (0.799)	Total loss 3.035 (2.776)
Epoch: [7][100/200]	Time 0.770 (0.798)	Total loss 2.381 (2.774)
Epoch: [7][105/200]	Time 0.745 (0.797)	Total loss 2.624 (2.769)
Epoch: [7][110/200]	Time 0.778 (0.797)	Total loss 2.747 (2.769)
Epoch: [7][115/200]	Time 0.740 (0.795)	Total loss 2.870 (2.771)
Epoch: [7][120/200]	Time 0.757 (0.794)	Total loss 2.628 (2.765)
Epoch: [7][125/200]	Time 0.862 (0.794)	Total loss 3.007 (2.764)
Epoch: [7][130/200]	Time 0.740 (0.792)	Total loss 2.825 (2.761)
Epoch: [7][135/200]	Time 0.753 (0.791)	Total loss 2.201 (2.755)
Epoch: [7][140/200]	Time 0.748 (0.790)	Total loss 2.772 (2.755)
Epoch: [7][145/200]	Time 0.743 (0.790)	Total loss 2.635 (2.752)
Epoch: [7][150/200]	Time 0.773 (0.794)	Total loss 2.882 (2.757)
Epoch: [7][155/200]	Time 0.761 (0.794)	Total loss 2.624 (2.759)
Epoch: [7][160/200]	Time 0.858 (0.793)	Total loss 2.573 (2.755)
Epoch: [7][165/200]	Time 0.748 (0.792)	Total loss 2.923 (2.759)
Epoch: [7][170/200]	Time 0.721 (0.791)	Total loss 2.952 (2.759)
Epoch: [7][175/200]	Time 0.747 (0.790)	Total loss 2.655 (2.760)
Epoch: [7][180/200]	Time 0.725 (0.789)	Total loss 2.764 (2.758)
Epoch: [7][185/200]	Time 0.748 (0.797)	Total loss 2.559 (2.756)
Epoch: [7][190/200]	Time 0.771 (0.796)	Total loss 2.845 (2.756)
Epoch: [7][195/200]	Time 0.851 (0.796)	Total loss 2.656 (2.752)
Epoch: [7][200/200]	Time 0.782 (0.795)	Total loss 2.314 (2.752)
==> start training epoch 8 	 ==> learning rate = 0.00028700000000000004
Epoch: [8][5/200]	Time 0.754 (0.794)	Total loss 2.664 (2.665)
Epoch: [8][10/200]	Time 0.745 (0.772)	Total loss 2.366 (2.613)
Epoch: [8][15/200]	Time 0.753 (0.776)	Total loss 2.686 (2.633)
Epoch: [8][20/200]	Time 0.895 (0.776)	Total loss 2.964 (2.687)
Epoch: [8][25/200]	Time 0.757 (0.778)	Total loss 2.207 (2.673)
Epoch: [8][30/200]	Time 0.762 (0.780)	Total loss 2.678 (2.675)
Epoch: [8][35/200]	Time 0.756 (0.778)	Total loss 2.848 (2.697)
Epoch: [8][40/200]	Time 0.764 (0.801)	Total loss 2.698 (2.675)
Epoch: [8][45/200]	Time 0.812 (0.798)	Total loss 2.614 (2.682)
Epoch: [8][50/200]	Time 0.802 (0.799)	Total loss 2.772 (2.691)
Epoch: [8][55/200]	Time 0.849 (0.798)	Total loss 2.876 (2.686)
Epoch: [8][60/200]	Time 0.764 (0.796)	Total loss 2.832 (2.694)
Epoch: [8][65/200]	Time 0.744 (0.793)	Total loss 2.545 (2.688)
Epoch: [8][70/200]	Time 0.758 (0.791)	Total loss 2.947 (2.692)
Epoch: [8][75/200]	Time 1.591 (0.800)	Total loss 2.583 (2.686)
Epoch: [8][80/200]	Time 0.770 (0.797)	Total loss 2.479 (2.677)
Epoch: [8][85/200]	Time 0.788 (0.797)	Total loss 2.548 (2.675)
Epoch: [8][90/200]	Time 0.748 (0.796)	Total loss 2.471 (2.675)
Epoch: [8][95/200]	Time 0.754 (0.793)	Total loss 2.619 (2.675)
Epoch: [8][100/200]	Time 0.734 (0.800)	Total loss 2.493 (2.672)
Epoch: [8][105/200]	Time 0.766 (0.800)	Total loss 2.510 (2.677)
Epoch: [8][110/200]	Time 0.743 (0.799)	Total loss 2.612 (2.674)
Epoch: [8][115/200]	Time 0.921 (0.799)	Total loss 2.724 (2.668)
Epoch: [8][120/200]	Time 0.762 (0.797)	Total loss 2.859 (2.667)
Epoch: [8][125/200]	Time 0.851 (0.797)	Total loss 2.806 (2.664)
Epoch: [8][130/200]	Time 1.641 (0.803)	Total loss 2.321 (2.663)
Epoch: [8][135/200]	Time 0.764 (0.802)	Total loss 2.482 (2.663)
Epoch: [8][140/200]	Time 0.867 (0.802)	Total loss 2.365 (2.663)
Epoch: [8][145/200]	Time 0.768 (0.801)	Total loss 2.730 (2.660)
Epoch: [8][150/200]	Time 0.753 (0.800)	Total loss 2.539 (2.660)
Epoch: [8][155/200]	Time 0.790 (0.799)	Total loss 2.875 (2.658)
Epoch: [8][160/200]	Time 0.742 (0.798)	Total loss 2.653 (2.656)
Epoch: [8][165/200]	Time 0.828 (0.797)	Total loss 3.021 (2.659)
Epoch: [8][170/200]	Time 0.772 (0.801)	Total loss 2.843 (2.662)
Epoch: [8][175/200]	Time 0.751 (0.800)	Total loss 2.248 (2.660)
Epoch: [8][180/200]	Time 0.758 (0.799)	Total loss 2.820 (2.661)
Epoch: [8][185/200]	Time 0.740 (0.799)	Total loss 2.686 (2.658)
Epoch: [8][190/200]	Time 0.747 (0.798)	Total loss 2.653 (2.659)
Epoch: [8][195/200]	Time 0.774 (0.798)	Total loss 2.399 (2.659)
Epoch: [8][200/200]	Time 0.750 (0.796)	Total loss 2.755 (2.658)
==> start training epoch 9 	 ==> learning rate = 0.0003185
Epoch: [9][5/200]	Time 0.721 (0.770)	Total loss 2.233 (2.534)
Epoch: [9][10/200]	Time 0.747 (0.848)	Total loss 2.774 (2.581)
Epoch: [9][15/200]	Time 0.747 (0.820)	Total loss 2.693 (2.612)
Epoch: [9][20/200]	Time 0.787 (0.809)	Total loss 2.771 (2.657)
Epoch: [9][25/200]	Time 0.763 (0.831)	Total loss 2.732 (2.634)
Epoch: [9][30/200]	Time 0.739 (0.822)	Total loss 2.310 (2.593)
Epoch: [9][35/200]	Time 0.782 (0.814)	Total loss 2.470 (2.599)
Epoch: [9][40/200]	Time 0.759 (0.811)	Total loss 2.561 (2.603)
Epoch: [9][45/200]	Time 0.778 (0.811)	Total loss 2.794 (2.594)
Epoch: [9][50/200]	Time 0.774 (0.806)	Total loss 2.414 (2.601)
Epoch: [9][55/200]	Time 0.762 (0.802)	Total loss 2.771 (2.597)
Epoch: [9][60/200]	Time 0.715 (0.797)	Total loss 2.662 (2.598)
Epoch: [9][65/200]	Time 0.763 (0.808)	Total loss 2.417 (2.606)
Epoch: [9][70/200]	Time 0.848 (0.806)	Total loss 2.818 (2.603)
Epoch: [9][75/200]	Time 0.778 (0.803)	Total loss 2.872 (2.612)
Epoch: [9][80/200]	Time 0.748 (0.800)	Total loss 2.550 (2.619)
Epoch: [9][85/200]	Time 0.755 (0.797)	Total loss 2.478 (2.633)
Epoch: [9][90/200]	Time 0.778 (0.797)	Total loss 2.661 (2.638)
Epoch: [9][95/200]	Time 0.823 (0.795)	Total loss 2.507 (2.631)
Epoch: [9][100/200]	Time 0.774 (0.794)	Total loss 2.485 (2.627)
Epoch: [9][105/200]	Time 0.812 (0.796)	Total loss 2.417 (2.625)
Epoch: [9][110/200]	Time 0.752 (0.794)	Total loss 3.011 (2.625)
Epoch: [9][115/200]	Time 0.763 (0.801)	Total loss 2.338 (2.622)
Epoch: [9][120/200]	Time 0.750 (0.800)	Total loss 2.197 (2.618)
Epoch: [9][125/200]	Time 0.754 (0.805)	Total loss 2.367 (2.614)
Epoch: [9][130/200]	Time 0.757 (0.804)	Total loss 2.630 (2.612)
Epoch: [9][135/200]	Time 0.746 (0.803)	Total loss 2.645 (2.608)
Epoch: [9][140/200]	Time 0.745 (0.801)	Total loss 2.307 (2.608)
Epoch: [9][145/200]	Time 0.737 (0.799)	Total loss 2.858 (2.609)
Epoch: [9][150/200]	Time 0.738 (0.798)	Total loss 2.769 (2.609)
Epoch: [9][155/200]	Time 0.847 (0.802)	Total loss 2.461 (2.611)
Epoch: [9][160/200]	Time 0.729 (0.801)	Total loss 2.621 (2.606)
Epoch: [9][165/200]	Time 0.734 (0.799)	Total loss 2.581 (2.602)
Epoch: [9][170/200]	Time 0.741 (0.797)	Total loss 2.524 (2.600)
Epoch: [9][175/200]	Time 0.751 (0.797)	Total loss 2.577 (2.601)
Epoch: [9][180/200]	Time 0.729 (0.796)	Total loss 2.861 (2.601)
Epoch: [9][185/200]	Time 0.765 (0.795)	Total loss 2.527 (2.600)
Epoch: [9][190/200]	Time 0.792 (0.795)	Total loss 2.409 (2.598)
Epoch: [9][195/200]	Time 0.791 (0.795)	Total loss 2.616 (2.596)
Epoch: [9][200/200]	Time 0.748 (0.794)	Total loss 2.482 (2.596)
==> start training epoch 10 	 ==> learning rate = 0.00035
Epoch: [10][5/200]	Time 0.760 (0.988)	Total loss 2.294 (2.375)
Epoch: [10][10/200]	Time 0.808 (0.888)	Total loss 2.636 (2.459)
Epoch: [10][15/200]	Time 0.898 (0.856)	Total loss 2.966 (2.493)
Epoch: [10][20/200]	Time 0.763 (0.830)	Total loss 2.419 (2.514)
Epoch: [10][25/200]	Time 0.793 (0.821)	Total loss 2.427 (2.500)
Epoch: [10][30/200]	Time 0.756 (0.808)	Total loss 2.627 (2.510)
Epoch: [10][35/200]	Time 1.610 (0.825)	Total loss 2.228 (2.498)
Epoch: [10][40/200]	Time 0.750 (0.820)	Total loss 3.005 (2.507)
Epoch: [10][45/200]	Time 0.780 (0.813)	Total loss 2.669 (2.521)
Epoch: [10][50/200]	Time 0.787 (0.827)	Total loss 2.409 (2.529)
Epoch: [10][55/200]	Time 0.782 (0.823)	Total loss 2.809 (2.542)
Epoch: [10][60/200]	Time 0.770 (0.821)	Total loss 2.426 (2.544)
Epoch: [10][65/200]	Time 0.733 (0.817)	Total loss 2.651 (2.550)
Epoch: [10][70/200]	Time 0.761 (0.814)	Total loss 2.634 (2.554)
Epoch: [10][75/200]	Time 0.863 (0.812)	Total loss 2.573 (2.549)
Epoch: [10][80/200]	Time 0.806 (0.809)	Total loss 2.563 (2.544)
Epoch: [10][85/200]	Time 0.748 (0.806)	Total loss 2.658 (2.545)
Epoch: [10][90/200]	Time 0.839 (0.803)	Total loss 2.298 (2.544)
Epoch: [10][95/200]	Time 0.723 (0.810)	Total loss 2.454 (2.534)
Epoch: [10][100/200]	Time 0.764 (0.808)	Total loss 2.573 (2.538)
Epoch: [10][105/200]	Time 0.744 (0.805)	Total loss 2.466 (2.542)
Epoch: [10][110/200]	Time 0.726 (0.803)	Total loss 2.417 (2.534)
Epoch: [10][115/200]	Time 0.843 (0.802)	Total loss 2.447 (2.527)
Epoch: [10][120/200]	Time 0.731 (0.800)	Total loss 2.414 (2.524)
Epoch: [10][125/200]	Time 0.850 (0.800)	Total loss 2.149 (2.515)
Epoch: [10][130/200]	Time 0.748 (0.799)	Total loss 2.416 (2.514)
Epoch: [10][135/200]	Time 0.731 (0.798)	Total loss 2.403 (2.516)
Epoch: [10][140/200]	Time 1.530 (0.802)	Total loss 2.153 (2.516)
Epoch: [10][145/200]	Time 0.761 (0.802)	Total loss 2.833 (2.517)
Epoch: [10][150/200]	Time 0.918 (0.806)	Total loss 2.295 (2.514)
Epoch: [10][155/200]	Time 0.739 (0.804)	Total loss 2.746 (2.513)
Epoch: [10][160/200]	Time 0.787 (0.804)	Total loss 2.622 (2.512)
Epoch: [10][165/200]	Time 0.729 (0.802)	Total loss 2.430 (2.513)
Epoch: [10][170/200]	Time 0.790 (0.801)	Total loss 2.795 (2.518)
Epoch: [10][175/200]	Time 0.826 (0.801)	Total loss 2.639 (2.524)
Epoch: [10][180/200]	Time 0.744 (0.800)	Total loss 2.909 (2.529)
Epoch: [10][185/200]	Time 1.643 (0.804)	Total loss 2.626 (2.532)
Epoch: [10][190/200]	Time 0.826 (0.804)	Total loss 2.548 (2.533)
Epoch: [10][195/200]	Time 0.758 (0.803)	Total loss 2.311 (2.533)
Epoch: [10][200/200]	Time 0.750 (0.802)	Total loss 2.646 (2.531)
==> start training epoch 11 	 ==> learning rate = 0.00035
Epoch: [11][5/200]	Time 0.808 (0.808)	Total loss 2.706 (2.615)
Epoch: [11][10/200]	Time 0.737 (0.791)	Total loss 2.321 (2.551)
Epoch: [11][15/200]	Time 0.740 (0.783)	Total loss 2.455 (2.566)
Epoch: [11][20/200]	Time 0.737 (0.779)	Total loss 2.158 (2.522)
Epoch: [11][25/200]	Time 0.741 (0.774)	Total loss 2.484 (2.509)
Epoch: [11][30/200]	Time 0.738 (0.771)	Total loss 2.291 (2.498)
Epoch: [11][35/200]	Time 0.865 (0.794)	Total loss 2.510 (2.497)
Epoch: [11][40/200]	Time 0.740 (0.790)	Total loss 2.405 (2.500)
Epoch: [11][45/200]	Time 0.793 (0.789)	Total loss 2.691 (2.506)
Epoch: [11][50/200]	Time 0.794 (0.786)	Total loss 2.382 (2.486)
Epoch: [11][55/200]	Time 0.739 (0.785)	Total loss 2.512 (2.484)
Epoch: [11][60/200]	Time 0.843 (0.784)	Total loss 2.318 (2.478)
Epoch: [11][65/200]	Time 0.745 (0.795)	Total loss 2.801 (2.475)
Epoch: [11][70/200]	Time 0.752 (0.795)	Total loss 3.014 (2.477)
Epoch: [11][75/200]	Time 0.762 (0.794)	Total loss 2.125 (2.471)
Epoch: [11][80/200]	Time 0.730 (0.803)	Total loss 2.353 (2.466)
Epoch: [11][85/200]	Time 0.830 (0.801)	Total loss 2.508 (2.468)
Epoch: [11][90/200]	Time 0.786 (0.798)	Total loss 2.825 (2.477)
Epoch: [11][95/200]	Time 0.741 (0.798)	Total loss 2.319 (2.480)
Epoch: [11][100/200]	Time 0.738 (0.796)	Total loss 2.473 (2.478)
Epoch: [11][105/200]	Time 0.743 (0.795)	Total loss 2.376 (2.484)
Epoch: [11][110/200]	Time 0.878 (0.794)	Total loss 2.586 (2.487)
Epoch: [11][115/200]	Time 0.746 (0.793)	Total loss 2.466 (2.487)
Epoch: [11][120/200]	Time 0.741 (0.792)	Total loss 2.394 (2.479)
Epoch: [11][125/200]	Time 0.724 (0.790)	Total loss 2.514 (2.481)
Epoch: [11][130/200]	Time 0.760 (0.796)	Total loss 2.667 (2.484)
Epoch: [11][135/200]	Time 0.748 (0.795)	Total loss 2.637 (2.481)
Epoch: [11][140/200]	Time 0.742 (0.795)	Total loss 2.524 (2.484)
Epoch: [11][145/200]	Time 0.732 (0.794)	Total loss 2.223 (2.488)
Epoch: [11][150/200]	Time 0.713 (0.793)	Total loss 2.297 (2.483)
Epoch: [11][155/200]	Time 0.795 (0.792)	Total loss 2.457 (2.481)
Epoch: [11][160/200]	Time 0.803 (0.791)	Total loss 2.744 (2.479)
Epoch: [11][165/200]	Time 0.761 (0.790)	Total loss 2.434 (2.481)
Epoch: [11][170/200]	Time 0.734 (0.795)	Total loss 2.638 (2.481)
Epoch: [11][175/200]	Time 0.758 (0.799)	Total loss 2.150 (2.477)
Epoch: [11][180/200]	Time 0.776 (0.798)	Total loss 2.480 (2.476)
Epoch: [11][185/200]	Time 0.773 (0.797)	Total loss 2.348 (2.470)
Epoch: [11][190/200]	Time 0.759 (0.797)	Total loss 2.647 (2.472)
Epoch: [11][195/200]	Time 0.888 (0.797)	Total loss 2.424 (2.472)
Epoch: [11][200/200]	Time 0.749 (0.796)	Total loss 2.544 (2.475)
==> start training epoch 12 	 ==> learning rate = 0.00035
Epoch: [12][5/200]	Time 0.769 (0.821)	Total loss 2.232 (2.363)
Epoch: [12][10/200]	Time 0.732 (0.794)	Total loss 2.368 (2.378)
Epoch: [12][15/200]	Time 0.743 (0.781)	Total loss 2.345 (2.406)
Epoch: [12][20/200]	Time 0.835 (0.815)	Total loss 2.127 (2.413)
Epoch: [12][25/200]	Time 0.774 (0.808)	Total loss 2.326 (2.429)
Epoch: [12][30/200]	Time 0.772 (0.801)	Total loss 2.660 (2.446)
Epoch: [12][35/200]	Time 0.748 (0.795)	Total loss 2.625 (2.447)
Epoch: [12][40/200]	Time 0.755 (0.793)	Total loss 2.222 (2.435)
Epoch: [12][45/200]	Time 0.796 (0.790)	Total loss 2.797 (2.436)
Epoch: [12][50/200]	Time 0.799 (0.791)	Total loss 2.100 (2.432)
Epoch: [12][55/200]	Time 0.821 (0.788)	Total loss 2.402 (2.435)
Epoch: [12][60/200]	Time 0.748 (0.799)	Total loss 2.623 (2.435)
Epoch: [12][65/200]	Time 0.771 (0.798)	Total loss 2.537 (2.436)
Epoch: [12][70/200]	Time 0.740 (0.794)	Total loss 2.369 (2.439)
Epoch: [12][75/200]	Time 0.739 (0.793)	Total loss 2.615 (2.439)
Epoch: [12][80/200]	Time 0.834 (0.791)	Total loss 2.175 (2.437)
Epoch: [12][85/200]	Time 0.743 (0.788)	Total loss 2.708 (2.438)
Epoch: [12][90/200]	Time 0.788 (0.797)	Total loss 2.564 (2.436)
Epoch: [12][95/200]	Time 0.800 (0.796)	Total loss 2.096 (2.434)
Epoch: [12][100/200]	Time 0.735 (0.795)	Total loss 2.585 (2.435)
Epoch: [12][105/200]	Time 0.731 (0.793)	Total loss 2.151 (2.431)
Epoch: [12][110/200]	Time 0.780 (0.793)	Total loss 2.443 (2.436)
Epoch: [12][115/200]	Time 0.724 (0.798)	Total loss 2.082 (2.427)
Epoch: [12][120/200]	Time 0.740 (0.797)	Total loss 2.409 (2.422)
Epoch: [12][125/200]	Time 0.776 (0.797)	Total loss 2.385 (2.418)
Epoch: [12][130/200]	Time 0.754 (0.796)	Total loss 2.502 (2.420)
Epoch: [12][135/200]	Time 0.716 (0.795)	Total loss 2.402 (2.416)
Epoch: [12][140/200]	Time 0.848 (0.795)	Total loss 2.470 (2.415)
Epoch: [12][145/200]	Time 0.760 (0.793)	Total loss 2.406 (2.417)
Epoch: [12][150/200]	Time 0.771 (0.799)	Total loss 2.210 (2.412)
Epoch: [12][155/200]	Time 0.795 (0.798)	Total loss 2.455 (2.414)
Epoch: [12][160/200]	Time 0.761 (0.797)	Total loss 2.198 (2.413)
Epoch: [12][165/200]	Time 0.759 (0.796)	Total loss 2.332 (2.414)
Epoch: [12][170/200]	Time 0.782 (0.795)	Total loss 2.238 (2.412)
Epoch: [12][175/200]	Time 0.870 (0.795)	Total loss 2.338 (2.414)
Epoch: [12][180/200]	Time 0.793 (0.794)	Total loss 2.662 (2.413)
Epoch: [12][185/200]	Time 0.779 (0.795)	Total loss 2.467 (2.414)
Epoch: [12][190/200]	Time 0.770 (0.794)	Total loss 2.240 (2.411)
Epoch: [12][195/200]	Time 0.814 (0.793)	Total loss 2.332 (2.409)
Epoch: [12][200/200]	Time 1.583 (0.796)	Total loss 2.194 (2.404)
==> start training epoch 13 	 ==> learning rate = 0.00035
Epoch: [13][5/200]	Time 1.584 (0.950)	Total loss 2.360 (2.319)
Epoch: [13][10/200]	Time 0.765 (0.872)	Total loss 2.264 (2.278)
Epoch: [13][15/200]	Time 0.816 (0.836)	Total loss 2.183 (2.304)
Epoch: [13][20/200]	Time 0.748 (0.823)	Total loss 2.216 (2.297)
Epoch: [13][25/200]	Time 0.844 (0.814)	Total loss 2.320 (2.289)
Epoch: [13][30/200]	Time 0.727 (0.802)	Total loss 2.720 (2.284)
Epoch: [13][35/200]	Time 0.731 (0.794)	Total loss 2.585 (2.293)
Epoch: [13][40/200]	Time 1.677 (0.812)	Total loss 2.385 (2.298)
Epoch: [13][45/200]	Time 0.767 (0.808)	Total loss 2.060 (2.290)
Epoch: [13][50/200]	Time 0.851 (0.805)	Total loss 2.566 (2.291)
Epoch: [13][55/200]	Time 0.751 (0.801)	Total loss 2.084 (2.287)
Epoch: [13][60/200]	Time 0.741 (0.798)	Total loss 2.506 (2.296)
Epoch: [13][65/200]	Time 0.747 (0.796)	Total loss 2.342 (2.291)
Epoch: [13][70/200]	Time 0.758 (0.795)	Total loss 2.489 (2.298)
Epoch: [13][75/200]	Time 0.754 (0.792)	Total loss 1.929 (2.295)
Epoch: [13][80/200]	Time 0.744 (0.791)	Total loss 2.103 (2.287)
Epoch: [13][85/200]	Time 0.827 (0.789)	Total loss 2.271 (2.287)
Epoch: [13][90/200]	Time 0.743 (0.788)	Total loss 2.537 (2.290)
Epoch: [13][95/200]	Time 0.729 (0.786)	Total loss 2.200 (2.295)
Epoch: [13][100/200]	Time 0.737 (0.794)	Total loss 2.374 (2.296)
Epoch: [13][105/200]	Time 0.722 (0.793)	Total loss 2.257 (2.295)
Epoch: [13][110/200]	Time 0.740 (0.791)	Total loss 2.317 (2.297)
Epoch: [13][115/200]	Time 0.734 (0.796)	Total loss 2.096 (2.297)
Epoch: [13][120/200]	Time 0.767 (0.795)	Total loss 2.300 (2.302)
Epoch: [13][125/200]	Time 0.726 (0.793)	Total loss 2.740 (2.309)
Epoch: [13][130/200]	Time 0.748 (0.791)	Total loss 2.264 (2.313)
Epoch: [13][135/200]	Time 0.744 (0.796)	Total loss 2.371 (2.310)
Epoch: [13][140/200]	Time 0.812 (0.796)	Total loss 2.261 (2.309)
Epoch: [13][145/200]	Time 0.794 (0.795)	Total loss 2.338 (2.312)
Epoch: [13][150/200]	Time 0.794 (0.795)	Total loss 2.395 (2.314)
Epoch: [13][155/200]	Time 0.759 (0.794)	Total loss 1.850 (2.310)
Epoch: [13][160/200]	Time 0.745 (0.793)	Total loss 2.378 (2.313)
Epoch: [13][165/200]	Time 0.786 (0.792)	Total loss 2.071 (2.315)
Epoch: [13][170/200]	Time 0.847 (0.792)	Total loss 2.273 (2.318)
Epoch: [13][175/200]	Time 0.746 (0.791)	Total loss 2.335 (2.317)
Epoch: [13][180/200]	Time 0.742 (0.790)	Total loss 2.538 (2.316)
Epoch: [13][185/200]	Time 0.732 (0.789)	Total loss 2.162 (2.314)
Epoch: [13][190/200]	Time 0.767 (0.788)	Total loss 2.589 (2.317)
Epoch: [13][195/200]	Time 0.881 (0.793)	Total loss 2.192 (2.314)
Epoch: [13][200/200]	Time 0.736 (0.792)	Total loss 2.473 (2.315)
==> start training epoch 14 	 ==> learning rate = 0.00035
Epoch: [14][5/200]	Time 0.743 (0.797)	Total loss 1.868 (2.223)
Epoch: [14][10/200]	Time 0.759 (0.780)	Total loss 2.460 (2.249)
Epoch: [14][15/200]	Time 0.736 (0.776)	Total loss 2.663 (2.321)
Epoch: [14][20/200]	Time 0.734 (0.774)	Total loss 2.393 (2.317)
Epoch: [14][25/200]	Time 0.740 (0.806)	Total loss 2.362 (2.309)
Epoch: [14][30/200]	Time 0.749 (0.825)	Total loss 2.006 (2.306)
Epoch: [14][35/200]	Time 0.747 (0.818)	Total loss 2.396 (2.312)
Epoch: [14][40/200]	Time 0.841 (0.815)	Total loss 2.023 (2.297)
Epoch: [14][45/200]	Time 0.810 (0.811)	Total loss 2.736 (2.297)
Epoch: [14][50/200]	Time 0.735 (0.805)	Total loss 2.262 (2.298)
Epoch: [14][55/200]	Time 0.823 (0.802)	Total loss 2.058 (2.293)
Epoch: [14][60/200]	Time 0.817 (0.802)	Total loss 2.227 (2.281)
Epoch: [14][65/200]	Time 0.869 (0.800)	Total loss 2.151 (2.283)
Epoch: [14][70/200]	Time 0.764 (0.798)	Total loss 2.140 (2.276)
Epoch: [14][75/200]	Time 0.742 (0.796)	Total loss 2.155 (2.266)
Epoch: [14][80/200]	Time 0.743 (0.793)	Total loss 2.064 (2.263)
Epoch: [14][85/200]	Time 0.774 (0.800)	Total loss 2.089 (2.255)
Epoch: [14][90/200]	Time 0.768 (0.800)	Total loss 2.238 (2.256)
Epoch: [14][95/200]	Time 0.751 (0.798)	Total loss 2.283 (2.258)
Epoch: [14][100/200]	Time 0.740 (0.797)	Total loss 2.080 (2.259)
Epoch: [14][105/200]	Time 0.765 (0.796)	Total loss 2.125 (2.251)
Epoch: [14][110/200]	Time 0.821 (0.795)	Total loss 2.115 (2.247)
Epoch: [14][115/200]	Time 0.896 (0.803)	Total loss 2.615 (2.248)
Epoch: [14][120/200]	Time 0.750 (0.801)	Total loss 2.238 (2.246)
Epoch: [14][125/200]	Time 0.791 (0.801)	Total loss 2.214 (2.250)
Epoch: [14][130/200]	Time 0.779 (0.800)	Total loss 2.433 (2.255)
Epoch: [14][135/200]	Time 0.721 (0.798)	Total loss 2.097 (2.253)
Epoch: [14][140/200]	Time 0.756 (0.803)	Total loss 2.438 (2.256)
Epoch: [14][145/200]	Time 0.819 (0.803)	Total loss 2.551 (2.258)
Epoch: [14][150/200]	Time 0.864 (0.803)	Total loss 2.338 (2.255)
Epoch: [14][155/200]	Time 0.745 (0.802)	Total loss 2.063 (2.249)
Epoch: [14][160/200]	Time 0.765 (0.801)	Total loss 1.990 (2.249)
Epoch: [14][165/200]	Time 0.755 (0.800)	Total loss 2.544 (2.253)
Epoch: [14][170/200]	Time 0.763 (0.799)	Total loss 2.367 (2.257)
Epoch: [14][175/200]	Time 0.759 (0.798)	Total loss 2.377 (2.255)
Epoch: [14][180/200]	Time 0.736 (0.803)	Total loss 2.274 (2.252)
Epoch: [14][185/200]	Time 0.874 (0.802)	Total loss 2.064 (2.255)
Epoch: [14][190/200]	Time 0.797 (0.801)	Total loss 2.129 (2.251)
Epoch: [14][195/200]	Time 0.784 (0.800)	Total loss 2.311 (2.250)
Epoch: [14][200/200]	Time 0.740 (0.799)	Total loss 1.995 (2.249)
==> start training epoch 15 	 ==> learning rate = 0.00035
Epoch: [15][5/200]	Time 0.770 (0.980)	Total loss 2.272 (2.292)
Epoch: [15][10/200]	Time 0.878 (0.885)	Total loss 2.318 (2.228)
Epoch: [15][15/200]	Time 0.754 (0.837)	Total loss 2.435 (2.246)
Epoch: [15][20/200]	Time 0.742 (0.820)	Total loss 2.229 (2.247)
Epoch: [15][25/200]	Time 0.783 (0.808)	Total loss 2.183 (2.239)
Epoch: [15][30/200]	Time 0.729 (0.801)	Total loss 2.215 (2.229)
Epoch: [15][35/200]	Time 0.747 (0.795)	Total loss 2.123 (2.228)
Epoch: [15][40/200]	Time 0.783 (0.794)	Total loss 2.164 (2.209)
Epoch: [15][45/200]	Time 0.827 (0.793)	Total loss 2.267 (2.224)
Epoch: [15][50/200]	Time 0.793 (0.789)	Total loss 2.369 (2.230)
Epoch: [15][55/200]	Time 0.774 (0.804)	Total loss 2.304 (2.231)
Epoch: [15][60/200]	Time 0.822 (0.803)	Total loss 2.253 (2.237)
Epoch: [15][65/200]	Time 0.759 (0.801)	Total loss 1.716 (2.221)
Epoch: [15][70/200]	Time 1.554 (0.809)	Total loss 1.812 (2.215)
Epoch: [15][75/200]	Time 0.764 (0.807)	Total loss 1.953 (2.217)
Epoch: [15][80/200]	Time 0.880 (0.806)	Total loss 2.311 (2.222)
Epoch: [15][85/200]	Time 0.740 (0.802)	Total loss 2.170 (2.223)
Epoch: [15][90/200]	Time 0.773 (0.801)	Total loss 2.011 (2.214)
Epoch: [15][95/200]	Time 1.613 (0.808)	Total loss 2.175 (2.212)
Epoch: [15][100/200]	Time 0.774 (0.807)	Total loss 1.898 (2.208)
Epoch: [15][105/200]	Time 0.724 (0.804)	Total loss 2.384 (2.206)
Epoch: [15][110/200]	Time 0.809 (0.804)	Total loss 2.195 (2.204)
Epoch: [15][115/200]	Time 0.843 (0.803)	Total loss 1.823 (2.202)
Epoch: [15][120/200]	Time 0.791 (0.801)	Total loss 2.278 (2.199)
Epoch: [15][125/200]	Time 0.762 (0.800)	Total loss 2.327 (2.205)
Epoch: [15][130/200]	Time 0.742 (0.799)	Total loss 2.295 (2.209)
Epoch: [15][135/200]	Time 0.763 (0.799)	Total loss 2.247 (2.210)
Epoch: [15][140/200]	Time 0.778 (0.798)	Total loss 2.008 (2.206)
Epoch: [15][145/200]	Time 0.742 (0.797)	Total loss 2.153 (2.214)
Epoch: [15][150/200]	Time 0.785 (0.797)	Total loss 2.123 (2.216)
Epoch: [15][155/200]	Time 0.723 (0.796)	Total loss 1.965 (2.214)
Epoch: [15][160/200]	Time 0.733 (0.795)	Total loss 2.086 (2.213)
Epoch: [15][165/200]	Time 1.580 (0.803)	Total loss 2.105 (2.211)
Epoch: [15][170/200]	Time 0.744 (0.801)	Total loss 2.091 (2.209)
Epoch: [15][175/200]	Time 0.852 (0.801)	Total loss 2.274 (2.209)
Epoch: [15][180/200]	Time 0.728 (0.799)	Total loss 1.899 (2.208)
Epoch: [15][185/200]	Time 0.726 (0.798)	Total loss 2.154 (2.205)
Epoch: [15][190/200]	Time 0.784 (0.802)	Total loss 2.162 (2.205)
Epoch: [15][195/200]	Time 0.720 (0.801)	Total loss 2.169 (2.206)
Epoch: [15][200/200]	Time 0.729 (0.799)	Total loss 2.213 (2.209)
==> start training epoch 16 	 ==> learning rate = 0.00035
Epoch: [16][5/200]	Time 0.755 (0.810)	Total loss 2.167 (2.108)
Epoch: [16][10/200]	Time 0.836 (0.795)	Total loss 2.049 (2.174)
Epoch: [16][15/200]	Time 0.773 (0.792)	Total loss 1.899 (2.105)
Epoch: [16][20/200]	Time 0.774 (0.793)	Total loss 2.280 (2.097)
Epoch: [16][25/200]	Time 0.757 (0.786)	Total loss 2.258 (2.116)
Epoch: [16][30/200]	Time 0.842 (0.788)	Total loss 2.075 (2.115)
Epoch: [16][35/200]	Time 0.919 (0.788)	Total loss 2.369 (2.145)
Epoch: [16][40/200]	Time 0.748 (0.783)	Total loss 1.969 (2.150)
Epoch: [16][45/200]	Time 0.723 (0.782)	Total loss 2.162 (2.148)
Epoch: [16][50/200]	Time 0.765 (0.781)	Total loss 1.906 (2.148)
Epoch: [16][55/200]	Time 0.748 (0.779)	Total loss 2.201 (2.156)
Epoch: [16][60/200]	Time 0.774 (0.790)	Total loss 2.238 (2.148)
Epoch: [16][65/200]	Time 0.744 (0.790)	Total loss 2.146 (2.148)
Epoch: [16][70/200]	Time 0.751 (0.790)	Total loss 2.187 (2.151)
Epoch: [16][75/200]	Time 0.774 (0.787)	Total loss 2.116 (2.155)
Epoch: [16][80/200]	Time 0.775 (0.807)	Total loss 2.142 (2.156)
Epoch: [16][85/200]	Time 0.792 (0.803)	Total loss 2.378 (2.160)
Epoch: [16][90/200]	Time 0.756 (0.802)	Total loss 1.852 (2.153)
Epoch: [16][95/200]	Time 0.746 (0.800)	Total loss 2.412 (2.157)
Epoch: [16][100/200]	Time 0.768 (0.797)	Total loss 2.082 (2.154)
Epoch: [16][105/200]	Time 0.803 (0.797)	Total loss 2.147 (2.148)
Epoch: [16][110/200]	Time 0.800 (0.796)	Total loss 1.894 (2.149)
Epoch: [16][115/200]	Time 0.770 (0.796)	Total loss 2.603 (2.155)
Epoch: [16][120/200]	Time 0.863 (0.795)	Total loss 1.943 (2.156)
Epoch: [16][125/200]	Time 0.770 (0.794)	Total loss 2.240 (2.155)
Epoch: [16][130/200]	Time 0.789 (0.794)	Total loss 2.265 (2.152)
Epoch: [16][135/200]	Time 0.756 (0.792)	Total loss 2.252 (2.152)
Epoch: [16][140/200]	Time 0.724 (0.792)	Total loss 2.096 (2.157)
Epoch: [16][145/200]	Time 0.833 (0.790)	Total loss 2.162 (2.159)
Epoch: [16][150/200]	Time 0.753 (0.794)	Total loss 2.220 (2.156)
Epoch: [16][155/200]	Time 0.728 (0.794)	Total loss 2.221 (2.155)
Epoch: [16][160/200]	Time 0.744 (0.792)	Total loss 1.916 (2.151)
Epoch: [16][165/200]	Time 0.731 (0.791)	Total loss 1.997 (2.154)
Epoch: [16][170/200]	Time 0.847 (0.795)	Total loss 2.335 (2.156)
Epoch: [16][175/200]	Time 0.754 (0.794)	Total loss 2.415 (2.158)
Epoch: [16][180/200]	Time 0.753 (0.793)	Total loss 1.924 (2.155)
Epoch: [16][185/200]	Time 0.744 (0.792)	Total loss 2.357 (2.159)
Epoch: [16][190/200]	Time 0.770 (0.792)	Total loss 2.095 (2.158)
Epoch: [16][195/200]	Time 0.773 (0.795)	Total loss 2.011 (2.156)
Epoch: [16][200/200]	Time 0.727 (0.794)	Total loss 2.279 (2.153)
==> start training epoch 17 	 ==> learning rate = 0.00035
Epoch: [17][5/200]	Time 0.753 (0.768)	Total loss 2.394 (2.232)
Epoch: [17][10/200]	Time 0.745 (0.769)	Total loss 2.206 (2.204)
Epoch: [17][15/200]	Time 0.736 (0.773)	Total loss 2.082 (2.198)
Epoch: [17][20/200]	Time 0.751 (0.766)	Total loss 2.049 (2.213)
Epoch: [17][25/200]	Time 0.738 (0.774)	Total loss 1.860 (2.194)
Epoch: [17][30/200]	Time 0.785 (0.774)	Total loss 2.095 (2.192)
Epoch: [17][35/200]	Time 0.732 (0.772)	Total loss 2.034 (2.174)
Epoch: [17][40/200]	Time 0.837 (0.773)	Total loss 2.558 (2.177)
Epoch: [17][45/200]	Time 0.759 (0.788)	Total loss 2.246 (2.185)
Epoch: [17][50/200]	Time 0.728 (0.789)	Total loss 2.276 (2.183)
Epoch: [17][55/200]	Time 0.740 (0.784)	Total loss 2.323 (2.180)
Epoch: [17][60/200]	Time 0.751 (0.797)	Total loss 1.755 (2.175)
Epoch: [17][65/200]	Time 0.810 (0.794)	Total loss 1.875 (2.166)
Epoch: [17][70/200]	Time 0.745 (0.792)	Total loss 2.004 (2.174)
Epoch: [17][75/200]	Time 0.730 (0.791)	Total loss 2.463 (2.179)
Epoch: [17][80/200]	Time 0.767 (0.790)	Total loss 2.339 (2.182)
Epoch: [17][85/200]	Time 0.743 (0.790)	Total loss 2.092 (2.178)
Epoch: [17][90/200]	Time 0.747 (0.789)	Total loss 2.277 (2.185)
Epoch: [17][95/200]	Time 0.748 (0.788)	Total loss 2.305 (2.186)
Epoch: [17][100/200]	Time 0.841 (0.787)	Total loss 2.236 (2.183)
Epoch: [17][105/200]	Time 0.744 (0.792)	Total loss 2.407 (2.181)
Epoch: [17][110/200]	Time 0.747 (0.791)	Total loss 2.099 (2.184)
Epoch: [17][115/200]	Time 0.732 (0.789)	Total loss 2.021 (2.180)
Epoch: [17][120/200]	Time 0.745 (0.788)	Total loss 1.906 (2.172)
Epoch: [17][125/200]	Time 0.854 (0.788)	Total loss 2.058 (2.173)
Epoch: [17][130/200]	Time 0.732 (0.786)	Total loss 2.207 (2.174)
Epoch: [17][135/200]	Time 1.523 (0.791)	Total loss 2.398 (2.173)
Epoch: [17][140/200]	Time 0.769 (0.790)	Total loss 1.869 (2.171)
Epoch: [17][145/200]	Time 0.783 (0.790)	Total loss 2.045 (2.164)
Epoch: [17][150/200]	Time 1.731 (0.796)	Total loss 2.097 (2.164)
Epoch: [17][155/200]	Time 0.730 (0.795)	Total loss 2.056 (2.163)
Epoch: [17][160/200]	Time 0.745 (0.794)	Total loss 2.408 (2.162)
Epoch: [17][165/200]	Time 0.747 (0.793)	Total loss 1.945 (2.160)
Epoch: [17][170/200]	Time 0.727 (0.792)	Total loss 2.232 (2.158)
Epoch: [17][175/200]	Time 0.771 (0.790)	Total loss 2.281 (2.161)
Epoch: [17][180/200]	Time 0.749 (0.790)	Total loss 2.111 (2.159)
Epoch: [17][185/200]	Time 0.749 (0.789)	Total loss 2.150 (2.157)
Epoch: [17][190/200]	Time 0.744 (0.788)	Total loss 2.130 (2.154)
Epoch: [17][195/200]	Time 0.749 (0.788)	Total loss 2.272 (2.157)
Epoch: [17][200/200]	Time 0.751 (0.787)	Total loss 1.901 (2.155)
==> start training epoch 18 	 ==> learning rate = 0.00035
Epoch: [18][5/200]	Time 0.749 (0.791)	Total loss 2.054 (2.133)
Epoch: [18][10/200]	Time 0.825 (0.777)	Total loss 2.113 (2.130)
Epoch: [18][15/200]	Time 0.752 (0.768)	Total loss 2.288 (2.124)
Epoch: [18][20/200]	Time 0.798 (0.814)	Total loss 1.714 (2.100)
Epoch: [18][25/200]	Time 0.740 (0.798)	Total loss 1.897 (2.127)
Epoch: [18][30/200]	Time 0.731 (0.818)	Total loss 1.825 (2.102)
Epoch: [18][35/200]	Time 0.747 (0.808)	Total loss 2.268 (2.113)
Epoch: [18][40/200]	Time 0.751 (0.805)	Total loss 2.001 (2.093)
Epoch: [18][45/200]	Time 0.744 (0.824)	Total loss 2.151 (2.091)
Epoch: [18][50/200]	Time 0.773 (0.817)	Total loss 1.925 (2.091)
Epoch: [18][55/200]	Time 0.770 (0.813)	Total loss 1.930 (2.081)
Epoch: [18][60/200]	Time 0.750 (0.808)	Total loss 2.040 (2.084)
Epoch: [18][65/200]	Time 0.773 (0.806)	Total loss 1.951 (2.077)
Epoch: [18][70/200]	Time 0.874 (0.805)	Total loss 2.306 (2.085)
Epoch: [18][75/200]	Time 0.795 (0.801)	Total loss 2.389 (2.098)
Epoch: [18][80/200]	Time 0.755 (0.800)	Total loss 2.294 (2.102)
Epoch: [18][85/200]	Time 0.755 (0.797)	Total loss 2.632 (2.116)
Epoch: [18][90/200]	Time 0.774 (0.798)	Total loss 2.256 (2.106)
Epoch: [18][95/200]	Time 0.846 (0.797)	Total loss 1.961 (2.099)
Epoch: [18][100/200]	Time 0.784 (0.796)	Total loss 2.124 (2.096)
Epoch: [18][105/200]	Time 0.806 (0.797)	Total loss 1.691 (2.091)
Epoch: [18][110/200]	Time 0.773 (0.796)	Total loss 2.145 (2.094)
Epoch: [18][115/200]	Time 0.748 (0.795)	Total loss 2.072 (2.090)
Epoch: [18][120/200]	Time 0.755 (0.793)	Total loss 2.161 (2.098)
Epoch: [18][125/200]	Time 0.770 (0.799)	Total loss 1.801 (2.095)
Epoch: [18][130/200]	Time 1.624 (0.804)	Total loss 1.943 (2.089)
Epoch: [18][135/200]	Time 0.828 (0.811)	Total loss 1.990 (2.087)
Epoch: [18][140/200]	Time 0.797 (0.810)	Total loss 2.277 (2.085)
Epoch: [18][145/200]	Time 0.754 (0.808)	Total loss 1.943 (2.083)
Epoch: [18][150/200]	Time 0.768 (0.807)	Total loss 1.887 (2.080)
Epoch: [18][155/200]	Time 0.861 (0.806)	Total loss 2.278 (2.081)
Epoch: [18][160/200]	Time 0.748 (0.806)	Total loss 2.254 (2.080)
Epoch: [18][165/200]	Time 0.727 (0.805)	Total loss 1.899 (2.079)
Epoch: [18][170/200]	Time 0.766 (0.803)	Total loss 1.801 (2.076)
Epoch: [18][175/200]	Time 0.756 (0.803)	Total loss 1.946 (2.078)
Epoch: [18][180/200]	Time 0.909 (0.803)	Total loss 2.170 (2.077)
Epoch: [18][185/200]	Time 0.775 (0.802)	Total loss 2.192 (2.080)
Epoch: [18][190/200]	Time 0.782 (0.802)	Total loss 1.784 (2.077)
Epoch: [18][195/200]	Time 0.757 (0.800)	Total loss 2.224 (2.076)
Epoch: [18][200/200]	Time 0.762 (0.800)	Total loss 2.413 (2.077)
==> start training epoch 19 	 ==> learning rate = 0.00035
Epoch: [19][5/200]	Time 0.759 (0.805)	Total loss 2.289 (2.122)
Epoch: [19][10/200]	Time 0.736 (0.780)	Total loss 1.930 (2.106)
Epoch: [19][15/200]	Time 0.766 (0.831)	Total loss 2.103 (2.084)
Epoch: [19][20/200]	Time 0.780 (0.812)	Total loss 1.989 (2.096)
Epoch: [19][25/200]	Time 0.788 (0.850)	Total loss 2.009 (2.096)
Epoch: [19][30/200]	Time 0.753 (0.835)	Total loss 2.038 (2.090)
Epoch: [19][35/200]	Time 0.753 (0.830)	Total loss 2.164 (2.086)
Epoch: [19][40/200]	Time 0.733 (0.823)	Total loss 2.072 (2.086)
Epoch: [19][45/200]	Time 0.790 (0.836)	Total loss 1.929 (2.080)
Epoch: [19][50/200]	Time 0.740 (0.830)	Total loss 2.131 (2.088)
Epoch: [19][55/200]	Time 0.763 (0.825)	Total loss 1.722 (2.077)
Epoch: [19][60/200]	Time 0.750 (0.823)	Total loss 2.084 (2.084)
Epoch: [19][65/200]	Time 0.890 (0.820)	Total loss 1.996 (2.083)
Epoch: [19][70/200]	Time 0.798 (0.817)	Total loss 1.990 (2.075)
Epoch: [19][75/200]	Time 0.779 (0.815)	Total loss 1.875 (2.065)
Epoch: [19][80/200]	Time 0.786 (0.813)	Total loss 1.950 (2.070)
Epoch: [19][85/200]	Time 0.766 (0.813)	Total loss 2.185 (2.072)
Epoch: [19][90/200]	Time 0.852 (0.813)	Total loss 2.097 (2.070)
Epoch: [19][95/200]	Time 0.763 (0.810)	Total loss 1.965 (2.060)
Epoch: [19][100/200]	Time 0.735 (0.808)	Total loss 2.308 (2.058)
Epoch: [19][105/200]	Time 0.716 (0.805)	Total loss 1.810 (2.063)
Epoch: [19][110/200]	Time 0.734 (0.811)	Total loss 2.102 (2.069)
Epoch: [19][115/200]	Time 0.775 (0.818)	Total loss 1.891 (2.062)
Epoch: [19][120/200]	Time 0.811 (0.817)	Total loss 1.895 (2.061)
Epoch: [19][125/200]	Time 0.849 (0.815)	Total loss 2.434 (2.059)
Epoch: [19][130/200]	Time 0.775 (0.813)	Total loss 2.140 (2.062)
Epoch: [19][135/200]	Time 0.736 (0.812)	Total loss 2.270 (2.066)
Epoch: [19][140/200]	Time 0.832 (0.811)	Total loss 1.769 (2.063)
Epoch: [19][145/200]	Time 0.790 (0.811)	Total loss 2.242 (2.063)
Epoch: [19][150/200]	Time 0.863 (0.810)	Total loss 2.484 (2.063)
Epoch: [19][155/200]	Time 0.750 (0.809)	Total loss 1.994 (2.063)
Epoch: [19][160/200]	Time 0.777 (0.814)	Total loss 1.573 (2.057)
Epoch: [19][165/200]	Time 0.786 (0.813)	Total loss 2.211 (2.055)
Epoch: [19][170/200]	Time 0.776 (0.812)	Total loss 2.234 (2.057)
Epoch: [19][175/200]	Time 0.749 (0.811)	Total loss 2.023 (2.057)
Epoch: [19][180/200]	Time 0.796 (0.811)	Total loss 2.178 (2.057)
Epoch: [19][185/200]	Time 0.884 (0.810)	Total loss 2.224 (2.054)
Epoch: [19][190/200]	Time 0.785 (0.809)	Total loss 2.090 (2.056)
Epoch: [19][195/200]	Time 0.731 (0.808)	Total loss 2.172 (2.059)
Epoch: [19][200/200]	Time 1.592 (0.811)	Total loss 1.538 (2.057)
==> start training epoch 20 	 ==> learning rate = 0.00035
Epoch: [20][5/200]	Time 1.834 (1.043)	Total loss 2.514 (2.160)
Epoch: [20][10/200]	Time 0.787 (0.904)	Total loss 2.270 (2.176)
Epoch: [20][15/200]	Time 0.782 (0.875)	Total loss 2.116 (2.090)
Epoch: [20][20/200]	Time 0.789 (0.857)	Total loss 2.150 (2.091)
Epoch: [20][25/200]	Time 0.799 (0.844)	Total loss 1.916 (2.061)
Epoch: [20][30/200]	Time 0.726 (0.828)	Total loss 2.018 (2.056)
Epoch: [20][35/200]	Time 0.750 (0.820)	Total loss 2.327 (2.065)
Epoch: [20][40/200]	Time 0.775 (0.815)	Total loss 1.956 (2.066)
Epoch: [20][45/200]	Time 0.884 (0.814)	Total loss 2.010 (2.078)
Epoch: [20][50/200]	Time 0.789 (0.810)	Total loss 2.220 (2.080)
Epoch: [20][55/200]	Time 0.726 (0.808)	Total loss 1.915 (2.081)
Epoch: [20][60/200]	Time 0.752 (0.804)	Total loss 2.117 (2.079)
Epoch: [20][65/200]	Time 0.791 (0.803)	Total loss 1.786 (2.073)
Epoch: [20][70/200]	Time 0.895 (0.813)	Total loss 2.106 (2.062)
Epoch: [20][75/200]	Time 0.756 (0.809)	Total loss 1.999 (2.057)
Epoch: [20][80/200]	Time 0.772 (0.808)	Total loss 2.142 (2.053)
Epoch: [20][85/200]	Time 0.755 (0.806)	Total loss 1.842 (2.054)
Epoch: [20][90/200]	Time 0.749 (0.804)	Total loss 2.027 (2.052)
Epoch: [20][95/200]	Time 0.755 (0.810)	Total loss 2.006 (2.052)
Epoch: [20][100/200]	Time 0.742 (0.818)	Total loss 2.044 (2.045)
Epoch: [20][105/200]	Time 0.748 (0.816)	Total loss 2.156 (2.048)
Epoch: [20][110/200]	Time 0.753 (0.815)	Total loss 2.441 (2.050)
Epoch: [20][115/200]	Time 0.741 (0.812)	Total loss 2.029 (2.047)
Epoch: [20][120/200]	Time 0.765 (0.810)	Total loss 2.299 (2.050)
Epoch: [20][125/200]	Time 0.770 (0.810)	Total loss 2.150 (2.054)
Epoch: [20][130/200]	Time 0.893 (0.810)	Total loss 1.635 (2.052)
Epoch: [20][135/200]	Time 0.739 (0.808)	Total loss 2.223 (2.051)
Epoch: [20][140/200]	Time 0.783 (0.808)	Total loss 2.671 (2.052)
Epoch: [20][145/200]	Time 0.781 (0.807)	Total loss 1.893 (2.052)
Epoch: [20][150/200]	Time 0.797 (0.807)	Total loss 2.027 (2.052)
Epoch: [20][155/200]	Time 0.747 (0.805)	Total loss 2.307 (2.056)
Epoch: [20][160/200]	Time 0.755 (0.805)	Total loss 1.954 (2.055)
Epoch: [20][165/200]	Time 0.745 (0.804)	Total loss 1.742 (2.054)
Epoch: [20][170/200]	Time 0.783 (0.803)	Total loss 2.097 (2.053)
Epoch: [20][175/200]	Time 0.773 (0.802)	Total loss 2.069 (2.054)
Epoch: [20][180/200]	Time 0.740 (0.801)	Total loss 2.343 (2.056)
Epoch: [20][185/200]	Time 0.755 (0.805)	Total loss 1.943 (2.056)
Epoch: [20][190/200]	Time 0.857 (0.813)	Total loss 1.916 (2.054)
Epoch: [20][195/200]	Time 0.786 (0.813)	Total loss 1.890 (2.052)
Epoch: [20][200/200]	Time 0.748 (0.813)	Total loss 1.792 (2.046)
==> start training epoch 21 	 ==> learning rate = 0.00035
Epoch: [21][5/200]	Time 0.798 (0.800)	Total loss 1.889 (1.950)
Epoch: [21][10/200]	Time 0.762 (0.787)	Total loss 2.150 (2.017)
Epoch: [21][15/200]	Time 0.773 (0.778)	Total loss 2.224 (2.035)
Epoch: [21][20/200]	Time 0.744 (0.777)	Total loss 2.000 (2.052)
Epoch: [21][25/200]	Time 0.844 (0.774)	Total loss 2.148 (2.056)
Epoch: [21][30/200]	Time 0.759 (0.769)	Total loss 1.973 (2.053)
Epoch: [21][35/200]	Time 0.743 (0.769)	Total loss 1.761 (2.056)
Epoch: [21][40/200]	Time 0.759 (0.766)	Total loss 1.710 (2.053)
Epoch: [21][45/200]	Time 0.768 (0.768)	Total loss 2.325 (2.057)
Epoch: [21][50/200]	Time 0.804 (0.768)	Total loss 2.123 (2.053)
Epoch: [21][55/200]	Time 0.791 (0.771)	Total loss 2.251 (2.065)
Epoch: [21][60/200]	Time 0.760 (0.772)	Total loss 2.357 (2.080)
Epoch: [21][65/200]	Time 0.807 (0.772)	Total loss 1.903 (2.075)
Epoch: [21][70/200]	Time 0.730 (0.772)	Total loss 2.347 (2.077)
Epoch: [21][75/200]	Time 0.733 (0.769)	Total loss 2.050 (2.076)
Epoch: [21][80/200]	Time 0.770 (0.790)	Total loss 2.080 (2.073)
Epoch: [21][85/200]	Time 0.867 (0.790)	Total loss 2.084 (2.073)
Epoch: [21][90/200]	Time 0.788 (0.788)	Total loss 1.784 (2.064)
Epoch: [21][95/200]	Time 1.591 (0.796)	Total loss 1.902 (2.057)
Epoch: [21][100/200]	Time 0.735 (0.795)	Total loss 1.721 (2.059)
Epoch: [21][105/200]	Time 0.803 (0.795)	Total loss 2.346 (2.061)
Epoch: [21][110/200]	Time 0.769 (0.795)	Total loss 1.866 (2.051)
Epoch: [21][115/200]	Time 0.752 (0.794)	Total loss 1.727 (2.048)
Epoch: [21][120/200]	Time 0.759 (0.794)	Total loss 1.975 (2.046)
Epoch: [21][125/200]	Time 0.744 (0.793)	Total loss 1.882 (2.045)
Epoch: [21][130/200]	Time 0.793 (0.792)	Total loss 1.545 (2.037)
Epoch: [21][135/200]	Time 0.895 (0.792)	Total loss 2.013 (2.033)
Epoch: [21][140/200]	Time 0.771 (0.792)	Total loss 2.185 (2.037)
Epoch: [21][145/200]	Time 0.824 (0.792)	Total loss 2.144 (2.036)
Epoch: [21][150/200]	Time 0.759 (0.791)	Total loss 1.657 (2.031)
Epoch: [21][155/200]	Time 0.770 (0.791)	Total loss 2.253 (2.031)
Epoch: [21][160/200]	Time 0.898 (0.791)	Total loss 1.841 (2.027)
Epoch: [21][165/200]	Time 0.738 (0.790)	Total loss 1.644 (2.021)
Epoch: [21][170/200]	Time 0.741 (0.795)	Total loss 1.722 (2.017)
Epoch: [21][175/200]	Time 0.830 (0.799)	Total loss 2.154 (2.016)
Epoch: [21][180/200]	Time 0.732 (0.799)	Total loss 2.299 (2.015)
Epoch: [21][185/200]	Time 0.765 (0.799)	Total loss 1.914 (2.014)
Epoch: [21][190/200]	Time 0.733 (0.799)	Total loss 2.066 (2.017)
Epoch: [21][195/200]	Time 0.757 (0.799)	Total loss 2.094 (2.017)
Epoch: [21][200/200]	Time 0.738 (0.798)	Total loss 2.126 (2.015)
==> start training epoch 22 	 ==> learning rate = 0.00035
Epoch: [22][5/200]	Time 0.728 (0.810)	Total loss 2.044 (2.116)
Epoch: [22][10/200]	Time 0.780 (0.874)	Total loss 1.977 (1.994)
Epoch: [22][15/200]	Time 0.769 (0.848)	Total loss 2.094 (1.938)
Epoch: [22][20/200]	Time 0.901 (0.841)	Total loss 1.823 (1.943)
Epoch: [22][25/200]	Time 0.750 (0.826)	Total loss 2.293 (1.959)
Epoch: [22][30/200]	Time 0.773 (0.821)	Total loss 1.851 (1.948)
Epoch: [22][35/200]	Time 0.740 (0.810)	Total loss 2.057 (1.963)
Epoch: [22][40/200]	Time 0.746 (0.804)	Total loss 1.828 (1.954)
Epoch: [22][45/200]	Time 0.951 (0.802)	Total loss 1.821 (1.944)
Epoch: [22][50/200]	Time 0.755 (0.798)	Total loss 1.912 (1.937)
Epoch: [22][55/200]	Time 0.799 (0.798)	Total loss 2.148 (1.928)
Epoch: [22][60/200]	Time 1.589 (0.809)	Total loss 2.109 (1.927)
Epoch: [22][65/200]	Time 1.578 (0.820)	Total loss 2.046 (1.933)
Epoch: [22][70/200]	Time 0.921 (0.820)	Total loss 1.898 (1.940)
Epoch: [22][75/200]	Time 0.761 (0.815)	Total loss 1.823 (1.937)
Epoch: [22][80/200]	Time 0.714 (0.813)	Total loss 1.957 (1.938)
Epoch: [22][85/200]	Time 0.733 (0.809)	Total loss 2.152 (1.943)
Epoch: [22][90/200]	Time 0.722 (0.808)	Total loss 2.261 (1.944)
Epoch: [22][95/200]	Time 0.737 (0.804)	Total loss 1.852 (1.937)
Epoch: [22][100/200]	Time 0.744 (0.802)	Total loss 2.023 (1.935)
Epoch: [22][105/200]	Time 0.743 (0.803)	Total loss 2.004 (1.931)
Epoch: [22][110/200]	Time 0.749 (0.800)	Total loss 1.840 (1.936)
Epoch: [22][115/200]	Time 0.764 (0.799)	Total loss 2.079 (1.935)
Epoch: [22][120/200]	Time 0.728 (0.797)	Total loss 1.936 (1.937)
Epoch: [22][125/200]	Time 0.722 (0.806)	Total loss 2.045 (1.934)
Epoch: [22][130/200]	Time 0.772 (0.805)	Total loss 1.767 (1.935)
Epoch: [22][135/200]	Time 0.782 (0.803)	Total loss 1.722 (1.930)
Epoch: [22][140/200]	Time 0.795 (0.802)	Total loss 2.012 (1.932)
Epoch: [22][145/200]	Time 0.750 (0.800)	Total loss 1.967 (1.931)
Epoch: [22][150/200]	Time 0.739 (0.799)	Total loss 1.731 (1.928)
Epoch: [22][155/200]	Time 0.918 (0.805)	Total loss 1.793 (1.930)
Epoch: [22][160/200]	Time 0.791 (0.811)	Total loss 2.133 (1.934)
Epoch: [22][165/200]	Time 0.911 (0.810)	Total loss 1.964 (1.935)
Epoch: [22][170/200]	Time 0.819 (0.809)	Total loss 1.641 (1.933)
Epoch: [22][175/200]	Time 0.742 (0.809)	Total loss 1.995 (1.932)
Epoch: [22][180/200]	Time 0.797 (0.808)	Total loss 1.792 (1.933)
Epoch: [22][185/200]	Time 0.775 (0.807)	Total loss 1.713 (1.933)
Epoch: [22][190/200]	Time 0.778 (0.806)	Total loss 1.793 (1.934)
Epoch: [22][195/200]	Time 0.728 (0.805)	Total loss 2.103 (1.936)
Epoch: [22][200/200]	Time 0.842 (0.804)	Total loss 1.866 (1.938)
==> start training epoch 23 	 ==> learning rate = 0.00035
Epoch: [23][5/200]	Time 0.724 (0.778)	Total loss 2.349 (2.131)
Epoch: [23][10/200]	Time 0.733 (0.763)	Total loss 2.261 (2.109)
Epoch: [23][15/200]	Time 0.756 (0.759)	Total loss 1.982 (2.059)
Epoch: [23][20/200]	Time 0.752 (0.764)	Total loss 1.651 (1.999)
Epoch: [23][25/200]	Time 0.771 (0.762)	Total loss 1.954 (1.999)
Epoch: [23][30/200]	Time 0.745 (0.762)	Total loss 2.182 (2.008)
Epoch: [23][35/200]	Time 0.752 (0.794)	Total loss 1.690 (1.986)
Epoch: [23][40/200]	Time 0.743 (0.787)	Total loss 1.893 (1.987)
Epoch: [23][45/200]	Time 0.774 (0.810)	Total loss 1.782 (1.976)
Epoch: [23][50/200]	Time 0.728 (0.805)	Total loss 1.782 (1.963)
Epoch: [23][55/200]	Time 0.754 (0.822)	Total loss 2.112 (1.970)
Epoch: [23][60/200]	Time 0.735 (0.816)	Total loss 2.272 (1.962)
Epoch: [23][65/200]	Time 0.754 (0.813)	Total loss 1.668 (1.953)
Epoch: [23][70/200]	Time 0.745 (0.812)	Total loss 1.865 (1.944)
Epoch: [23][75/200]	Time 0.764 (0.808)	Total loss 1.892 (1.946)
Epoch: [23][80/200]	Time 0.735 (0.807)	Total loss 1.810 (1.947)
Epoch: [23][85/200]	Time 0.815 (0.804)	Total loss 2.376 (1.949)
Epoch: [23][90/200]	Time 0.756 (0.803)	Total loss 2.098 (1.954)
Epoch: [23][95/200]	Time 0.826 (0.801)	Total loss 2.117 (1.952)
Epoch: [23][100/200]	Time 0.753 (0.799)	Total loss 1.904 (1.950)
Epoch: [23][105/200]	Time 0.760 (0.798)	Total loss 1.809 (1.945)
Epoch: [23][110/200]	Time 0.770 (0.796)	Total loss 1.934 (1.949)
Epoch: [23][115/200]	Time 0.777 (0.796)	Total loss 2.146 (1.953)
Epoch: [23][120/200]	Time 0.772 (0.794)	Total loss 2.151 (1.959)
Epoch: [23][125/200]	Time 0.740 (0.793)	Total loss 2.079 (1.964)
Epoch: [23][130/200]	Time 0.756 (0.792)	Total loss 1.758 (1.959)
Epoch: [23][135/200]	Time 0.776 (0.799)	Total loss 1.985 (1.960)
Epoch: [23][140/200]	Time 0.736 (0.797)	Total loss 2.202 (1.956)
Epoch: [23][145/200]	Time 0.851 (0.802)	Total loss 2.032 (1.957)
Epoch: [23][150/200]	Time 0.766 (0.807)	Total loss 1.896 (1.961)
Epoch: [23][155/200]	Time 0.752 (0.807)	Total loss 2.318 (1.957)
Epoch: [23][160/200]	Time 0.795 (0.806)	Total loss 1.892 (1.955)
Epoch: [23][165/200]	Time 0.769 (0.805)	Total loss 2.093 (1.956)
Epoch: [23][170/200]	Time 0.754 (0.803)	Total loss 1.794 (1.955)
Epoch: [23][175/200]	Time 0.755 (0.803)	Total loss 1.870 (1.954)
Epoch: [23][180/200]	Time 0.838 (0.802)	Total loss 2.169 (1.957)
Epoch: [23][185/200]	Time 0.784 (0.802)	Total loss 1.825 (1.955)
Epoch: [23][190/200]	Time 0.754 (0.801)	Total loss 2.073 (1.955)
Epoch: [23][195/200]	Time 0.745 (0.800)	Total loss 1.954 (1.959)
Epoch: [23][200/200]	Time 0.760 (0.799)	Total loss 1.869 (1.958)
==> start training epoch 24 	 ==> learning rate = 0.00035
Epoch: [24][5/200]	Time 0.865 (0.807)	Total loss 1.855 (1.998)
Epoch: [24][10/200]	Time 0.752 (0.777)	Total loss 1.971 (1.990)
Epoch: [24][15/200]	Time 0.750 (0.781)	Total loss 2.047 (1.965)
Epoch: [24][20/200]	Time 0.731 (0.769)	Total loss 2.040 (1.971)
Epoch: [24][25/200]	Time 0.735 (0.804)	Total loss 2.164 (1.940)
Epoch: [24][30/200]	Time 0.747 (0.797)	Total loss 2.391 (1.963)
Epoch: [24][35/200]	Time 0.733 (0.794)	Total loss 2.010 (1.964)
Epoch: [24][40/200]	Time 0.850 (0.812)	Total loss 1.735 (1.944)
Epoch: [24][45/200]	Time 0.781 (0.808)	Total loss 2.013 (1.945)
Epoch: [24][50/200]	Time 0.779 (0.806)	Total loss 2.212 (1.955)
Epoch: [24][55/200]	Time 0.768 (0.800)	Total loss 1.917 (1.948)
Epoch: [24][60/200]	Time 1.637 (0.812)	Total loss 1.923 (1.955)
Epoch: [24][65/200]	Time 0.763 (0.808)	Total loss 1.713 (1.957)
Epoch: [24][70/200]	Time 0.751 (0.803)	Total loss 1.925 (1.952)
Epoch: [24][75/200]	Time 0.768 (0.803)	Total loss 2.140 (1.958)
Epoch: [24][80/200]	Time 0.736 (0.800)	Total loss 1.717 (1.949)
Epoch: [24][85/200]	Time 0.748 (0.799)	Total loss 1.921 (1.948)
Epoch: [24][90/200]	Time 0.750 (0.797)	Total loss 1.780 (1.942)
Epoch: [24][95/200]	Time 0.791 (0.797)	Total loss 1.950 (1.938)
Epoch: [24][100/200]	Time 0.727 (0.795)	Total loss 1.813 (1.942)
Epoch: [24][105/200]	Time 0.760 (0.793)	Total loss 1.925 (1.941)
Epoch: [24][110/200]	Time 0.751 (0.793)	Total loss 1.426 (1.936)
Epoch: [24][115/200]	Time 1.701 (0.800)	Total loss 2.135 (1.937)
Epoch: [24][120/200]	Time 0.743 (0.799)	Total loss 1.741 (1.936)
Epoch: [24][125/200]	Time 0.746 (0.797)	Total loss 1.894 (1.935)
Epoch: [24][130/200]	Time 1.578 (0.803)	Total loss 2.013 (1.938)
Epoch: [24][135/200]	Time 0.791 (0.802)	Total loss 2.217 (1.937)
Epoch: [24][140/200]	Time 0.775 (0.802)	Total loss 2.095 (1.934)
Epoch: [24][145/200]	Time 0.885 (0.801)	Total loss 2.111 (1.934)
Epoch: [24][150/200]	Time 0.774 (0.801)	Total loss 2.047 (1.936)
Epoch: [24][155/200]	Time 0.781 (0.801)	Total loss 2.016 (1.939)
Epoch: [24][160/200]	Time 0.784 (0.800)	Total loss 1.928 (1.938)
Epoch: [24][165/200]	Time 0.771 (0.800)	Total loss 2.174 (1.937)
Epoch: [24][170/200]	Time 0.771 (0.798)	Total loss 2.104 (1.938)
Epoch: [24][175/200]	Time 0.774 (0.803)	Total loss 1.924 (1.940)
Epoch: [24][180/200]	Time 0.924 (0.804)	Total loss 1.887 (1.936)
Epoch: [24][185/200]	Time 0.788 (0.803)	Total loss 1.955 (1.935)
Epoch: [24][190/200]	Time 0.807 (0.804)	Total loss 2.312 (1.940)
Epoch: [24][195/200]	Time 0.774 (0.803)	Total loss 1.752 (1.937)
Epoch: [24][200/200]	Time 0.764 (0.803)	Total loss 1.664 (1.935)
==> start training epoch 25 	 ==> learning rate = 0.00035
Epoch: [25][5/200]	Time 0.888 (0.797)	Total loss 2.084 (2.073)
Epoch: [25][10/200]	Time 0.759 (0.865)	Total loss 1.669 (1.945)
Epoch: [25][15/200]	Time 0.739 (0.839)	Total loss 1.951 (1.911)
Epoch: [25][20/200]	Time 0.776 (0.824)	Total loss 1.737 (1.928)
Epoch: [25][25/200]	Time 0.782 (0.850)	Total loss 1.905 (1.956)
Epoch: [25][30/200]	Time 0.719 (0.832)	Total loss 1.757 (1.954)
Epoch: [25][35/200]	Time 0.778 (0.826)	Total loss 2.128 (1.959)
Epoch: [25][40/200]	Time 0.809 (0.823)	Total loss 1.739 (1.961)
Epoch: [25][45/200]	Time 0.770 (0.817)	Total loss 1.676 (1.954)
Epoch: [25][50/200]	Time 0.774 (0.813)	Total loss 1.764 (1.945)
Epoch: [25][55/200]	Time 0.754 (0.808)	Total loss 2.199 (1.936)
Epoch: [25][60/200]	Time 0.784 (0.807)	Total loss 2.107 (1.936)
Epoch: [25][65/200]	Time 0.886 (0.807)	Total loss 1.982 (1.944)
Epoch: [25][70/200]	Time 0.740 (0.804)	Total loss 2.093 (1.946)
Epoch: [25][75/200]	Time 0.756 (0.804)	Total loss 1.508 (1.935)
Epoch: [25][80/200]	Time 0.765 (0.801)	Total loss 1.614 (1.929)
Epoch: [25][85/200]	Time 0.753 (0.801)	Total loss 1.776 (1.927)
Epoch: [25][90/200]	Time 0.745 (0.809)	Total loss 1.615 (1.923)
Epoch: [25][95/200]	Time 0.805 (0.808)	Total loss 1.830 (1.925)
Epoch: [25][100/200]	Time 0.793 (0.816)	Total loss 1.558 (1.926)
Epoch: [25][105/200]	Time 0.770 (0.815)	Total loss 1.924 (1.930)
Epoch: [25][110/200]	Time 0.735 (0.813)	Total loss 2.280 (1.934)
Epoch: [25][115/200]	Time 0.734 (0.810)	Total loss 1.949 (1.929)
Epoch: [25][120/200]	Time 0.849 (0.817)	Total loss 1.961 (1.928)
Epoch: [25][125/200]	Time 0.885 (0.816)	Total loss 1.898 (1.929)
Epoch: [25][130/200]	Time 0.787 (0.815)	Total loss 2.006 (1.931)
Epoch: [25][135/200]	Time 0.749 (0.813)	Total loss 1.920 (1.930)
Epoch: [25][140/200]	Time 0.769 (0.812)	Total loss 1.833 (1.929)
Epoch: [25][145/200]	Time 0.764 (0.811)	Total loss 1.801 (1.935)
Epoch: [25][150/200]	Time 0.851 (0.810)	Total loss 2.242 (1.932)
Epoch: [25][155/200]	Time 0.781 (0.810)	Total loss 1.903 (1.933)
Epoch: [25][160/200]	Time 0.788 (0.809)	Total loss 1.625 (1.934)
Epoch: [25][165/200]	Time 0.749 (0.808)	Total loss 1.967 (1.936)
Epoch: [25][170/200]	Time 0.774 (0.808)	Total loss 2.057 (1.939)
Epoch: [25][175/200]	Time 0.768 (0.807)	Total loss 2.025 (1.943)
Epoch: [25][180/200]	Time 0.764 (0.806)	Total loss 1.982 (1.939)
Epoch: [25][185/200]	Time 0.734 (0.805)	Total loss 1.550 (1.932)
Epoch: [25][190/200]	Time 0.799 (0.809)	Total loss 1.902 (1.930)
Epoch: [25][195/200]	Time 0.753 (0.808)	Total loss 1.778 (1.929)
Epoch: [25][200/200]	Time 0.792 (0.811)	Total loss 1.856 (1.927)
==> start training epoch 26 	 ==> learning rate = 0.00035
Epoch: [26][5/200]	Time 0.730 (0.790)	Total loss 2.215 (2.043)
Epoch: [26][10/200]	Time 0.765 (0.864)	Total loss 2.179 (2.037)
Epoch: [26][15/200]	Time 0.776 (0.844)	Total loss 2.141 (1.982)
Epoch: [26][20/200]	Time 0.774 (0.830)	Total loss 1.756 (1.938)
Epoch: [26][25/200]	Time 0.732 (0.814)	Total loss 2.312 (1.951)
Epoch: [26][30/200]	Time 0.783 (0.810)	Total loss 1.842 (1.940)
Epoch: [26][35/200]	Time 0.767 (0.803)	Total loss 1.769 (1.938)
Epoch: [26][40/200]	Time 0.768 (0.800)	Total loss 1.773 (1.918)
Epoch: [26][45/200]	Time 0.872 (0.799)	Total loss 1.990 (1.930)
Epoch: [26][50/200]	Time 0.746 (0.795)	Total loss 2.035 (1.924)
Epoch: [26][55/200]	Time 0.778 (0.796)	Total loss 1.882 (1.915)
Epoch: [26][60/200]	Time 0.805 (0.794)	Total loss 1.842 (1.915)
Epoch: [26][65/200]	Time 0.755 (0.793)	Total loss 2.125 (1.914)
Epoch: [26][70/200]	Time 0.835 (0.792)	Total loss 1.712 (1.906)
Epoch: [26][75/200]	Time 0.800 (0.792)	Total loss 1.833 (1.911)
Epoch: [26][80/200]	Time 0.790 (0.805)	Total loss 1.811 (1.905)
Epoch: [26][85/200]	Time 0.765 (0.803)	Total loss 1.680 (1.895)
Epoch: [26][90/200]	Time 0.774 (0.802)	Total loss 2.039 (1.906)
Epoch: [26][95/200]	Time 0.733 (0.800)	Total loss 2.098 (1.913)
Epoch: [26][100/200]	Time 0.749 (0.799)	Total loss 2.098 (1.915)
Epoch: [26][105/200]	Time 0.795 (0.806)	Total loss 1.488 (1.910)
Epoch: [26][110/200]	Time 0.753 (0.804)	Total loss 1.922 (1.910)
Epoch: [26][115/200]	Time 0.896 (0.811)	Total loss 1.723 (1.907)
Epoch: [26][120/200]	Time 0.746 (0.809)	Total loss 2.043 (1.902)
Epoch: [26][125/200]	Time 0.759 (0.808)	Total loss 1.823 (1.897)
Epoch: [26][130/200]	Time 0.761 (0.807)	Total loss 2.043 (1.901)
Epoch: [26][135/200]	Time 0.773 (0.806)	Total loss 1.791 (1.899)
Epoch: [26][140/200]	Time 0.904 (0.806)	Total loss 1.967 (1.900)
Epoch: [26][145/200]	Time 0.758 (0.805)	Total loss 1.765 (1.897)
Epoch: [26][150/200]	Time 0.753 (0.805)	Total loss 1.810 (1.895)
Epoch: [26][155/200]	Time 0.745 (0.803)	Total loss 1.915 (1.896)
Epoch: [26][160/200]	Time 0.807 (0.803)	Total loss 1.654 (1.894)
Epoch: [26][165/200]	Time 0.767 (0.803)	Total loss 1.941 (1.895)
Epoch: [26][170/200]	Time 1.673 (0.808)	Total loss 2.095 (1.897)
Epoch: [26][175/200]	Time 0.778 (0.807)	Total loss 2.018 (1.897)
Epoch: [26][180/200]	Time 0.838 (0.806)	Total loss 2.424 (1.899)
Epoch: [26][185/200]	Time 0.765 (0.806)	Total loss 1.861 (1.899)
Epoch: [26][190/200]	Time 0.756 (0.806)	Total loss 2.078 (1.900)
Epoch: [26][195/200]	Time 1.624 (0.810)	Total loss 1.782 (1.900)
Epoch: [26][200/200]	Time 0.745 (0.809)	Total loss 1.872 (1.897)
==> start training epoch 27 	 ==> learning rate = 0.00035
Epoch: [27][5/200]	Time 0.784 (0.838)	Total loss 1.771 (1.816)
Epoch: [27][10/200]	Time 0.759 (0.815)	Total loss 1.952 (1.872)
Epoch: [27][15/200]	Time 0.781 (0.800)	Total loss 2.015 (1.902)
Epoch: [27][20/200]	Time 0.767 (0.789)	Total loss 1.863 (1.905)
Epoch: [27][25/200]	Time 1.562 (0.814)	Total loss 1.848 (1.896)
Epoch: [27][30/200]	Time 0.817 (0.815)	Total loss 1.776 (1.876)
Epoch: [27][35/200]	Time 0.881 (0.817)	Total loss 1.861 (1.882)
Epoch: [27][40/200]	Time 0.786 (0.814)	Total loss 1.825 (1.887)
Epoch: [27][45/200]	Time 0.752 (0.811)	Total loss 1.665 (1.877)
Epoch: [27][50/200]	Time 0.775 (0.807)	Total loss 2.287 (1.877)
Epoch: [27][55/200]	Time 0.803 (0.806)	Total loss 1.796 (1.874)
Epoch: [27][60/200]	Time 0.757 (0.804)	Total loss 1.800 (1.876)
Epoch: [27][65/200]	Time 0.753 (0.818)	Total loss 1.796 (1.864)
Epoch: [27][70/200]	Time 0.807 (0.818)	Total loss 1.945 (1.856)
Epoch: [27][75/200]	Time 0.758 (0.815)	Total loss 2.146 (1.856)
Epoch: [27][80/200]	Time 0.779 (0.813)	Total loss 1.730 (1.858)
Epoch: [27][85/200]	Time 0.774 (0.809)	Total loss 1.884 (1.856)
Epoch: [27][90/200]	Time 0.758 (0.818)	Total loss 1.729 (1.853)
Epoch: [27][95/200]	Time 0.883 (0.816)	Total loss 1.652 (1.847)
Epoch: [27][100/200]	Time 0.782 (0.813)	Total loss 1.677 (1.840)
Epoch: [27][105/200]	Time 0.775 (0.812)	Total loss 2.002 (1.844)
Epoch: [27][110/200]	Time 0.757 (0.810)	Total loss 1.863 (1.847)
Epoch: [27][115/200]	Time 0.785 (0.810)	Total loss 2.006 (1.846)
Epoch: [27][120/200]	Time 0.742 (0.808)	Total loss 1.800 (1.851)
Epoch: [27][125/200]	Time 0.757 (0.807)	Total loss 1.860 (1.848)
Epoch: [27][130/200]	Time 0.753 (0.806)	Total loss 1.916 (1.849)
Epoch: [27][135/200]	Time 0.759 (0.804)	Total loss 1.882 (1.847)
Epoch: [27][140/200]	Time 0.778 (0.811)	Total loss 2.049 (1.848)
Epoch: [27][145/200]	Time 0.737 (0.810)	Total loss 1.857 (1.845)
Epoch: [27][150/200]	Time 0.785 (0.809)	Total loss 1.936 (1.844)
Epoch: [27][155/200]	Time 0.897 (0.815)	Total loss 1.891 (1.843)
Epoch: [27][160/200]	Time 0.790 (0.814)	Total loss 1.847 (1.848)
Epoch: [27][165/200]	Time 0.747 (0.813)	Total loss 1.913 (1.850)
Epoch: [27][170/200]	Time 0.764 (0.811)	Total loss 2.062 (1.852)
Epoch: [27][175/200]	Time 0.724 (0.810)	Total loss 1.699 (1.849)
Epoch: [27][180/200]	Time 0.755 (0.808)	Total loss 1.974 (1.849)
Epoch: [27][185/200]	Time 0.804 (0.812)	Total loss 2.010 (1.848)
Epoch: [27][190/200]	Time 0.788 (0.812)	Total loss 1.615 (1.845)
Epoch: [27][195/200]	Time 0.766 (0.811)	Total loss 1.755 (1.847)
Epoch: [27][200/200]	Time 0.780 (0.810)	Total loss 1.907 (1.847)
==> start training epoch 28 	 ==> learning rate = 0.00035
Epoch: [28][5/200]	Time 0.818 (0.778)	Total loss 1.991 (1.870)
Epoch: [28][10/200]	Time 0.744 (0.764)	Total loss 1.945 (1.833)
Epoch: [28][15/200]	Time 0.765 (0.773)	Total loss 1.855 (1.835)
Epoch: [28][20/200]	Time 0.789 (0.773)	Total loss 2.013 (1.799)
Epoch: [28][25/200]	Time 0.733 (0.779)	Total loss 2.202 (1.842)
Epoch: [28][30/200]	Time 0.768 (0.779)	Total loss 1.701 (1.846)
Epoch: [28][35/200]	Time 0.756 (0.780)	Total loss 2.080 (1.851)
Epoch: [28][40/200]	Time 0.932 (0.783)	Total loss 1.774 (1.848)
Epoch: [28][45/200]	Time 0.767 (0.802)	Total loss 1.825 (1.850)
Epoch: [28][50/200]	Time 0.772 (0.800)	Total loss 1.736 (1.841)
Epoch: [28][55/200]	Time 0.753 (0.813)	Total loss 1.590 (1.834)
Epoch: [28][60/200]	Time 0.747 (0.811)	Total loss 1.833 (1.834)
Epoch: [28][65/200]	Time 0.812 (0.810)	Total loss 1.850 (1.836)
Epoch: [28][70/200]	Time 0.833 (0.811)	Total loss 2.230 (1.843)
Epoch: [28][75/200]	Time 0.807 (0.822)	Total loss 1.722 (1.841)
Epoch: [28][80/200]	Time 0.815 (0.819)	Total loss 1.710 (1.839)
Epoch: [28][85/200]	Time 0.806 (0.818)	Total loss 1.991 (1.840)
Epoch: [28][90/200]	Time 0.721 (0.814)	Total loss 1.828 (1.840)
Epoch: [28][95/200]	Time 0.812 (0.813)	Total loss 2.190 (1.844)
Epoch: [28][100/200]	Time 0.889 (0.814)	Total loss 1.837 (1.841)
Epoch: [28][105/200]	Time 0.736 (0.811)	Total loss 1.623 (1.840)
Epoch: [28][110/200]	Time 0.750 (0.812)	Total loss 1.799 (1.837)
Epoch: [28][115/200]	Time 0.759 (0.811)	Total loss 1.922 (1.834)
Epoch: [28][120/200]	Time 0.789 (0.811)	Total loss 2.031 (1.839)
Epoch: [28][125/200]	Time 0.874 (0.810)	Total loss 1.821 (1.839)
Epoch: [28][130/200]	Time 0.762 (0.809)	Total loss 1.637 (1.832)
Epoch: [28][135/200]	Time 0.893 (0.815)	Total loss 1.761 (1.828)
Epoch: [28][140/200]	Time 0.753 (0.813)	Total loss 1.502 (1.821)
Epoch: [28][145/200]	Time 0.749 (0.812)	Total loss 1.756 (1.819)
Epoch: [28][150/200]	Time 0.735 (0.812)	Total loss 1.853 (1.818)
Epoch: [28][155/200]	Time 0.830 (0.812)	Total loss 1.651 (1.815)
Epoch: [28][160/200]	Time 0.845 (0.812)	Total loss 1.834 (1.814)
Epoch: [28][165/200]	Time 0.761 (0.816)	Total loss 1.697 (1.819)
Epoch: [28][170/200]	Time 0.732 (0.820)	Total loss 1.712 (1.815)
Epoch: [28][175/200]	Time 0.771 (0.818)	Total loss 1.619 (1.813)
Epoch: [28][180/200]	Time 0.748 (0.817)	Total loss 1.789 (1.808)
Epoch: [28][185/200]	Time 0.760 (0.816)	Total loss 2.142 (1.811)
Epoch: [28][190/200]	Time 0.761 (0.815)	Total loss 1.678 (1.811)
Epoch: [28][195/200]	Time 0.822 (0.815)	Total loss 1.702 (1.810)
Epoch: [28][200/200]	Time 0.778 (0.813)	Total loss 1.828 (1.810)
==> start training epoch 29 	 ==> learning rate = 0.00035
Epoch: [29][5/200]	Time 0.761 (0.816)	Total loss 1.575 (1.748)
Epoch: [29][10/200]	Time 0.776 (0.800)	Total loss 1.641 (1.785)
Epoch: [29][15/200]	Time 0.756 (0.784)	Total loss 2.019 (1.823)
Epoch: [29][20/200]	Time 0.861 (0.787)	Total loss 1.820 (1.835)
Epoch: [29][25/200]	Time 1.659 (0.815)	Total loss 1.917 (1.833)
Epoch: [29][30/200]	Time 0.754 (0.811)	Total loss 1.890 (1.827)
Epoch: [29][35/200]	Time 0.749 (0.805)	Total loss 1.928 (1.816)
Epoch: [29][40/200]	Time 0.743 (0.803)	Total loss 1.617 (1.816)
Epoch: [29][45/200]	Time 0.757 (0.798)	Total loss 1.940 (1.814)
Epoch: [29][50/200]	Time 0.784 (0.796)	Total loss 1.592 (1.815)
Epoch: [29][55/200]	Time 0.856 (0.796)	Total loss 1.841 (1.807)
Epoch: [29][60/200]	Time 1.552 (0.805)	Total loss 1.958 (1.803)
Epoch: [29][65/200]	Time 0.761 (0.804)	Total loss 1.624 (1.783)
Epoch: [29][70/200]	Time 0.794 (0.802)	Total loss 1.660 (1.789)
Epoch: [29][75/200]	Time 0.761 (0.801)	Total loss 1.988 (1.795)
Epoch: [29][80/200]	Time 0.770 (0.809)	Total loss 1.695 (1.789)
Epoch: [29][85/200]	Time 0.789 (0.808)	Total loss 1.721 (1.790)
Epoch: [29][90/200]	Time 0.727 (0.805)	Total loss 1.844 (1.790)
Epoch: [29][95/200]	Time 0.820 (0.803)	Total loss 1.821 (1.793)
Epoch: [29][100/200]	Time 0.742 (0.802)	Total loss 1.711 (1.798)
Epoch: [29][105/200]	Time 0.800 (0.800)	Total loss 1.676 (1.796)
Epoch: [29][110/200]	Time 0.752 (0.799)	Total loss 1.840 (1.795)
Epoch: [29][115/200]	Time 0.878 (0.798)	Total loss 1.988 (1.801)
Epoch: [29][120/200]	Time 0.760 (0.805)	Total loss 1.987 (1.801)
Epoch: [29][125/200]	Time 0.770 (0.804)	Total loss 1.329 (1.797)
Epoch: [29][130/200]	Time 0.841 (0.803)	Total loss 1.748 (1.796)
Epoch: [29][135/200]	Time 0.761 (0.803)	Total loss 1.653 (1.792)
Epoch: [29][140/200]	Time 0.788 (0.802)	Total loss 1.845 (1.791)
Epoch: [29][145/200]	Time 0.728 (0.801)	Total loss 1.548 (1.787)
Epoch: [29][150/200]	Time 0.849 (0.800)	Total loss 1.752 (1.791)
Epoch: [29][155/200]	Time 0.790 (0.805)	Total loss 1.771 (1.792)
Epoch: [29][160/200]	Time 0.986 (0.806)	Total loss 1.749 (1.792)
Epoch: [29][165/200]	Time 0.755 (0.805)	Total loss 1.737 (1.793)
Epoch: [29][170/200]	Time 0.788 (0.805)	Total loss 2.040 (1.796)
Epoch: [29][175/200]	Time 0.765 (0.804)	Total loss 1.447 (1.795)
Epoch: [29][180/200]	Time 0.764 (0.804)	Total loss 2.129 (1.795)
Epoch: [29][185/200]	Time 0.737 (0.803)	Total loss 1.739 (1.793)
Epoch: [29][190/200]	Time 1.627 (0.807)	Total loss 1.613 (1.789)
Epoch: [29][195/200]	Time 0.762 (0.806)	Total loss 1.700 (1.787)
Epoch: [29][200/200]	Time 0.740 (0.805)	Total loss 1.625 (1.787)
Extract Features: [50/733]	Time 0.090 (0.155)	Data 0.000 (0.055)	
Extract Features: [100/733]	Time 0.121 (0.143)	Data 0.026 (0.042)	
Extract Features: [150/733]	Time 0.110 (0.140)	Data 0.000 (0.040)	
Extract Features: [200/733]	Time 0.427 (0.141)	Data 0.204 (0.041)	
Extract Features: [250/733]	Time 0.092 (0.137)	Data 0.000 (0.037)	
Extract Features: [300/733]	Time 0.150 (0.135)	Data 0.052 (0.035)	
Extract Features: [350/733]	Time 0.239 (0.134)	Data 0.144 (0.034)	
Extract Features: [400/733]	Time 0.092 (0.133)	Data 0.000 (0.032)	
Extract Features: [450/733]	Time 0.160 (0.132)	Data 0.064 (0.032)	
Extract Features: [500/733]	Time 0.107 (0.132)	Data 0.000 (0.031)	
Extract Features: [550/733]	Time 0.172 (0.131)	Data 0.075 (0.031)	
Extract Features: [600/733]	Time 0.108 (0.131)	Data 0.001 (0.031)	
Extract Features: [650/733]	Time 0.092 (0.131)	Data 0.000 (0.030)	
Extract Features: [700/733]	Time 0.090 (0.131)	Data 0.000 (0.030)	
Mean AP: 17.0%
CMC Scores:
  top-1          40.8%
  top-5          54.3%
  top-10         59.7%

 * Finished epoch  29  model mAP: 17.0%  best: 17.0% *

==> start training epoch 30 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [30][5/200]	Time 0.737 (0.810)	Total loss 1.803 (1.768)
Epoch: [30][10/200]	Time 0.746 (0.868)	Total loss 1.844 (1.719)
Epoch: [30][15/200]	Time 0.748 (0.838)	Total loss 1.730 (1.730)
Epoch: [30][20/200]	Time 0.786 (0.827)	Total loss 1.668 (1.750)
Epoch: [30][25/200]	Time 0.830 (0.815)	Total loss 1.410 (1.744)
Epoch: [30][30/200]	Time 0.735 (0.809)	Total loss 1.854 (1.733)
Epoch: [30][35/200]	Time 0.778 (0.804)	Total loss 1.581 (1.728)
Epoch: [30][40/200]	Time 0.758 (0.804)	Total loss 1.332 (1.715)
Epoch: [30][45/200]	Time 0.815 (0.799)	Total loss 1.564 (1.704)
Epoch: [30][50/200]	Time 0.792 (0.815)	Total loss 1.422 (1.687)
Epoch: [30][55/200]	Time 0.738 (0.811)	Total loss 1.788 (1.690)
Epoch: [30][60/200]	Time 0.766 (0.807)	Total loss 1.459 (1.680)
Epoch: [30][65/200]	Time 0.780 (0.806)	Total loss 1.665 (1.675)
Epoch: [30][70/200]	Time 0.871 (0.804)	Total loss 1.614 (1.669)
Epoch: [30][75/200]	Time 0.735 (0.802)	Total loss 1.476 (1.663)
Epoch: [30][80/200]	Time 0.772 (0.802)	Total loss 1.439 (1.652)
Epoch: [30][85/200]	Time 0.771 (0.799)	Total loss 1.326 (1.646)
Epoch: [30][90/200]	Time 0.741 (0.799)	Total loss 1.349 (1.646)
Epoch: [30][95/200]	Time 0.724 (0.797)	Total loss 1.459 (1.640)
Epoch: [30][100/200]	Time 0.737 (0.805)	Total loss 1.648 (1.637)
Epoch: [30][105/200]	Time 0.882 (0.811)	Total loss 1.190 (1.630)
Epoch: [30][110/200]	Time 0.796 (0.810)	Total loss 1.347 (1.615)
Epoch: [30][115/200]	Time 0.761 (0.809)	Total loss 1.456 (1.602)
Epoch: [30][120/200]	Time 0.758 (0.807)	Total loss 1.658 (1.601)
Epoch: [30][125/200]	Time 0.802 (0.807)	Total loss 1.495 (1.597)
Epoch: [30][130/200]	Time 0.831 (0.806)	Total loss 1.843 (1.588)
Epoch: [30][135/200]	Time 0.789 (0.806)	Total loss 1.517 (1.585)
Epoch: [30][140/200]	Time 0.760 (0.811)	Total loss 1.305 (1.575)
Epoch: [30][145/200]	Time 0.808 (0.810)	Total loss 1.670 (1.566)
Epoch: [30][150/200]	Time 0.748 (0.810)	Total loss 1.310 (1.555)
Epoch: [30][155/200]	Time 0.760 (0.808)	Total loss 1.677 (1.546)
Epoch: [30][160/200]	Time 0.796 (0.808)	Total loss 1.296 (1.537)
Epoch: [30][165/200]	Time 0.887 (0.807)	Total loss 1.372 (1.531)
Epoch: [30][170/200]	Time 0.752 (0.806)	Total loss 1.290 (1.524)
Epoch: [30][175/200]	Time 0.773 (0.807)	Total loss 1.435 (1.518)
Epoch: [30][180/200]	Time 0.787 (0.806)	Total loss 1.267 (1.511)
Epoch: [30][185/200]	Time 0.765 (0.805)	Total loss 1.203 (1.506)
Epoch: [30][190/200]	Time 0.884 (0.810)	Total loss 0.877 (1.499)
Epoch: [30][195/200]	Time 0.785 (0.809)	Total loss 1.255 (1.491)
Epoch: [30][200/200]	Time 0.759 (0.808)	Total loss 1.190 (1.485)
Extract Features: [50/733]	Time 0.095 (0.162)	Data 0.000 (0.062)	
Extract Features: [100/733]	Time 0.102 (0.150)	Data 0.000 (0.050)	
Extract Features: [150/733]	Time 0.091 (0.145)	Data 0.000 (0.045)	
Extract Features: [200/733]	Time 0.093 (0.141)	Data 0.000 (0.041)	
Extract Features: [250/733]	Time 0.092 (0.140)	Data 0.000 (0.040)	
Extract Features: [300/733]	Time 0.093 (0.139)	Data 0.000 (0.038)	
Extract Features: [350/733]	Time 0.092 (0.137)	Data 0.000 (0.037)	
Extract Features: [400/733]	Time 0.124 (0.136)	Data 0.028 (0.035)	
Extract Features: [450/733]	Time 0.093 (0.135)	Data 0.000 (0.035)	
Extract Features: [500/733]	Time 0.135 (0.134)	Data 0.041 (0.034)	
Extract Features: [550/733]	Time 0.093 (0.134)	Data 0.000 (0.034)	
Extract Features: [600/733]	Time 0.093 (0.134)	Data 0.000 (0.034)	
Extract Features: [650/733]	Time 0.103 (0.134)	Data 0.000 (0.034)	
Extract Features: [700/733]	Time 0.204 (0.133)	Data 0.109 (0.033)	
Mean AP: 19.6%
CMC Scores:
  top-1          44.2%
  top-5          57.8%
  top-10         63.1%

 * Finished epoch  30  model mAP: 19.6%  best: 19.6% *

==> start training epoch 31 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [31][5/200]	Time 0.780 (0.773)	Total loss 1.200 (1.266)
Epoch: [31][10/200]	Time 0.720 (0.760)	Total loss 1.342 (1.279)
Epoch: [31][15/200]	Time 0.725 (0.753)	Total loss 1.390 (1.293)
Epoch: [31][20/200]	Time 0.803 (0.809)	Total loss 1.007 (1.247)
Epoch: [31][25/200]	Time 0.761 (0.797)	Total loss 1.444 (1.264)
Epoch: [31][30/200]	Time 0.727 (0.792)	Total loss 1.084 (1.244)
Epoch: [31][35/200]	Time 0.728 (0.808)	Total loss 1.011 (1.227)
Epoch: [31][40/200]	Time 0.740 (0.802)	Total loss 1.408 (1.221)
Epoch: [31][45/200]	Time 0.868 (0.799)	Total loss 0.956 (1.228)
Epoch: [31][50/200]	Time 0.742 (0.794)	Total loss 1.210 (1.222)
Epoch: [31][55/200]	Time 0.779 (0.793)	Total loss 1.344 (1.226)
Epoch: [31][60/200]	Time 0.740 (0.789)	Total loss 1.204 (1.221)
Epoch: [31][65/200]	Time 0.720 (0.786)	Total loss 1.176 (1.221)
Epoch: [31][70/200]	Time 0.877 (0.785)	Total loss 1.442 (1.225)
Epoch: [31][75/200]	Time 0.828 (0.784)	Total loss 1.240 (1.219)
Epoch: [31][80/200]	Time 1.730 (0.795)	Total loss 1.351 (1.220)
Epoch: [31][85/200]	Time 0.794 (0.793)	Total loss 1.115 (1.219)
Epoch: [31][90/200]	Time 0.736 (0.792)	Total loss 1.462 (1.223)
Epoch: [31][95/200]	Time 0.778 (0.790)	Total loss 1.196 (1.221)
Epoch: [31][100/200]	Time 0.736 (0.789)	Total loss 1.481 (1.224)
Epoch: [31][105/200]	Time 0.839 (0.787)	Total loss 1.022 (1.224)
Epoch: [31][110/200]	Time 0.762 (0.786)	Total loss 1.173 (1.226)
Epoch: [31][115/200]	Time 0.799 (0.786)	Total loss 1.265 (1.227)
Epoch: [31][120/200]	Time 0.727 (0.785)	Total loss 0.982 (1.227)
Epoch: [31][125/200]	Time 1.682 (0.791)	Total loss 1.042 (1.227)
Epoch: [31][130/200]	Time 0.738 (0.796)	Total loss 1.636 (1.231)
Epoch: [31][135/200]	Time 0.754 (0.795)	Total loss 1.189 (1.227)
Epoch: [31][140/200]	Time 0.746 (0.795)	Total loss 1.532 (1.231)
Epoch: [31][145/200]	Time 0.772 (0.793)	Total loss 1.378 (1.233)
Epoch: [31][150/200]	Time 0.778 (0.793)	Total loss 1.214 (1.233)
Epoch: [31][155/200]	Time 0.762 (0.792)	Total loss 1.169 (1.228)
Epoch: [31][160/200]	Time 0.777 (0.793)	Total loss 1.162 (1.229)
Epoch: [31][165/200]	Time 0.732 (0.791)	Total loss 1.267 (1.228)
Epoch: [31][170/200]	Time 0.758 (0.791)	Total loss 1.055 (1.226)
Epoch: [31][175/200]	Time 0.762 (0.797)	Total loss 1.058 (1.223)
Epoch: [31][180/200]	Time 0.824 (0.796)	Total loss 1.312 (1.223)
Epoch: [31][185/200]	Time 0.763 (0.797)	Total loss 1.065 (1.222)
Epoch: [31][190/200]	Time 0.886 (0.797)	Total loss 1.199 (1.220)
Epoch: [31][195/200]	Time 0.789 (0.797)	Total loss 1.359 (1.219)
Epoch: [31][200/200]	Time 0.771 (0.798)	Total loss 1.057 (1.218)
Extract Features: [50/733]	Time 0.114 (0.165)	Data 0.000 (0.064)	
Extract Features: [100/733]	Time 0.095 (0.149)	Data 0.000 (0.048)	
Extract Features: [150/733]	Time 0.138 (0.146)	Data 0.045 (0.044)	
Extract Features: [200/733]	Time 0.092 (0.141)	Data 0.000 (0.039)	
Extract Features: [250/733]	Time 0.112 (0.139)	Data 0.000 (0.038)	
Extract Features: [300/733]	Time 0.101 (0.137)	Data 0.000 (0.036)	
Extract Features: [350/733]	Time 0.171 (0.136)	Data 0.075 (0.035)	
Extract Features: [400/733]	Time 0.098 (0.135)	Data 0.000 (0.034)	
Extract Features: [450/733]	Time 0.204 (0.135)	Data 0.097 (0.034)	
Extract Features: [500/733]	Time 0.093 (0.134)	Data 0.000 (0.034)	
Extract Features: [550/733]	Time 0.177 (0.133)	Data 0.077 (0.033)	
Extract Features: [600/733]	Time 0.092 (0.133)	Data 0.000 (0.033)	
Extract Features: [650/733]	Time 0.290 (0.133)	Data 0.189 (0.033)	
Extract Features: [700/733]	Time 0.090 (0.133)	Data 0.000 (0.033)	
Mean AP: 20.1%
CMC Scores:
  top-1          44.8%
  top-5          58.4%
  top-10         64.1%

 * Finished epoch  31  model mAP: 20.1%  best: 20.1% *

==> start training epoch 32 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [32][5/200]	Time 0.740 (0.782)	Total loss 1.328 (1.242)
Epoch: [32][10/200]	Time 0.730 (0.756)	Total loss 0.941 (1.173)
Epoch: [32][15/200]	Time 0.738 (0.750)	Total loss 1.254 (1.212)
Epoch: [32][20/200]	Time 0.758 (0.804)	Total loss 1.253 (1.236)
Epoch: [32][25/200]	Time 0.779 (0.795)	Total loss 0.879 (1.218)
Epoch: [32][30/200]	Time 0.737 (0.793)	Total loss 1.212 (1.208)
Epoch: [32][35/200]	Time 0.909 (0.791)	Total loss 1.107 (1.213)
Epoch: [32][40/200]	Time 0.769 (0.786)	Total loss 1.078 (1.194)
Epoch: [32][45/200]	Time 0.764 (0.806)	Total loss 1.073 (1.191)
Epoch: [32][50/200]	Time 0.733 (0.800)	Total loss 1.095 (1.179)
Epoch: [32][55/200]	Time 0.775 (0.799)	Total loss 0.826 (1.176)
Epoch: [32][60/200]	Time 0.753 (0.795)	Total loss 1.124 (1.179)
Epoch: [32][65/200]	Time 0.762 (0.815)	Total loss 1.294 (1.183)
Epoch: [32][70/200]	Time 0.908 (0.813)	Total loss 1.252 (1.179)
Epoch: [32][75/200]	Time 0.813 (0.810)	Total loss 1.176 (1.181)
Epoch: [32][80/200]	Time 0.831 (0.810)	Total loss 0.989 (1.179)
Epoch: [32][85/200]	Time 0.743 (0.807)	Total loss 1.298 (1.182)
Epoch: [32][90/200]	Time 0.762 (0.805)	Total loss 0.909 (1.177)
Epoch: [32][95/200]	Time 0.744 (0.804)	Total loss 1.237 (1.173)
Epoch: [32][100/200]	Time 0.750 (0.804)	Total loss 1.346 (1.174)
Epoch: [32][105/200]	Time 0.735 (0.802)	Total loss 1.177 (1.169)
Epoch: [32][110/200]	Time 0.731 (0.799)	Total loss 1.282 (1.168)
Epoch: [32][115/200]	Time 0.800 (0.807)	Total loss 1.140 (1.170)
Epoch: [32][120/200]	Time 0.733 (0.804)	Total loss 1.208 (1.169)
Epoch: [32][125/200]	Time 0.744 (0.803)	Total loss 1.322 (1.172)
Epoch: [32][130/200]	Time 0.758 (0.801)	Total loss 1.241 (1.173)
Epoch: [32][135/200]	Time 0.749 (0.800)	Total loss 1.204 (1.167)
Epoch: [32][140/200]	Time 0.854 (0.799)	Total loss 1.135 (1.163)
Epoch: [32][145/200]	Time 0.788 (0.799)	Total loss 1.223 (1.162)
Epoch: [32][150/200]	Time 0.744 (0.797)	Total loss 1.224 (1.162)
Epoch: [32][155/200]	Time 1.617 (0.807)	Total loss 1.187 (1.160)
Epoch: [32][160/200]	Time 0.731 (0.805)	Total loss 1.335 (1.161)
Epoch: [32][165/200]	Time 0.873 (0.805)	Total loss 1.275 (1.162)
Epoch: [32][170/200]	Time 0.785 (0.804)	Total loss 1.352 (1.160)
Epoch: [32][175/200]	Time 0.822 (0.804)	Total loss 1.199 (1.160)
Epoch: [32][180/200]	Time 0.745 (0.803)	Total loss 1.264 (1.160)
Epoch: [32][185/200]	Time 0.787 (0.802)	Total loss 1.118 (1.156)
Epoch: [32][190/200]	Time 0.836 (0.802)	Total loss 1.073 (1.158)
Epoch: [32][195/200]	Time 0.745 (0.801)	Total loss 0.946 (1.157)
Epoch: [32][200/200]	Time 0.748 (0.800)	Total loss 1.217 (1.159)
Extract Features: [50/733]	Time 0.090 (0.155)	Data 0.000 (0.058)	
Extract Features: [100/733]	Time 0.100 (0.143)	Data 0.000 (0.043)	
Extract Features: [150/733]	Time 0.093 (0.139)	Data 0.000 (0.040)	
Extract Features: [200/733]	Time 0.090 (0.136)	Data 0.000 (0.037)	
Extract Features: [250/733]	Time 0.101 (0.135)	Data 0.000 (0.037)	
Extract Features: [300/733]	Time 0.095 (0.134)	Data 0.000 (0.035)	
Extract Features: [350/733]	Time 0.221 (0.133)	Data 0.124 (0.034)	
Extract Features: [400/733]	Time 0.258 (0.133)	Data 0.161 (0.034)	
Extract Features: [450/733]	Time 0.092 (0.132)	Data 0.000 (0.033)	
Extract Features: [500/733]	Time 0.143 (0.131)	Data 0.038 (0.032)	
Extract Features: [550/733]	Time 0.095 (0.131)	Data 0.000 (0.032)	
Extract Features: [600/733]	Time 0.093 (0.131)	Data 0.000 (0.032)	
Extract Features: [650/733]	Time 0.093 (0.131)	Data 0.000 (0.033)	
Extract Features: [700/733]	Time 0.102 (0.131)	Data 0.000 (0.032)	
Mean AP: 19.9%
CMC Scores:
  top-1          44.7%
  top-5          58.1%
  top-10         63.9%

 * Finished epoch  32  model mAP: 19.9%  best: 20.1%

==> start training epoch 33 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [33][5/200]	Time 0.760 (0.948)	Total loss 0.922 (1.132)
Epoch: [33][10/200]	Time 0.732 (0.861)	Total loss 1.017 (1.124)
Epoch: [33][15/200]	Time 0.733 (0.820)	Total loss 0.976 (1.071)
Epoch: [33][20/200]	Time 0.754 (0.811)	Total loss 1.175 (1.097)
Epoch: [33][25/200]	Time 0.763 (0.802)	Total loss 1.074 (1.093)
Epoch: [33][30/200]	Time 0.798 (0.798)	Total loss 1.715 (1.137)
Epoch: [33][35/200]	Time 0.774 (0.794)	Total loss 0.985 (1.131)
Epoch: [33][40/200]	Time 0.790 (0.793)	Total loss 1.398 (1.138)
Epoch: [33][45/200]	Time 0.803 (0.815)	Total loss 1.107 (1.153)
Epoch: [33][50/200]	Time 0.785 (0.810)	Total loss 1.165 (1.161)
Epoch: [33][55/200]	Time 0.786 (0.810)	Total loss 1.312 (1.149)
Epoch: [33][60/200]	Time 0.781 (0.805)	Total loss 1.283 (1.153)
Epoch: [33][65/200]	Time 0.785 (0.803)	Total loss 1.031 (1.149)
Epoch: [33][70/200]	Time 0.738 (0.813)	Total loss 1.122 (1.145)
Epoch: [33][75/200]	Time 0.757 (0.809)	Total loss 1.235 (1.144)
Epoch: [33][80/200]	Time 0.761 (0.810)	Total loss 1.367 (1.141)
Epoch: [33][85/200]	Time 0.745 (0.807)	Total loss 0.961 (1.131)
Epoch: [33][90/200]	Time 0.734 (0.806)	Total loss 1.334 (1.136)
Epoch: [33][95/200]	Time 0.864 (0.804)	Total loss 1.389 (1.141)
Epoch: [33][100/200]	Time 0.737 (0.810)	Total loss 1.139 (1.142)
Epoch: [33][105/200]	Time 0.737 (0.810)	Total loss 0.986 (1.140)
Epoch: [33][110/200]	Time 0.801 (0.809)	Total loss 0.984 (1.137)
Epoch: [33][115/200]	Time 0.762 (0.809)	Total loss 1.149 (1.133)
Epoch: [33][120/200]	Time 0.857 (0.808)	Total loss 1.107 (1.132)
Epoch: [33][125/200]	Time 0.766 (0.806)	Total loss 1.104 (1.132)
Epoch: [33][130/200]	Time 0.743 (0.805)	Total loss 1.294 (1.132)
Epoch: [33][135/200]	Time 1.704 (0.811)	Total loss 1.051 (1.130)
Epoch: [33][140/200]	Time 0.753 (0.810)	Total loss 1.111 (1.130)
Epoch: [33][145/200]	Time 0.792 (0.810)	Total loss 1.107 (1.136)
Epoch: [33][150/200]	Time 0.735 (0.808)	Total loss 1.063 (1.132)
Epoch: [33][155/200]	Time 0.791 (0.808)	Total loss 1.336 (1.133)
Epoch: [33][160/200]	Time 0.753 (0.807)	Total loss 1.122 (1.131)
Epoch: [33][165/200]	Time 0.790 (0.806)	Total loss 1.142 (1.131)
Epoch: [33][170/200]	Time 0.753 (0.805)	Total loss 0.726 (1.126)
Epoch: [33][175/200]	Time 0.744 (0.805)	Total loss 1.166 (1.126)
Epoch: [33][180/200]	Time 0.756 (0.804)	Total loss 1.080 (1.128)
Epoch: [33][185/200]	Time 0.779 (0.807)	Total loss 1.046 (1.128)
Epoch: [33][190/200]	Time 1.640 (0.811)	Total loss 0.831 (1.122)
Epoch: [33][195/200]	Time 0.767 (0.810)	Total loss 1.416 (1.123)
Epoch: [33][200/200]	Time 0.846 (0.810)	Total loss 1.272 (1.125)
Extract Features: [50/733]	Time 0.093 (0.166)	Data 0.000 (0.062)	
Extract Features: [100/733]	Time 0.093 (0.146)	Data 0.000 (0.045)	
Extract Features: [150/733]	Time 0.168 (0.142)	Data 0.071 (0.040)	
Extract Features: [200/733]	Time 0.093 (0.139)	Data 0.000 (0.038)	
Extract Features: [250/733]	Time 0.107 (0.137)	Data 0.000 (0.036)	
Extract Features: [300/733]	Time 0.090 (0.136)	Data 0.000 (0.035)	
Extract Features: [350/733]	Time 0.129 (0.136)	Data 0.000 (0.035)	
Extract Features: [400/733]	Time 0.092 (0.136)	Data 0.000 (0.035)	
Extract Features: [450/733]	Time 0.093 (0.136)	Data 0.000 (0.035)	
Extract Features: [500/733]	Time 0.096 (0.135)	Data 0.000 (0.035)	
Extract Features: [550/733]	Time 0.093 (0.134)	Data 0.000 (0.034)	
Extract Features: [600/733]	Time 0.104 (0.134)	Data 0.000 (0.034)	
Extract Features: [650/733]	Time 0.098 (0.134)	Data 0.000 (0.034)	
Extract Features: [700/733]	Time 0.093 (0.133)	Data 0.000 (0.033)	
Mean AP: 19.7%
CMC Scores:
  top-1          44.2%
  top-5          57.9%
  top-10         63.4%

 * Finished epoch  33  model mAP: 19.7%  best: 20.1%

==> start training epoch 34 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [34][5/200]	Time 0.740 (0.770)	Total loss 1.074 (1.000)
Epoch: [34][10/200]	Time 0.733 (0.754)	Total loss 1.189 (1.093)
Epoch: [34][15/200]	Time 0.749 (0.752)	Total loss 1.377 (1.134)
Epoch: [34][20/200]	Time 0.790 (0.753)	Total loss 1.018 (1.137)
Epoch: [34][25/200]	Time 0.726 (0.758)	Total loss 1.308 (1.143)
Epoch: [34][30/200]	Time 0.793 (0.791)	Total loss 0.974 (1.152)
Epoch: [34][35/200]	Time 0.810 (0.789)	Total loss 1.062 (1.158)
Epoch: [34][40/200]	Time 0.748 (0.784)	Total loss 1.106 (1.159)
Epoch: [34][45/200]	Time 0.725 (0.782)	Total loss 1.409 (1.159)
Epoch: [34][50/200]	Time 0.750 (0.779)	Total loss 0.922 (1.157)
Epoch: [34][55/200]	Time 0.747 (0.778)	Total loss 1.413 (1.152)
Epoch: [34][60/200]	Time 0.744 (0.779)	Total loss 0.957 (1.152)
Epoch: [34][65/200]	Time 0.783 (0.779)	Total loss 1.228 (1.142)
Epoch: [34][70/200]	Time 0.722 (0.777)	Total loss 1.013 (1.132)
Epoch: [34][75/200]	Time 0.838 (0.776)	Total loss 1.020 (1.126)
Epoch: [34][80/200]	Time 0.734 (0.773)	Total loss 1.410 (1.129)
Epoch: [34][85/200]	Time 0.841 (0.784)	Total loss 1.317 (1.137)
Epoch: [34][90/200]	Time 0.740 (0.782)	Total loss 1.045 (1.134)
Epoch: [34][95/200]	Time 0.766 (0.792)	Total loss 1.056 (1.136)
Epoch: [34][100/200]	Time 0.867 (0.791)	Total loss 0.850 (1.132)
Epoch: [34][105/200]	Time 0.751 (0.790)	Total loss 1.088 (1.128)
Epoch: [34][110/200]	Time 0.754 (0.789)	Total loss 0.890 (1.122)
Epoch: [34][115/200]	Time 0.792 (0.788)	Total loss 1.096 (1.121)
Epoch: [34][120/200]	Time 0.753 (0.795)	Total loss 1.234 (1.125)
Epoch: [34][125/200]	Time 0.883 (0.794)	Total loss 1.247 (1.128)
Epoch: [34][130/200]	Time 0.779 (0.794)	Total loss 0.848 (1.125)
Epoch: [34][135/200]	Time 0.736 (0.793)	Total loss 0.823 (1.120)
Epoch: [34][140/200]	Time 0.755 (0.792)	Total loss 1.071 (1.120)
Epoch: [34][145/200]	Time 0.771 (0.793)	Total loss 0.830 (1.118)
Epoch: [34][150/200]	Time 0.744 (0.792)	Total loss 1.034 (1.114)
Epoch: [34][155/200]	Time 0.892 (0.792)	Total loss 1.251 (1.112)
Epoch: [34][160/200]	Time 0.799 (0.792)	Total loss 1.060 (1.112)
Epoch: [34][165/200]	Time 0.753 (0.792)	Total loss 1.422 (1.114)
Epoch: [34][170/200]	Time 0.763 (0.791)	Total loss 1.023 (1.116)
Epoch: [34][175/200]	Time 0.736 (0.791)	Total loss 0.998 (1.116)
Epoch: [34][180/200]	Time 0.759 (0.795)	Total loss 0.962 (1.115)
Epoch: [34][185/200]	Time 0.761 (0.794)	Total loss 1.374 (1.120)
Epoch: [34][190/200]	Time 0.802 (0.794)	Total loss 1.051 (1.118)
Epoch: [34][195/200]	Time 0.761 (0.795)	Total loss 1.054 (1.118)
Epoch: [34][200/200]	Time 0.764 (0.794)	Total loss 1.218 (1.117)
Extract Features: [50/733]	Time 0.095 (0.164)	Data 0.000 (0.061)	
Extract Features: [100/733]	Time 0.091 (0.148)	Data 0.000 (0.048)	
Extract Features: [150/733]	Time 0.248 (0.147)	Data 0.152 (0.046)	
Extract Features: [200/733]	Time 0.093 (0.142)	Data 0.000 (0.042)	
Extract Features: [250/733]	Time 0.202 (0.140)	Data 0.102 (0.039)	
Extract Features: [300/733]	Time 0.093 (0.139)	Data 0.000 (0.037)	
Extract Features: [350/733]	Time 0.124 (0.137)	Data 0.020 (0.036)	
Extract Features: [400/733]	Time 0.100 (0.137)	Data 0.000 (0.035)	
Extract Features: [450/733]	Time 0.094 (0.136)	Data 0.000 (0.034)	
Extract Features: [500/733]	Time 0.105 (0.135)	Data 0.012 (0.033)	
Extract Features: [550/733]	Time 0.092 (0.135)	Data 0.000 (0.033)	
Extract Features: [600/733]	Time 0.238 (0.134)	Data 0.131 (0.033)	
Extract Features: [650/733]	Time 0.197 (0.134)	Data 0.096 (0.033)	
Extract Features: [700/733]	Time 0.093 (0.134)	Data 0.000 (0.032)	
Mean AP: 19.9%
CMC Scores:
  top-1          44.7%
  top-5          58.2%
  top-10         64.0%

 * Finished epoch  34  model mAP: 19.9%  best: 20.1%

==> start training epoch 35 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [35][5/200]	Time 0.723 (0.760)	Total loss 1.241 (1.080)
Epoch: [35][10/200]	Time 0.753 (0.933)	Total loss 1.199 (1.079)
Epoch: [35][15/200]	Time 0.759 (0.877)	Total loss 1.289 (1.109)
Epoch: [35][20/200]	Time 0.876 (0.854)	Total loss 1.087 (1.091)
Epoch: [35][25/200]	Time 0.762 (0.835)	Total loss 1.297 (1.083)
Epoch: [35][30/200]	Time 0.736 (0.826)	Total loss 1.277 (1.085)
Epoch: [35][35/200]	Time 0.724 (0.813)	Total loss 1.074 (1.085)
Epoch: [35][40/200]	Time 0.777 (0.807)	Total loss 1.152 (1.086)
Epoch: [35][45/200]	Time 0.764 (0.805)	Total loss 1.279 (1.088)
Epoch: [35][50/200]	Time 0.735 (0.802)	Total loss 1.002 (1.080)
Epoch: [35][55/200]	Time 0.849 (0.799)	Total loss 1.092 (1.088)
Epoch: [35][60/200]	Time 0.744 (0.795)	Total loss 1.081 (1.089)
Epoch: [35][65/200]	Time 0.736 (0.791)	Total loss 1.004 (1.082)
Epoch: [35][70/200]	Time 0.757 (0.801)	Total loss 1.303 (1.089)
Epoch: [35][75/200]	Time 0.741 (0.799)	Total loss 1.184 (1.090)
Epoch: [35][80/200]	Time 0.742 (0.796)	Total loss 1.064 (1.085)
Epoch: [35][85/200]	Time 0.735 (0.795)	Total loss 0.902 (1.081)
Epoch: [35][90/200]	Time 0.768 (0.795)	Total loss 1.391 (1.086)
Epoch: [35][95/200]	Time 0.736 (0.791)	Total loss 1.016 (1.086)
Epoch: [35][100/200]	Time 0.722 (0.798)	Total loss 1.024 (1.085)
Epoch: [35][105/200]	Time 0.771 (0.796)	Total loss 0.732 (1.080)
Epoch: [35][110/200]	Time 0.752 (0.796)	Total loss 0.982 (1.079)
Epoch: [35][115/200]	Time 0.828 (0.794)	Total loss 1.160 (1.081)
Epoch: [35][120/200]	Time 1.627 (0.799)	Total loss 0.868 (1.081)
Epoch: [35][125/200]	Time 0.731 (0.799)	Total loss 1.287 (1.089)
Epoch: [35][130/200]	Time 0.742 (0.797)	Total loss 0.983 (1.093)
Epoch: [35][135/200]	Time 0.725 (0.795)	Total loss 0.848 (1.090)
Epoch: [35][140/200]	Time 0.723 (0.793)	Total loss 1.267 (1.091)
Epoch: [35][145/200]	Time 0.749 (0.791)	Total loss 1.159 (1.089)
Epoch: [35][150/200]	Time 0.835 (0.790)	Total loss 1.326 (1.089)
Epoch: [35][155/200]	Time 0.755 (0.789)	Total loss 1.082 (1.087)
Epoch: [35][160/200]	Time 0.743 (0.788)	Total loss 1.319 (1.089)
Epoch: [35][165/200]	Time 0.724 (0.792)	Total loss 0.963 (1.088)
Epoch: [35][170/200]	Time 0.768 (0.791)	Total loss 1.138 (1.085)
Epoch: [35][175/200]	Time 0.885 (0.790)	Total loss 1.032 (1.085)
Epoch: [35][180/200]	Time 0.723 (0.789)	Total loss 1.222 (1.087)
Epoch: [35][185/200]	Time 0.792 (0.788)	Total loss 0.921 (1.084)
Epoch: [35][190/200]	Time 1.657 (0.792)	Total loss 1.041 (1.083)
Epoch: [35][195/200]	Time 0.729 (0.791)	Total loss 0.994 (1.082)
Epoch: [35][200/200]	Time 0.843 (0.790)	Total loss 0.969 (1.081)
Extract Features: [50/733]	Time 0.093 (0.155)	Data 0.000 (0.057)	
Extract Features: [100/733]	Time 0.093 (0.142)	Data 0.000 (0.043)	
Extract Features: [150/733]	Time 0.114 (0.137)	Data 0.000 (0.039)	
Extract Features: [200/733]	Time 0.092 (0.135)	Data 0.000 (0.036)	
Extract Features: [250/733]	Time 0.093 (0.134)	Data 0.000 (0.035)	
Extract Features: [300/733]	Time 0.093 (0.132)	Data 0.000 (0.033)	
Extract Features: [350/733]	Time 0.186 (0.131)	Data 0.090 (0.032)	
Extract Features: [400/733]	Time 0.128 (0.130)	Data 0.032 (0.031)	
Extract Features: [450/733]	Time 0.109 (0.130)	Data 0.000 (0.031)	
Extract Features: [500/733]	Time 0.093 (0.129)	Data 0.000 (0.030)	
Extract Features: [550/733]	Time 0.090 (0.129)	Data 0.000 (0.030)	
Extract Features: [600/733]	Time 0.093 (0.129)	Data 0.000 (0.031)	
Extract Features: [650/733]	Time 0.095 (0.130)	Data 0.000 (0.031)	
Extract Features: [700/733]	Time 0.093 (0.129)	Data 0.000 (0.030)	
Mean AP: 20.4%
CMC Scores:
  top-1          45.7%
  top-5          59.0%
  top-10         64.4%

 * Finished epoch  35  model mAP: 20.4%  best: 20.4% *

==> start training epoch 36 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [36][5/200]	Time 0.734 (0.795)	Total loss 1.139 (1.050)
Epoch: [36][10/200]	Time 0.729 (0.765)	Total loss 1.034 (1.019)
Epoch: [36][15/200]	Time 0.730 (0.757)	Total loss 1.069 (1.024)
Epoch: [36][20/200]	Time 0.854 (0.764)	Total loss 1.107 (1.045)
Epoch: [36][25/200]	Time 0.726 (0.758)	Total loss 1.148 (1.049)
Epoch: [36][30/200]	Time 0.775 (0.762)	Total loss 1.058 (1.070)
Epoch: [36][35/200]	Time 0.736 (0.784)	Total loss 1.135 (1.067)
Epoch: [36][40/200]	Time 0.734 (0.784)	Total loss 0.934 (1.061)
Epoch: [36][45/200]	Time 0.733 (0.781)	Total loss 1.049 (1.058)
Epoch: [36][50/200]	Time 0.746 (0.778)	Total loss 1.032 (1.063)
Epoch: [36][55/200]	Time 1.702 (0.792)	Total loss 0.776 (1.059)
Epoch: [36][60/200]	Time 0.733 (0.790)	Total loss 0.941 (1.059)
Epoch: [36][65/200]	Time 0.757 (0.790)	Total loss 0.842 (1.052)
Epoch: [36][70/200]	Time 0.738 (0.786)	Total loss 0.983 (1.053)
Epoch: [36][75/200]	Time 0.738 (0.785)	Total loss 1.039 (1.054)
Epoch: [36][80/200]	Time 0.737 (0.782)	Total loss 0.915 (1.050)
Epoch: [36][85/200]	Time 0.753 (0.792)	Total loss 1.516 (1.053)
Epoch: [36][90/200]	Time 0.866 (0.792)	Total loss 1.174 (1.053)
Epoch: [36][95/200]	Time 0.793 (0.791)	Total loss 0.935 (1.048)
Epoch: [36][100/200]	Time 0.761 (0.791)	Total loss 0.922 (1.043)
Epoch: [36][105/200]	Time 0.764 (0.791)	Total loss 0.982 (1.045)
Epoch: [36][110/200]	Time 0.759 (0.790)	Total loss 0.840 (1.044)
Epoch: [36][115/200]	Time 0.761 (0.789)	Total loss 0.990 (1.043)
Epoch: [36][120/200]	Time 0.763 (0.787)	Total loss 1.015 (1.043)
Epoch: [36][125/200]	Time 0.739 (0.786)	Total loss 0.910 (1.041)
Epoch: [36][130/200]	Time 0.756 (0.785)	Total loss 1.135 (1.041)
Epoch: [36][135/200]	Time 0.778 (0.785)	Total loss 1.371 (1.043)
Epoch: [36][140/200]	Time 0.726 (0.783)	Total loss 0.733 (1.041)
Epoch: [36][145/200]	Time 0.726 (0.782)	Total loss 1.066 (1.043)
Epoch: [36][150/200]	Time 0.778 (0.793)	Total loss 0.927 (1.043)
Epoch: [36][155/200]	Time 0.764 (0.792)	Total loss 1.062 (1.043)
Epoch: [36][160/200]	Time 0.738 (0.791)	Total loss 0.856 (1.041)
Epoch: [36][165/200]	Time 0.745 (0.790)	Total loss 1.085 (1.041)
Epoch: [36][170/200]	Time 0.745 (0.789)	Total loss 1.160 (1.044)
Epoch: [36][175/200]	Time 0.797 (0.794)	Total loss 0.922 (1.042)
Epoch: [36][180/200]	Time 0.760 (0.794)	Total loss 0.735 (1.040)
Epoch: [36][185/200]	Time 0.791 (0.794)	Total loss 1.002 (1.039)
Epoch: [36][190/200]	Time 0.778 (0.793)	Total loss 1.103 (1.037)
Epoch: [36][195/200]	Time 0.750 (0.793)	Total loss 0.915 (1.033)
Epoch: [36][200/200]	Time 0.843 (0.792)	Total loss 1.107 (1.033)
Extract Features: [50/733]	Time 0.092 (0.156)	Data 0.000 (0.058)	
Extract Features: [100/733]	Time 0.093 (0.143)	Data 0.000 (0.044)	
Extract Features: [150/733]	Time 0.093 (0.138)	Data 0.000 (0.039)	
Extract Features: [200/733]	Time 0.093 (0.135)	Data 0.000 (0.036)	
Extract Features: [250/733]	Time 0.096 (0.134)	Data 0.000 (0.034)	
Extract Features: [300/733]	Time 0.114 (0.132)	Data 0.019 (0.033)	
Extract Features: [350/733]	Time 0.093 (0.132)	Data 0.000 (0.032)	
Extract Features: [400/733]	Time 0.124 (0.131)	Data 0.029 (0.031)	
Extract Features: [450/733]	Time 0.173 (0.130)	Data 0.063 (0.031)	
Extract Features: [500/733]	Time 0.094 (0.130)	Data 0.000 (0.031)	
Extract Features: [550/733]	Time 0.093 (0.130)	Data 0.000 (0.030)	
Extract Features: [600/733]	Time 0.096 (0.129)	Data 0.000 (0.030)	
Extract Features: [650/733]	Time 0.106 (0.130)	Data 0.000 (0.031)	
Extract Features: [700/733]	Time 0.094 (0.129)	Data 0.000 (0.030)	
Mean AP: 20.0%
CMC Scores:
  top-1          45.3%
  top-5          58.3%
  top-10         63.9%

 * Finished epoch  36  model mAP: 20.0%  best: 20.4%

==> start training epoch 37 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [37][5/200]	Time 0.800 (0.817)	Total loss 0.994 (0.965)
Epoch: [37][10/200]	Time 0.842 (0.790)	Total loss 1.172 (0.972)
Epoch: [37][15/200]	Time 0.737 (0.773)	Total loss 1.107 (0.994)
Epoch: [37][20/200]	Time 0.746 (0.772)	Total loss 1.022 (0.993)
Epoch: [37][25/200]	Time 0.738 (0.764)	Total loss 1.253 (1.020)
Epoch: [37][30/200]	Time 0.751 (0.764)	Total loss 1.137 (1.028)
Epoch: [37][35/200]	Time 0.844 (0.763)	Total loss 1.014 (1.043)
Epoch: [37][40/200]	Time 0.717 (0.759)	Total loss 1.373 (1.061)
Epoch: [37][45/200]	Time 0.729 (0.779)	Total loss 1.051 (1.054)
Epoch: [37][50/200]	Time 0.716 (0.775)	Total loss 0.887 (1.050)
Epoch: [37][55/200]	Time 0.742 (0.771)	Total loss 1.227 (1.049)
Epoch: [37][60/200]	Time 0.721 (0.782)	Total loss 1.018 (1.049)
Epoch: [37][65/200]	Time 0.752 (0.795)	Total loss 0.924 (1.046)
Epoch: [37][70/200]	Time 0.793 (0.795)	Total loss 1.173 (1.051)
Epoch: [37][75/200]	Time 0.733 (0.794)	Total loss 0.913 (1.041)
Epoch: [37][80/200]	Time 0.712 (0.791)	Total loss 0.949 (1.037)
Epoch: [37][85/200]	Time 0.721 (0.788)	Total loss 0.868 (1.036)
Epoch: [37][90/200]	Time 0.731 (0.787)	Total loss 1.161 (1.041)
Epoch: [37][95/200]	Time 0.798 (0.785)	Total loss 0.927 (1.045)
Epoch: [37][100/200]	Time 0.775 (0.784)	Total loss 0.761 (1.037)
Epoch: [37][105/200]	Time 0.741 (0.783)	Total loss 0.799 (1.037)
Epoch: [37][110/200]	Time 0.795 (0.782)	Total loss 1.004 (1.041)
Epoch: [37][115/200]	Time 0.739 (0.781)	Total loss 0.904 (1.044)
Epoch: [37][120/200]	Time 0.868 (0.781)	Total loss 0.812 (1.045)
Epoch: [37][125/200]	Time 0.749 (0.780)	Total loss 1.012 (1.048)
Epoch: [37][130/200]	Time 0.731 (0.779)	Total loss 0.983 (1.046)
Epoch: [37][135/200]	Time 0.746 (0.785)	Total loss 1.022 (1.044)
Epoch: [37][140/200]	Time 0.759 (0.784)	Total loss 0.935 (1.043)
Epoch: [37][145/200]	Time 0.834 (0.784)	Total loss 0.877 (1.042)
Epoch: [37][150/200]	Time 0.786 (0.785)	Total loss 1.178 (1.043)
Epoch: [37][155/200]	Time 0.764 (0.790)	Total loss 1.064 (1.042)
Epoch: [37][160/200]	Time 0.749 (0.789)	Total loss 0.890 (1.042)
Epoch: [37][165/200]	Time 0.742 (0.788)	Total loss 0.786 (1.041)
Epoch: [37][170/200]	Time 0.742 (0.787)	Total loss 1.117 (1.042)
Epoch: [37][175/200]	Time 0.723 (0.791)	Total loss 1.000 (1.043)
Epoch: [37][180/200]	Time 0.880 (0.791)	Total loss 0.976 (1.042)
Epoch: [37][185/200]	Time 0.720 (0.790)	Total loss 1.079 (1.040)
Epoch: [37][190/200]	Time 0.768 (0.790)	Total loss 0.903 (1.039)
Epoch: [37][195/200]	Time 0.794 (0.789)	Total loss 1.059 (1.041)
Epoch: [37][200/200]	Time 0.749 (0.789)	Total loss 1.187 (1.044)
Extract Features: [50/733]	Time 0.094 (0.157)	Data 0.000 (0.056)	
Extract Features: [100/733]	Time 0.094 (0.143)	Data 0.000 (0.044)	
Extract Features: [150/733]	Time 0.092 (0.138)	Data 0.000 (0.039)	
Extract Features: [200/733]	Time 0.093 (0.136)	Data 0.000 (0.037)	
Extract Features: [250/733]	Time 0.090 (0.135)	Data 0.000 (0.036)	
Extract Features: [300/733]	Time 0.103 (0.133)	Data 0.000 (0.034)	
Extract Features: [350/733]	Time 0.092 (0.132)	Data 0.000 (0.033)	
Extract Features: [400/733]	Time 0.127 (0.131)	Data 0.032 (0.032)	
Extract Features: [450/733]	Time 0.103 (0.131)	Data 0.000 (0.032)	
Extract Features: [500/733]	Time 0.093 (0.130)	Data 0.000 (0.031)	
Extract Features: [550/733]	Time 0.104 (0.130)	Data 0.000 (0.031)	
Extract Features: [600/733]	Time 0.092 (0.130)	Data 0.000 (0.031)	
Extract Features: [650/733]	Time 0.099 (0.130)	Data 0.000 (0.031)	
Extract Features: [700/733]	Time 0.094 (0.130)	Data 0.000 (0.031)	
