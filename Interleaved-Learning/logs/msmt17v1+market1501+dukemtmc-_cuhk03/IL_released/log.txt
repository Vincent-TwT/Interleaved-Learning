==========
Args:Namespace(dataset='cuhk03', dataset_src1='msmt17v1', dataset_src2='market1501', dataset_src3='dukemtmc', batch_size=64, test_batch_size=128, workers=4, height=256, width=128, num_instances=4, arch='resnet50', features=0, dropout=0, BNNeck=True, momentum=0.2, BNtype='sample', metaType='', margin=0.3, lr=0.00035, weight_decay=0.0005, epochs=70, iters=200, step_size=20, seed=1, print_freq=5, eval_step=1, temp=0.05, data_dir='/data3/guowei/reidData/', logs_dir='logs/Released', resume='', evaluate=False, Preprocessor='normal', back_num=1, num_camera=33, version='IL_released', training_set='mix_dataset', baseline='real', sampler='tri', style_method='UBS', style_type='', head='Memory', trainStyle=False, updateStyle=True, style_input='shuffle', style_layer='1', p=1.0, useGeM=False, with_ibn=False)
==========
==> Load datasets
Using downloaded file: /data3/guowei/reidData/msmt17/MSMT17_V1
MSMT17_V1 v1~~~ dataset loaded
  ---------------------------
  subset   | # ids | # images
  ---------------------------
  train    |  1041 |    32621
  query    |  3060 |    11659
  gallery  |  3060 |    82161
  mix      |  4101 |   126441
  ---------------------------
=> Market1501 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   751 |    12936 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  mix      |  1501 |    29419 |         6
  ----------------------------------------
This dataset has been downloaded.
=> DukeMTMC-reID loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   702 |    16522 |         8
  query    |   702 |     2228 |         8
  gallery  |  1110 |    17660 |         8
  mix      |  1812 |    36410 |         8
  ----------------------------------------
Note: if root path is changed, the previously generated json files need to be re-generated (delete them first)
Split index = 0
=> CUHK03 (detected) loaded
Dataset statistics:
  ------------------------------
  subset   | # ids | # images
  ------------------------------
  train    |   767 |     7365
  query    |   700 |     1400
  gallery  |   700 |     5332
  mix      |  1467 |    14097
  ------------------------------
  total    |  1467 |     8765
  ------------------------------
 number classes =  [4101, 1501, 1812]
 each source camera number= [15, 6, 8]
It is real baseline setting!
Using train set and test set for training!
Using triple sampler!
Using triple sampler!
Using triple sampler!
Insert style layer in  ['layer1']
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=1)
    (feat_bn0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (style): UBS(p=1.0,rho=3.0)
  )
)
Model size: 23.51213M
==> Initialize source-domain class centroids and memories 
Extract Features: [50/988]	Time 0.111 (0.675)	Data 0.000 (0.038)	
Extract Features: [100/988]	Time 0.070 (0.386)	Data 0.000 (0.033)	
Extract Features: [150/988]	Time 0.081 (0.295)	Data 0.000 (0.037)	
Extract Features: [200/988]	Time 0.063 (0.245)	Data 0.000 (0.036)	
Extract Features: [250/988]	Time 0.058 (0.218)	Data 0.000 (0.037)	
Extract Features: [300/988]	Time 0.067 (0.200)	Data 0.000 (0.038)	
Extract Features: [350/988]	Time 0.068 (0.188)	Data 0.000 (0.039)	
Extract Features: [400/988]	Time 0.166 (0.178)	Data 0.096 (0.039)	
Extract Features: [450/988]	Time 0.074 (0.168)	Data 0.000 (0.038)	
Extract Features: [500/988]	Time 0.059 (0.162)	Data 0.000 (0.037)	
Extract Features: [550/988]	Time 0.052 (0.155)	Data 0.000 (0.036)	
Extract Features: [600/988]	Time 0.060 (0.151)	Data 0.000 (0.036)	
Extract Features: [650/988]	Time 0.064 (0.148)	Data 0.000 (0.036)	
Extract Features: [700/988]	Time 0.221 (0.145)	Data 0.161 (0.036)	
Extract Features: [750/988]	Time 0.069 (0.142)	Data 0.000 (0.035)	
Extract Features: [800/988]	Time 0.101 (0.139)	Data 0.043 (0.034)	
Extract Features: [850/988]	Time 0.075 (0.138)	Data 0.000 (0.035)	
Extract Features: [900/988]	Time 0.066 (0.135)	Data 0.000 (0.034)	
Extract Features: [950/988]	Time 0.214 (0.134)	Data 0.158 (0.034)	
Extract Features: [50/230]	Time 0.060 (0.090)	Data 0.000 (0.020)	
Extract Features: [100/230]	Time 0.296 (0.082)	Data 0.001 (0.010)	
Extract Features: [150/230]	Time 0.054 (0.077)	Data 0.000 (0.007)	
Extract Features: [200/230]	Time 0.077 (0.076)	Data 0.000 (0.005)	
Extract Features: [50/285]	Time 0.058 (0.100)	Data 0.000 (0.028)	
Extract Features: [100/285]	Time 0.066 (0.087)	Data 0.000 (0.015)	
Extract Features: [150/285]	Time 0.096 (0.083)	Data 0.017 (0.011)	
Extract Features: [200/285]	Time 0.081 (0.082)	Data 0.000 (0.010)	
Extract Features: [250/285]	Time 0.059 (0.080)	Data 0.000 (0.009)	
==> start training epoch 0 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [0][5/200]	Time 0.521 (3.096)	Total loss 7.264 (7.304)
Epoch: [0][10/200]	Time 0.663 (1.827)	Total loss 7.381 (7.354)
Epoch: [0][15/200]	Time 0.470 (1.392)	Total loss 7.390 (7.348)
Epoch: [0][20/200]	Time 0.541 (1.177)	Total loss 7.334 (7.347)
Epoch: [0][25/200]	Time 0.503 (1.042)	Total loss 7.263 (7.340)
Epoch: [0][30/200]	Time 0.506 (0.957)	Total loss 7.306 (7.336)
Epoch: [0][35/200]	Time 0.500 (0.896)	Total loss 7.347 (7.330)
Epoch: [0][40/200]	Time 0.498 (0.847)	Total loss 7.305 (7.327)
Epoch: [0][45/200]	Time 0.544 (0.812)	Total loss 7.433 (7.340)
Epoch: [0][50/200]	Time 0.621 (0.785)	Total loss 7.312 (7.347)
Epoch: [0][55/200]	Time 0.479 (0.760)	Total loss 7.411 (7.352)
Epoch: [0][60/200]	Time 0.505 (0.743)	Total loss 7.480 (7.362)
Epoch: [0][65/200]	Time 0.531 (0.726)	Total loss 7.367 (7.363)
Epoch: [0][70/200]	Time 0.516 (0.713)	Total loss 7.404 (7.368)
Epoch: [0][75/200]	Time 0.515 (0.703)	Total loss 7.552 (7.380)
Epoch: [0][80/200]	Time 0.525 (0.692)	Total loss 7.397 (7.386)
Epoch: [0][85/200]	Time 0.538 (0.683)	Total loss 7.549 (7.390)
Epoch: [0][90/200]	Time 0.640 (0.674)	Total loss 7.589 (7.399)
Epoch: [0][95/200]	Time 0.525 (0.676)	Total loss 7.201 (7.401)
Epoch: [0][100/200]	Time 0.520 (0.670)	Total loss 7.361 (7.390)
Epoch: [0][105/200]	Time 0.514 (0.663)	Total loss 7.102 (7.379)
Epoch: [0][110/200]	Time 0.469 (0.657)	Total loss 7.198 (7.370)
Epoch: [0][115/200]	Time 0.511 (0.661)	Total loss 6.737 (7.355)
Epoch: [0][120/200]	Time 0.477 (0.654)	Total loss 6.690 (7.329)
Epoch: [0][125/200]	Time 0.503 (0.649)	Total loss 7.041 (7.309)
Epoch: [0][130/200]	Time 0.609 (0.644)	Total loss 6.972 (7.288)
Epoch: [0][135/200]	Time 0.517 (0.639)	Total loss 6.836 (7.267)
Epoch: [0][140/200]	Time 0.503 (0.636)	Total loss 6.811 (7.255)
Epoch: [0][145/200]	Time 0.516 (0.632)	Total loss 7.020 (7.243)
Epoch: [0][150/200]	Time 0.489 (0.628)	Total loss 6.670 (7.228)
Epoch: [0][155/200]	Time 0.495 (0.625)	Total loss 6.926 (7.214)
Epoch: [0][160/200]	Time 0.514 (0.622)	Total loss 6.881 (7.202)
Epoch: [0][165/200]	Time 0.532 (0.620)	Total loss 6.742 (7.192)
Epoch: [0][170/200]	Time 0.637 (0.618)	Total loss 6.758 (7.179)
Epoch: [0][175/200]	Time 0.500 (0.615)	Total loss 6.815 (7.170)
Epoch: [0][180/200]	Time 0.463 (0.613)	Total loss 7.096 (7.163)
Epoch: [0][185/200]	Time 0.498 (0.610)	Total loss 7.009 (7.156)
Epoch: [0][190/200]	Time 0.539 (0.614)	Total loss 6.857 (7.141)
Epoch: [0][195/200]	Time 0.504 (0.612)	Total loss 6.687 (7.127)
Epoch: [0][200/200]	Time 0.516 (0.609)	Total loss 6.457 (7.113)
==> start training epoch 1 	 ==> learning rate = 6.65e-05
Epoch: [1][5/200]	Time 0.517 (1.116)	Total loss 6.668 (6.635)
Epoch: [1][10/200]	Time 0.597 (0.815)	Total loss 6.462 (6.544)
Epoch: [1][15/200]	Time 0.499 (0.720)	Total loss 6.544 (6.581)
Epoch: [1][20/200]	Time 0.525 (0.681)	Total loss 6.716 (6.621)
Epoch: [1][25/200]	Time 0.552 (0.652)	Total loss 6.476 (6.628)
Epoch: [1][30/200]	Time 0.476 (0.677)	Total loss 6.223 (6.583)
Epoch: [1][35/200]	Time 0.548 (0.656)	Total loss 6.164 (6.542)
Epoch: [1][40/200]	Time 0.542 (0.645)	Total loss 6.312 (6.519)
Epoch: [1][45/200]	Time 0.531 (0.632)	Total loss 6.350 (6.496)
Epoch: [1][50/200]	Time 0.543 (0.621)	Total loss 6.203 (6.475)
Epoch: [1][55/200]	Time 0.516 (0.615)	Total loss 6.719 (6.462)
Epoch: [1][60/200]	Time 0.691 (0.632)	Total loss 5.772 (6.417)
Epoch: [1][65/200]	Time 0.511 (0.623)	Total loss 6.106 (6.368)
Epoch: [1][70/200]	Time 0.506 (0.618)	Total loss 5.780 (6.340)
Epoch: [1][75/200]	Time 0.514 (0.611)	Total loss 5.583 (6.303)
Epoch: [1][80/200]	Time 1.536 (0.618)	Total loss 5.719 (6.279)
Epoch: [1][85/200]	Time 0.503 (0.614)	Total loss 5.595 (6.236)
Epoch: [1][90/200]	Time 0.528 (0.611)	Total loss 5.484 (6.202)
Epoch: [1][95/200]	Time 0.518 (0.607)	Total loss 5.719 (6.177)
Epoch: [1][100/200]	Time 0.577 (0.603)	Total loss 5.681 (6.154)
Epoch: [1][105/200]	Time 0.508 (0.601)	Total loss 5.703 (6.136)
Epoch: [1][110/200]	Time 0.555 (0.599)	Total loss 5.771 (6.111)
Epoch: [1][115/200]	Time 0.493 (0.596)	Total loss 5.538 (6.088)
Epoch: [1][120/200]	Time 0.527 (0.594)	Total loss 5.890 (6.073)
Epoch: [1][125/200]	Time 0.705 (0.593)	Total loss 5.748 (6.061)
Epoch: [1][130/200]	Time 0.523 (0.590)	Total loss 5.854 (6.048)
Epoch: [1][135/200]	Time 0.513 (0.588)	Total loss 5.565 (6.029)
Epoch: [1][140/200]	Time 1.757 (0.595)	Total loss 5.295 (6.016)
Epoch: [1][145/200]	Time 0.546 (0.594)	Total loss 5.436 (5.996)
Epoch: [1][150/200]	Time 0.499 (0.592)	Total loss 5.485 (5.979)
Epoch: [1][155/200]	Time 0.519 (0.590)	Total loss 5.603 (5.963)
Epoch: [1][160/200]	Time 0.507 (0.589)	Total loss 5.467 (5.948)
Epoch: [1][165/200]	Time 0.640 (0.588)	Total loss 5.433 (5.930)
Epoch: [1][170/200]	Time 0.502 (0.585)	Total loss 5.527 (5.918)
Epoch: [1][175/200]	Time 0.512 (0.590)	Total loss 5.400 (5.903)
Epoch: [1][180/200]	Time 0.494 (0.587)	Total loss 5.277 (5.886)
Epoch: [1][185/200]	Time 0.527 (0.586)	Total loss 5.163 (5.867)
Epoch: [1][190/200]	Time 0.502 (0.585)	Total loss 5.416 (5.856)
Epoch: [1][195/200]	Time 0.524 (0.584)	Total loss 5.196 (5.841)
Epoch: [1][200/200]	Time 0.501 (0.583)	Total loss 5.615 (5.829)
==> start training epoch 2 	 ==> learning rate = 9.800000000000001e-05
Epoch: [2][5/200]	Time 0.668 (0.677)	Total loss 5.447 (5.335)
Epoch: [2][10/200]	Time 0.535 (0.600)	Total loss 5.561 (5.346)
Epoch: [2][15/200]	Time 0.553 (0.579)	Total loss 5.279 (5.386)
Epoch: [2][20/200]	Time 0.515 (0.559)	Total loss 5.511 (5.384)
Epoch: [2][25/200]	Time 0.556 (0.557)	Total loss 5.666 (5.352)
Epoch: [2][30/200]	Time 0.509 (0.557)	Total loss 5.620 (5.397)
Epoch: [2][35/200]	Time 0.509 (0.549)	Total loss 5.228 (5.392)
Epoch: [2][40/200]	Time 0.580 (0.549)	Total loss 4.826 (5.380)
Epoch: [2][45/200]	Time 0.658 (0.549)	Total loss 5.424 (5.377)
Epoch: [2][50/200]	Time 0.510 (0.547)	Total loss 5.599 (5.381)
Epoch: [2][55/200]	Time 0.517 (0.566)	Total loss 5.566 (5.378)
Epoch: [2][60/200]	Time 0.545 (0.560)	Total loss 4.800 (5.360)
Epoch: [2][65/200]	Time 0.504 (0.558)	Total loss 5.051 (5.347)
Epoch: [2][70/200]	Time 0.514 (0.573)	Total loss 4.785 (5.328)
Epoch: [2][75/200]	Time 0.559 (0.570)	Total loss 5.319 (5.317)
Epoch: [2][80/200]	Time 0.513 (0.568)	Total loss 5.165 (5.313)
Epoch: [2][85/200]	Time 0.710 (0.568)	Total loss 5.219 (5.303)
Epoch: [2][90/200]	Time 0.517 (0.565)	Total loss 5.020 (5.293)
Epoch: [2][95/200]	Time 0.527 (0.564)	Total loss 5.432 (5.293)
Epoch: [2][100/200]	Time 0.535 (0.562)	Total loss 5.064 (5.283)
Epoch: [2][105/200]	Time 0.496 (0.561)	Total loss 5.470 (5.279)
Epoch: [2][110/200]	Time 0.502 (0.560)	Total loss 4.961 (5.271)
Epoch: [2][115/200]	Time 0.540 (0.569)	Total loss 4.910 (5.258)
Epoch: [2][120/200]	Time 0.544 (0.569)	Total loss 4.712 (5.240)
Epoch: [2][125/200]	Time 0.697 (0.569)	Total loss 5.055 (5.224)
Epoch: [2][130/200]	Time 0.514 (0.567)	Total loss 4.661 (5.204)
Epoch: [2][135/200]	Time 0.528 (0.566)	Total loss 4.866 (5.188)
Epoch: [2][140/200]	Time 0.494 (0.564)	Total loss 4.478 (5.167)
Epoch: [2][145/200]	Time 0.472 (0.562)	Total loss 4.902 (5.157)
Epoch: [2][150/200]	Time 0.475 (0.560)	Total loss 4.453 (5.138)
Epoch: [2][155/200]	Time 0.477 (0.557)	Total loss 4.566 (5.123)
Epoch: [2][160/200]	Time 0.494 (0.562)	Total loss 4.811 (5.107)
Epoch: [2][165/200]	Time 0.646 (0.561)	Total loss 4.509 (5.094)
Epoch: [2][170/200]	Time 0.485 (0.566)	Total loss 4.825 (5.082)
Epoch: [2][175/200]	Time 0.490 (0.565)	Total loss 4.597 (5.067)
Epoch: [2][180/200]	Time 0.525 (0.564)	Total loss 4.257 (5.050)
Epoch: [2][185/200]	Time 0.522 (0.563)	Total loss 4.654 (5.039)
Epoch: [2][190/200]	Time 0.525 (0.563)	Total loss 4.682 (5.021)
Epoch: [2][195/200]	Time 0.507 (0.562)	Total loss 4.704 (5.009)
Epoch: [2][200/200]	Time 0.498 (0.561)	Total loss 4.683 (4.999)
==> start training epoch 3 	 ==> learning rate = 0.0001295
Epoch: [3][5/200]	Time 0.635 (1.110)	Total loss 5.228 (4.824)
Epoch: [3][10/200]	Time 0.516 (0.814)	Total loss 4.826 (4.729)
Epoch: [3][15/200]	Time 0.488 (0.727)	Total loss 4.321 (4.748)
Epoch: [3][20/200]	Time 0.568 (0.676)	Total loss 4.351 (4.694)
Epoch: [3][25/200]	Time 0.504 (0.647)	Total loss 4.920 (4.682)
Epoch: [3][30/200]	Time 0.540 (0.627)	Total loss 4.766 (4.669)
Epoch: [3][35/200]	Time 0.523 (0.614)	Total loss 4.490 (4.648)
Epoch: [3][40/200]	Time 0.518 (0.607)	Total loss 4.736 (4.642)
Epoch: [3][45/200]	Time 0.621 (0.598)	Total loss 4.413 (4.647)
Epoch: [3][50/200]	Time 0.532 (0.591)	Total loss 4.703 (4.640)
Epoch: [3][55/200]	Time 0.511 (0.606)	Total loss 4.372 (4.624)
Epoch: [3][60/200]	Time 0.531 (0.601)	Total loss 4.768 (4.619)
Epoch: [3][65/200]	Time 0.492 (0.596)	Total loss 4.531 (4.622)
Epoch: [3][70/200]	Time 0.493 (0.590)	Total loss 4.959 (4.624)
Epoch: [3][75/200]	Time 0.512 (0.585)	Total loss 4.319 (4.616)
Epoch: [3][80/200]	Time 0.509 (0.596)	Total loss 3.941 (4.602)
Epoch: [3][85/200]	Time 0.696 (0.593)	Total loss 4.465 (4.585)
Epoch: [3][90/200]	Time 0.501 (0.589)	Total loss 4.804 (4.578)
Epoch: [3][95/200]	Time 0.550 (0.587)	Total loss 4.613 (4.575)
Epoch: [3][100/200]	Time 0.524 (0.584)	Total loss 4.750 (4.571)
Epoch: [3][105/200]	Time 0.498 (0.581)	Total loss 4.311 (4.561)
Epoch: [3][110/200]	Time 0.513 (0.580)	Total loss 4.507 (4.560)
Epoch: [3][115/200]	Time 0.514 (0.577)	Total loss 4.699 (4.561)
Epoch: [3][120/200]	Time 0.540 (0.577)	Total loss 4.139 (4.552)
Epoch: [3][125/200]	Time 0.655 (0.575)	Total loss 4.977 (4.549)
Epoch: [3][130/200]	Time 0.540 (0.573)	Total loss 4.594 (4.551)
Epoch: [3][135/200]	Time 0.494 (0.572)	Total loss 4.214 (4.539)
Epoch: [3][140/200]	Time 0.531 (0.570)	Total loss 4.569 (4.537)
Epoch: [3][145/200]	Time 1.547 (0.576)	Total loss 4.559 (4.539)
Epoch: [3][150/200]	Time 0.529 (0.575)	Total loss 4.610 (4.532)
Epoch: [3][155/200]	Time 0.492 (0.573)	Total loss 4.545 (4.534)
Epoch: [3][160/200]	Time 0.524 (0.572)	Total loss 4.458 (4.531)
Epoch: [3][165/200]	Time 0.625 (0.571)	Total loss 4.130 (4.530)
Epoch: [3][170/200]	Time 0.477 (0.578)	Total loss 3.996 (4.521)
Epoch: [3][175/200]	Time 0.497 (0.576)	Total loss 4.112 (4.510)
Epoch: [3][180/200]	Time 0.529 (0.575)	Total loss 3.928 (4.502)
Epoch: [3][185/200]	Time 0.490 (0.574)	Total loss 4.305 (4.498)
Epoch: [3][190/200]	Time 0.524 (0.573)	Total loss 4.540 (4.490)
Epoch: [3][195/200]	Time 0.519 (0.577)	Total loss 4.793 (4.488)
Epoch: [3][200/200]	Time 0.525 (0.576)	Total loss 4.634 (4.482)
==> start training epoch 4 	 ==> learning rate = 0.000161
Epoch: [4][5/200]	Time 0.666 (1.244)	Total loss 3.595 (3.954)
Epoch: [4][10/200]	Time 0.501 (0.876)	Total loss 4.131 (4.017)
Epoch: [4][15/200]	Time 0.531 (0.764)	Total loss 4.085 (4.045)
Epoch: [4][20/200]	Time 0.556 (0.703)	Total loss 4.396 (4.088)
Epoch: [4][25/200]	Time 0.507 (0.670)	Total loss 4.197 (4.067)
Epoch: [4][30/200]	Time 0.512 (0.650)	Total loss 4.160 (4.075)
Epoch: [4][35/200]	Time 0.540 (0.636)	Total loss 4.417 (4.067)
Epoch: [4][40/200]	Time 0.528 (0.657)	Total loss 4.237 (4.086)
Epoch: [4][45/200]	Time 0.732 (0.647)	Total loss 4.140 (4.086)
Epoch: [4][50/200]	Time 0.542 (0.635)	Total loss 4.073 (4.074)
Epoch: [4][55/200]	Time 0.527 (0.628)	Total loss 4.262 (4.094)
Epoch: [4][60/200]	Time 0.471 (0.617)	Total loss 3.847 (4.094)
Epoch: [4][65/200]	Time 0.498 (0.612)	Total loss 4.139 (4.088)
Epoch: [4][70/200]	Time 0.493 (0.607)	Total loss 3.974 (4.092)
Epoch: [4][75/200]	Time 0.488 (0.600)	Total loss 3.881 (4.101)
Epoch: [4][80/200]	Time 0.563 (0.597)	Total loss 4.299 (4.114)
Epoch: [4][85/200]	Time 0.636 (0.593)	Total loss 4.542 (4.117)
Epoch: [4][90/200]	Time 0.526 (0.588)	Total loss 4.181 (4.112)
Epoch: [4][95/200]	Time 0.533 (0.585)	Total loss 4.056 (4.112)
Epoch: [4][100/200]	Time 0.513 (0.581)	Total loss 4.358 (4.108)
Epoch: [4][105/200]	Time 1.624 (0.590)	Total loss 4.382 (4.110)
Epoch: [4][110/200]	Time 0.511 (0.588)	Total loss 4.001 (4.108)
Epoch: [4][115/200]	Time 0.472 (0.585)	Total loss 4.441 (4.115)
Epoch: [4][120/200]	Time 0.541 (0.584)	Total loss 4.245 (4.113)
Epoch: [4][125/200]	Time 0.615 (0.582)	Total loss 3.855 (4.106)
Epoch: [4][130/200]	Time 0.494 (0.578)	Total loss 4.100 (4.101)
Epoch: [4][135/200]	Time 0.512 (0.585)	Total loss 4.049 (4.097)
Epoch: [4][140/200]	Time 0.508 (0.583)	Total loss 4.167 (4.091)
Epoch: [4][145/200]	Time 0.503 (0.581)	Total loss 3.989 (4.096)
Epoch: [4][150/200]	Time 0.562 (0.581)	Total loss 4.278 (4.098)
Epoch: [4][155/200]	Time 0.558 (0.580)	Total loss 3.654 (4.092)
Epoch: [4][160/200]	Time 0.528 (0.579)	Total loss 4.179 (4.089)
Epoch: [4][165/200]	Time 0.657 (0.578)	Total loss 4.479 (4.086)
Epoch: [4][170/200]	Time 0.490 (0.576)	Total loss 4.412 (4.081)
Epoch: [4][175/200]	Time 0.491 (0.575)	Total loss 4.294 (4.084)
Epoch: [4][180/200]	Time 0.531 (0.573)	Total loss 3.935 (4.083)
Epoch: [4][185/200]	Time 0.506 (0.572)	Total loss 3.754 (4.077)
Epoch: [4][190/200]	Time 0.495 (0.571)	Total loss 3.815 (4.073)
Epoch: [4][195/200]	Time 0.513 (0.570)	Total loss 4.003 (4.069)
Epoch: [4][200/200]	Time 0.531 (0.569)	Total loss 4.077 (4.065)
==> start training epoch 5 	 ==> learning rate = 0.00019250000000000002
Epoch: [5][5/200]	Time 0.658 (1.425)	Total loss 4.105 (3.973)
Epoch: [5][10/200]	Time 0.504 (0.972)	Total loss 4.108 (4.035)
Epoch: [5][15/200]	Time 0.518 (0.828)	Total loss 4.201 (4.053)
Epoch: [5][20/200]	Time 0.528 (0.799)	Total loss 3.883 (4.001)
Epoch: [5][25/200]	Time 1.908 (0.849)	Total loss 3.783 (3.983)
Epoch: [5][30/200]	Time 0.497 (0.800)	Total loss 4.259 (3.963)
Epoch: [5][35/200]	Time 0.561 (0.762)	Total loss 3.780 (3.926)
Epoch: [5][40/200]	Time 0.556 (0.735)	Total loss 4.105 (3.908)
Epoch: [5][45/200]	Time 0.644 (0.713)	Total loss 3.844 (3.909)
Epoch: [5][50/200]	Time 0.506 (0.694)	Total loss 3.786 (3.902)
Epoch: [5][55/200]	Time 0.502 (0.679)	Total loss 3.549 (3.886)
Epoch: [5][60/200]	Time 0.499 (0.664)	Total loss 3.500 (3.872)
Epoch: [5][65/200]	Time 0.577 (0.655)	Total loss 3.626 (3.866)
Epoch: [5][70/200]	Time 0.511 (0.645)	Total loss 3.761 (3.862)
Epoch: [5][75/200]	Time 0.532 (0.637)	Total loss 3.181 (3.841)
Epoch: [5][80/200]	Time 0.556 (0.635)	Total loss 3.907 (3.842)
Epoch: [5][85/200]	Time 0.697 (0.630)	Total loss 3.387 (3.831)
Epoch: [5][90/200]	Time 0.504 (0.623)	Total loss 3.772 (3.822)
Epoch: [5][95/200]	Time 0.524 (0.619)	Total loss 3.856 (3.826)
Epoch: [5][100/200]	Time 0.520 (0.614)	Total loss 3.904 (3.831)
Epoch: [5][105/200]	Time 0.506 (0.611)	Total loss 3.365 (3.831)
Epoch: [5][110/200]	Time 0.499 (0.609)	Total loss 4.329 (3.839)
Epoch: [5][115/200]	Time 0.491 (0.604)	Total loss 4.239 (3.833)
Epoch: [5][120/200]	Time 0.513 (0.611)	Total loss 3.957 (3.833)
Epoch: [5][125/200]	Time 0.687 (0.609)	Total loss 3.411 (3.824)
Epoch: [5][130/200]	Time 0.516 (0.605)	Total loss 3.960 (3.829)
Epoch: [5][135/200]	Time 0.533 (0.612)	Total loss 3.373 (3.827)
Epoch: [5][140/200]	Time 0.536 (0.608)	Total loss 4.129 (3.827)
Epoch: [5][145/200]	Time 0.515 (0.606)	Total loss 3.681 (3.826)
Epoch: [5][150/200]	Time 0.538 (0.603)	Total loss 3.758 (3.827)
Epoch: [5][155/200]	Time 0.481 (0.599)	Total loss 3.708 (3.823)
Epoch: [5][160/200]	Time 0.489 (0.597)	Total loss 3.525 (3.820)
Epoch: [5][165/200]	Time 0.493 (0.594)	Total loss 3.680 (3.818)
Epoch: [5][170/200]	Time 0.483 (0.592)	Total loss 3.589 (3.818)
Epoch: [5][175/200]	Time 0.609 (0.590)	Total loss 3.766 (3.812)
Epoch: [5][180/200]	Time 0.529 (0.588)	Total loss 3.881 (3.813)
Epoch: [5][185/200]	Time 0.504 (0.587)	Total loss 3.862 (3.811)
Epoch: [5][190/200]	Time 0.533 (0.586)	Total loss 3.753 (3.809)
Epoch: [5][195/200]	Time 0.515 (0.584)	Total loss 4.170 (3.812)
Epoch: [5][200/200]	Time 0.489 (0.582)	Total loss 3.579 (3.807)
==> start training epoch 6 	 ==> learning rate = 0.000224
Epoch: [6][5/200]	Time 0.517 (1.068)	Total loss 3.509 (3.808)
Epoch: [6][10/200]	Time 1.792 (0.918)	Total loss 3.512 (3.777)
Epoch: [6][15/200]	Time 0.530 (0.786)	Total loss 3.879 (3.719)
Epoch: [6][20/200]	Time 0.516 (0.723)	Total loss 3.648 (3.732)
Epoch: [6][25/200]	Time 0.491 (0.684)	Total loss 3.637 (3.748)
Epoch: [6][30/200]	Time 0.584 (0.663)	Total loss 3.338 (3.771)
Epoch: [6][35/200]	Time 0.497 (0.645)	Total loss 3.907 (3.766)
Epoch: [6][40/200]	Time 0.497 (0.630)	Total loss 3.790 (3.779)
Epoch: [6][45/200]	Time 0.526 (0.639)	Total loss 3.652 (3.798)
Epoch: [6][50/200]	Time 0.496 (0.626)	Total loss 3.801 (3.799)
Epoch: [6][55/200]	Time 0.556 (0.620)	Total loss 3.618 (3.786)
Epoch: [6][60/200]	Time 0.490 (0.612)	Total loss 3.993 (3.792)
Epoch: [6][65/200]	Time 0.517 (0.608)	Total loss 3.517 (3.777)
Epoch: [6][70/200]	Time 0.544 (0.604)	Total loss 3.471 (3.767)
Epoch: [6][75/200]	Time 0.678 (0.601)	Total loss 3.960 (3.768)
Epoch: [6][80/200]	Time 0.532 (0.595)	Total loss 3.649 (3.777)
Epoch: [6][85/200]	Time 0.554 (0.608)	Total loss 3.844 (3.767)
Epoch: [6][90/200]	Time 0.545 (0.605)	Total loss 3.377 (3.749)
Epoch: [6][95/200]	Time 0.516 (0.601)	Total loss 3.556 (3.742)
Epoch: [6][100/200]	Time 0.466 (0.598)	Total loss 3.662 (3.738)
Epoch: [6][105/200]	Time 0.497 (0.606)	Total loss 4.144 (3.730)
Epoch: [6][110/200]	Time 0.502 (0.601)	Total loss 4.002 (3.733)
Epoch: [6][115/200]	Time 0.544 (0.599)	Total loss 3.879 (3.727)
Epoch: [6][120/200]	Time 0.620 (0.596)	Total loss 3.777 (3.721)
Epoch: [6][125/200]	Time 0.524 (0.593)	Total loss 3.707 (3.715)
Epoch: [6][130/200]	Time 0.504 (0.590)	Total loss 4.068 (3.722)
Epoch: [6][135/200]	Time 0.501 (0.587)	Total loss 3.200 (3.713)
Epoch: [6][140/200]	Time 0.562 (0.586)	Total loss 3.504 (3.708)
Epoch: [6][145/200]	Time 0.546 (0.585)	Total loss 3.559 (3.701)
Epoch: [6][150/200]	Time 0.521 (0.582)	Total loss 3.634 (3.694)
Epoch: [6][155/200]	Time 0.528 (0.580)	Total loss 3.508 (3.689)
Epoch: [6][160/200]	Time 0.722 (0.587)	Total loss 3.633 (3.691)
Epoch: [6][165/200]	Time 0.522 (0.585)	Total loss 3.343 (3.688)
Epoch: [6][170/200]	Time 0.560 (0.584)	Total loss 3.487 (3.685)
Epoch: [6][175/200]	Time 0.507 (0.582)	Total loss 3.621 (3.684)
Epoch: [6][180/200]	Time 0.519 (0.581)	Total loss 3.427 (3.684)
Epoch: [6][185/200]	Time 0.487 (0.580)	Total loss 3.813 (3.683)
Epoch: [6][190/200]	Time 0.486 (0.578)	Total loss 3.577 (3.681)
Epoch: [6][195/200]	Time 0.495 (0.576)	Total loss 3.355 (3.676)
Epoch: [6][200/200]	Time 0.656 (0.581)	Total loss 3.397 (3.673)
==> start training epoch 7 	 ==> learning rate = 0.0002555
Epoch: [7][5/200]	Time 0.513 (1.015)	Total loss 3.399 (3.680)
Epoch: [7][10/200]	Time 0.494 (0.781)	Total loss 3.777 (3.671)
Epoch: [7][15/200]	Time 0.474 (0.690)	Total loss 3.538 (3.646)
Epoch: [7][20/200]	Time 0.555 (0.659)	Total loss 3.384 (3.647)
Epoch: [7][25/200]	Time 0.522 (0.635)	Total loss 3.315 (3.626)
Epoch: [7][30/200]	Time 0.501 (0.615)	Total loss 3.182 (3.612)
Epoch: [7][35/200]	Time 0.554 (0.605)	Total loss 3.897 (3.613)
Epoch: [7][40/200]	Time 0.705 (0.600)	Total loss 3.514 (3.602)
Epoch: [7][45/200]	Time 0.549 (0.592)	Total loss 3.578 (3.611)
Epoch: [7][50/200]	Time 0.517 (0.590)	Total loss 3.613 (3.617)
Epoch: [7][55/200]	Time 0.542 (0.585)	Total loss 3.020 (3.614)
Epoch: [7][60/200]	Time 0.524 (0.584)	Total loss 3.737 (3.610)
Epoch: [7][65/200]	Time 0.523 (0.581)	Total loss 3.303 (3.602)
Epoch: [7][70/200]	Time 1.600 (0.592)	Total loss 3.744 (3.609)
Epoch: [7][75/200]	Time 0.504 (0.590)	Total loss 3.559 (3.604)
Epoch: [7][80/200]	Time 0.665 (0.586)	Total loss 3.828 (3.605)
Epoch: [7][85/200]	Time 0.528 (0.583)	Total loss 3.603 (3.605)
Epoch: [7][90/200]	Time 0.499 (0.594)	Total loss 3.444 (3.603)
Epoch: [7][95/200]	Time 0.524 (0.590)	Total loss 3.999 (3.607)
Epoch: [7][100/200]	Time 0.548 (0.588)	Total loss 3.631 (3.602)
Epoch: [7][105/200]	Time 0.530 (0.585)	Total loss 3.684 (3.602)
Epoch: [7][110/200]	Time 0.571 (0.583)	Total loss 3.282 (3.599)
Epoch: [7][115/200]	Time 0.481 (0.582)	Total loss 4.053 (3.598)
Epoch: [7][120/200]	Time 0.667 (0.580)	Total loss 3.263 (3.592)
Epoch: [7][125/200]	Time 0.478 (0.577)	Total loss 3.738 (3.595)
Epoch: [7][130/200]	Time 0.503 (0.576)	Total loss 3.644 (3.591)
Epoch: [7][135/200]	Time 0.486 (0.574)	Total loss 3.518 (3.591)
Epoch: [7][140/200]	Time 0.517 (0.582)	Total loss 3.427 (3.588)
Epoch: [7][145/200]	Time 0.552 (0.582)	Total loss 3.404 (3.585)
Epoch: [7][150/200]	Time 0.573 (0.580)	Total loss 3.726 (3.579)
Epoch: [7][155/200]	Time 0.508 (0.579)	Total loss 3.704 (3.575)
Epoch: [7][160/200]	Time 0.609 (0.577)	Total loss 4.119 (3.575)
Epoch: [7][165/200]	Time 0.497 (0.575)	Total loss 3.196 (3.575)
Epoch: [7][170/200]	Time 0.503 (0.574)	Total loss 3.378 (3.573)
Epoch: [7][175/200]	Time 0.478 (0.572)	Total loss 3.813 (3.571)
Epoch: [7][180/200]	Time 0.486 (0.570)	Total loss 3.438 (3.567)
Epoch: [7][185/200]	Time 0.513 (0.584)	Total loss 3.769 (3.563)
Epoch: [7][190/200]	Time 0.509 (0.582)	Total loss 3.247 (3.558)
Epoch: [7][195/200]	Time 0.499 (0.581)	Total loss 3.355 (3.557)
Epoch: [7][200/200]	Time 0.647 (0.581)	Total loss 3.199 (3.555)
==> start training epoch 8 	 ==> learning rate = 0.00028700000000000004
Epoch: [8][5/200]	Time 0.507 (0.615)	Total loss 3.275 (3.423)
Epoch: [8][10/200]	Time 0.486 (0.569)	Total loss 3.489 (3.489)
Epoch: [8][15/200]	Time 0.527 (0.547)	Total loss 3.607 (3.502)
Epoch: [8][20/200]	Time 0.463 (0.540)	Total loss 3.676 (3.481)
Epoch: [8][25/200]	Time 0.508 (0.536)	Total loss 3.494 (3.492)
Epoch: [8][30/200]	Time 0.549 (0.531)	Total loss 3.161 (3.465)
Epoch: [8][35/200]	Time 0.501 (0.531)	Total loss 3.394 (3.443)
Epoch: [8][40/200]	Time 0.686 (0.537)	Total loss 3.517 (3.449)
Epoch: [8][45/200]	Time 0.500 (0.535)	Total loss 3.387 (3.450)
Epoch: [8][50/200]	Time 0.525 (0.535)	Total loss 3.305 (3.450)
Epoch: [8][55/200]	Time 0.495 (0.533)	Total loss 3.556 (3.467)
Epoch: [8][60/200]	Time 0.507 (0.534)	Total loss 3.525 (3.475)
Epoch: [8][65/200]	Time 0.535 (0.535)	Total loss 3.583 (3.482)
Epoch: [8][70/200]	Time 0.486 (0.532)	Total loss 3.271 (3.470)
Epoch: [8][75/200]	Time 1.580 (0.547)	Total loss 3.310 (3.477)
Epoch: [8][80/200]	Time 0.657 (0.547)	Total loss 3.481 (3.485)
Epoch: [8][85/200]	Time 0.511 (0.545)	Total loss 3.870 (3.488)
Epoch: [8][90/200]	Time 0.498 (0.544)	Total loss 2.906 (3.487)
Epoch: [8][95/200]	Time 0.528 (0.543)	Total loss 3.272 (3.487)
Epoch: [8][100/200]	Time 0.473 (0.553)	Total loss 4.087 (3.496)
Epoch: [8][105/200]	Time 0.540 (0.553)	Total loss 3.377 (3.495)
Epoch: [8][110/200]	Time 0.563 (0.552)	Total loss 3.609 (3.495)
Epoch: [8][115/200]	Time 0.552 (0.553)	Total loss 3.487 (3.505)
Epoch: [8][120/200]	Time 0.676 (0.554)	Total loss 3.738 (3.502)
Epoch: [8][125/200]	Time 0.519 (0.552)	Total loss 3.420 (3.497)
Epoch: [8][130/200]	Time 0.528 (0.551)	Total loss 3.534 (3.498)
Epoch: [8][135/200]	Time 0.508 (0.550)	Total loss 3.489 (3.496)
Epoch: [8][140/200]	Time 0.551 (0.550)	Total loss 3.577 (3.500)
Epoch: [8][145/200]	Time 0.531 (0.551)	Total loss 3.501 (3.498)
Epoch: [8][150/200]	Time 0.530 (0.551)	Total loss 3.551 (3.495)
Epoch: [8][155/200]	Time 0.505 (0.550)	Total loss 3.298 (3.491)
Epoch: [8][160/200]	Time 0.628 (0.551)	Total loss 3.397 (3.492)
Epoch: [8][165/200]	Time 0.481 (0.549)	Total loss 3.265 (3.485)
Epoch: [8][170/200]	Time 0.494 (0.555)	Total loss 3.486 (3.486)
Epoch: [8][175/200]	Time 0.555 (0.554)	Total loss 3.412 (3.480)
Epoch: [8][180/200]	Time 0.497 (0.554)	Total loss 3.155 (3.481)
Epoch: [8][185/200]	Time 0.534 (0.554)	Total loss 3.594 (3.479)
Epoch: [8][190/200]	Time 0.501 (0.553)	Total loss 2.972 (3.476)
Epoch: [8][195/200]	Time 0.527 (0.559)	Total loss 3.796 (3.478)
Epoch: [8][200/200]	Time 0.731 (0.560)	Total loss 3.153 (3.476)
==> start training epoch 9 	 ==> learning rate = 0.0003185
Epoch: [9][5/200]	Time 0.499 (1.214)	Total loss 3.353 (3.341)
Epoch: [9][10/200]	Time 0.495 (1.010)	Total loss 3.174 (3.373)
Epoch: [9][15/200]	Time 0.557 (0.850)	Total loss 3.296 (3.394)
Epoch: [9][20/200]	Time 0.547 (0.781)	Total loss 3.208 (3.357)
Epoch: [9][25/200]	Time 0.513 (0.735)	Total loss 2.799 (3.357)
Epoch: [9][30/200]	Time 0.538 (0.699)	Total loss 3.838 (3.405)
Epoch: [9][35/200]	Time 0.537 (0.681)	Total loss 3.228 (3.372)
Epoch: [9][40/200]	Time 0.688 (0.666)	Total loss 3.291 (3.372)
Epoch: [9][45/200]	Time 0.523 (0.651)	Total loss 3.268 (3.368)
Epoch: [9][50/200]	Time 0.535 (0.640)	Total loss 3.327 (3.371)
Epoch: [9][55/200]	Time 0.529 (0.628)	Total loss 3.266 (3.375)
Epoch: [9][60/200]	Time 0.515 (0.622)	Total loss 3.589 (3.385)
Epoch: [9][65/200]	Time 0.515 (0.636)	Total loss 3.531 (3.387)
Epoch: [9][70/200]	Time 0.503 (0.627)	Total loss 3.160 (3.379)
Epoch: [9][75/200]	Time 0.491 (0.622)	Total loss 3.509 (3.375)
Epoch: [9][80/200]	Time 0.669 (0.618)	Total loss 3.565 (3.382)
Epoch: [9][85/200]	Time 0.526 (0.613)	Total loss 3.353 (3.372)
Epoch: [9][90/200]	Time 0.523 (0.609)	Total loss 3.115 (3.372)
Epoch: [9][95/200]	Time 0.523 (0.606)	Total loss 3.073 (3.360)
Epoch: [9][100/200]	Time 0.489 (0.603)	Total loss 3.504 (3.357)
Epoch: [9][105/200]	Time 0.507 (0.601)	Total loss 3.566 (3.362)
Epoch: [9][110/200]	Time 0.556 (0.598)	Total loss 3.609 (3.364)
Epoch: [9][115/200]	Time 0.519 (0.597)	Total loss 3.681 (3.364)
Epoch: [9][120/200]	Time 0.663 (0.595)	Total loss 3.434 (3.369)
Epoch: [9][125/200]	Time 0.536 (0.603)	Total loss 3.355 (3.371)
Epoch: [9][130/200]	Time 0.538 (0.602)	Total loss 3.370 (3.368)
Epoch: [9][135/200]	Time 0.518 (0.598)	Total loss 3.854 (3.371)
Epoch: [9][140/200]	Time 0.508 (0.596)	Total loss 3.260 (3.373)
Epoch: [9][145/200]	Time 0.515 (0.594)	Total loss 3.052 (3.372)
Epoch: [9][150/200]	Time 0.517 (0.591)	Total loss 3.818 (3.377)
Epoch: [9][155/200]	Time 0.483 (0.597)	Total loss 3.190 (3.371)
Epoch: [9][160/200]	Time 0.647 (0.594)	Total loss 3.511 (3.375)
Epoch: [9][165/200]	Time 0.519 (0.591)	Total loss 3.472 (3.374)
Epoch: [9][170/200]	Time 0.494 (0.590)	Total loss 3.438 (3.371)
Epoch: [9][175/200]	Time 0.539 (0.588)	Total loss 3.432 (3.371)
Epoch: [9][180/200]	Time 0.504 (0.587)	Total loss 3.177 (3.371)
Epoch: [9][185/200]	Time 0.514 (0.585)	Total loss 3.635 (3.369)
Epoch: [9][190/200]	Time 0.500 (0.583)	Total loss 3.227 (3.365)
Epoch: [9][195/200]	Time 0.503 (0.582)	Total loss 3.220 (3.366)
Epoch: [9][200/200]	Time 0.684 (0.581)	Total loss 3.572 (3.372)
==> start training epoch 10 	 ==> learning rate = 0.00035
Epoch: [10][5/200]	Time 0.526 (1.227)	Total loss 3.145 (3.217)
Epoch: [10][10/200]	Time 0.560 (0.908)	Total loss 3.383 (3.331)
Epoch: [10][15/200]	Time 0.489 (0.777)	Total loss 3.439 (3.305)
Epoch: [10][20/200]	Time 0.533 (0.716)	Total loss 3.120 (3.281)
Epoch: [10][25/200]	Time 0.532 (0.684)	Total loss 3.019 (3.282)
Epoch: [10][30/200]	Time 0.509 (0.655)	Total loss 3.311 (3.306)
Epoch: [10][35/200]	Time 1.670 (0.672)	Total loss 3.308 (3.316)
Epoch: [10][40/200]	Time 0.716 (0.656)	Total loss 3.273 (3.330)
Epoch: [10][45/200]	Time 0.513 (0.641)	Total loss 3.218 (3.331)
Epoch: [10][50/200]	Time 0.511 (0.684)	Total loss 3.157 (3.319)
Epoch: [10][55/200]	Time 0.512 (0.669)	Total loss 3.401 (3.316)
Epoch: [10][60/200]	Time 0.513 (0.660)	Total loss 2.993 (3.307)
Epoch: [10][65/200]	Time 0.505 (0.652)	Total loss 3.280 (3.309)
Epoch: [10][70/200]	Time 0.500 (0.642)	Total loss 3.345 (3.308)
Epoch: [10][75/200]	Time 0.537 (0.636)	Total loss 3.480 (3.310)
Epoch: [10][80/200]	Time 0.659 (0.631)	Total loss 2.987 (3.307)
Epoch: [10][85/200]	Time 0.502 (0.623)	Total loss 3.602 (3.320)
Epoch: [10][90/200]	Time 0.513 (0.619)	Total loss 3.582 (3.312)
Epoch: [10][95/200]	Time 0.497 (0.613)	Total loss 3.372 (3.315)
Epoch: [10][100/200]	Time 0.506 (0.610)	Total loss 2.979 (3.308)
Epoch: [10][105/200]	Time 0.508 (0.607)	Total loss 3.098 (3.304)
Epoch: [10][110/200]	Time 0.497 (0.602)	Total loss 3.420 (3.303)
Epoch: [10][115/200]	Time 0.505 (0.600)	Total loss 3.201 (3.310)
Epoch: [10][120/200]	Time 0.662 (0.597)	Total loss 3.411 (3.308)
Epoch: [10][125/200]	Time 0.498 (0.594)	Total loss 3.523 (3.314)
Epoch: [10][130/200]	Time 0.543 (0.593)	Total loss 3.197 (3.315)
Epoch: [10][135/200]	Time 0.493 (0.590)	Total loss 3.310 (3.314)
Epoch: [10][140/200]	Time 1.811 (0.597)	Total loss 3.486 (3.318)
Epoch: [10][145/200]	Time 0.520 (0.596)	Total loss 3.118 (3.308)
Epoch: [10][150/200]	Time 0.494 (0.601)	Total loss 3.353 (3.314)
Epoch: [10][155/200]	Time 0.503 (0.599)	Total loss 3.285 (3.312)
Epoch: [10][160/200]	Time 0.705 (0.598)	Total loss 2.977 (3.310)
Epoch: [10][165/200]	Time 0.521 (0.595)	Total loss 3.240 (3.307)
Epoch: [10][170/200]	Time 0.496 (0.594)	Total loss 3.330 (3.305)
Epoch: [10][175/200]	Time 0.514 (0.591)	Total loss 3.489 (3.313)
Epoch: [10][180/200]	Time 0.508 (0.590)	Total loss 3.607 (3.309)
Epoch: [10][185/200]	Time 0.508 (0.589)	Total loss 3.100 (3.312)
Epoch: [10][190/200]	Time 0.516 (0.587)	Total loss 3.175 (3.315)
Epoch: [10][195/200]	Time 0.487 (0.586)	Total loss 3.244 (3.310)
Epoch: [10][200/200]	Time 0.690 (0.585)	Total loss 2.945 (3.309)
==> start training epoch 11 	 ==> learning rate = 0.00035
Epoch: [11][5/200]	Time 0.525 (1.096)	Total loss 3.189 (3.377)
Epoch: [11][10/200]	Time 0.510 (0.820)	Total loss 3.057 (3.325)
Epoch: [11][15/200]	Time 0.494 (0.716)	Total loss 3.756 (3.345)
Epoch: [11][20/200]	Time 0.501 (0.673)	Total loss 2.912 (3.307)
Epoch: [11][25/200]	Time 0.491 (0.649)	Total loss 3.245 (3.298)
Epoch: [11][30/200]	Time 0.488 (0.625)	Total loss 2.790 (3.292)
Epoch: [11][35/200]	Time 0.525 (0.649)	Total loss 3.360 (3.281)
Epoch: [11][40/200]	Time 0.708 (0.637)	Total loss 3.364 (3.275)
Epoch: [11][45/200]	Time 0.507 (0.624)	Total loss 2.951 (3.272)
Epoch: [11][50/200]	Time 0.511 (0.615)	Total loss 3.709 (3.284)
Epoch: [11][55/200]	Time 0.545 (0.609)	Total loss 3.477 (3.279)
Epoch: [11][60/200]	Time 0.549 (0.603)	Total loss 2.820 (3.281)
Epoch: [11][65/200]	Time 0.530 (0.620)	Total loss 3.470 (3.286)
Epoch: [11][70/200]	Time 0.534 (0.614)	Total loss 3.208 (3.287)
Epoch: [11][75/200]	Time 0.513 (0.610)	Total loss 3.507 (3.290)
Epoch: [11][80/200]	Time 0.676 (0.607)	Total loss 3.246 (3.291)
Epoch: [11][85/200]	Time 0.531 (0.601)	Total loss 3.132 (3.278)
Epoch: [11][90/200]	Time 0.493 (0.599)	Total loss 2.907 (3.273)
Epoch: [11][95/200]	Time 0.550 (0.595)	Total loss 3.407 (3.276)
Epoch: [11][100/200]	Time 0.515 (0.593)	Total loss 3.481 (3.283)
Epoch: [11][105/200]	Time 2.012 (0.606)	Total loss 3.423 (3.289)
Epoch: [11][110/200]	Time 0.518 (0.601)	Total loss 3.200 (3.276)
Epoch: [11][115/200]	Time 0.507 (0.599)	Total loss 3.255 (3.276)
Epoch: [11][120/200]	Time 0.690 (0.597)	Total loss 3.449 (3.274)
Epoch: [11][125/200]	Time 0.503 (0.593)	Total loss 3.423 (3.277)
Epoch: [11][130/200]	Time 0.537 (0.601)	Total loss 3.345 (3.281)
Epoch: [11][135/200]	Time 0.504 (0.598)	Total loss 2.938 (3.278)
Epoch: [11][140/200]	Time 0.512 (0.596)	Total loss 3.310 (3.276)
Epoch: [11][145/200]	Time 0.509 (0.595)	Total loss 2.996 (3.277)
Epoch: [11][150/200]	Time 0.501 (0.592)	Total loss 3.142 (3.275)
Epoch: [11][155/200]	Time 0.533 (0.591)	Total loss 3.013 (3.271)
Epoch: [11][160/200]	Time 0.718 (0.590)	Total loss 3.144 (3.274)
Epoch: [11][165/200]	Time 0.545 (0.588)	Total loss 3.417 (3.277)
Epoch: [11][170/200]	Time 0.516 (0.587)	Total loss 2.929 (3.272)
Epoch: [11][175/200]	Time 0.528 (0.592)	Total loss 3.270 (3.273)
Epoch: [11][180/200]	Time 0.515 (0.591)	Total loss 3.205 (3.269)
Epoch: [11][185/200]	Time 0.502 (0.590)	Total loss 3.438 (3.265)
Epoch: [11][190/200]	Time 0.514 (0.588)	Total loss 3.355 (3.264)
Epoch: [11][195/200]	Time 0.498 (0.587)	Total loss 3.170 (3.262)
Epoch: [11][200/200]	Time 0.718 (0.586)	Total loss 3.319 (3.256)
==> start training epoch 12 	 ==> learning rate = 0.00035
Epoch: [12][5/200]	Time 0.504 (1.374)	Total loss 3.429 (3.265)
Epoch: [12][10/200]	Time 0.486 (0.959)	Total loss 3.145 (3.259)
Epoch: [12][15/200]	Time 0.503 (0.810)	Total loss 3.437 (3.237)
Epoch: [12][20/200]	Time 0.510 (0.807)	Total loss 2.985 (3.218)
Epoch: [12][25/200]	Time 0.489 (0.756)	Total loss 3.464 (3.229)
Epoch: [12][30/200]	Time 0.559 (0.717)	Total loss 3.305 (3.226)
Epoch: [12][35/200]	Time 0.528 (0.694)	Total loss 3.003 (3.240)
Epoch: [12][40/200]	Time 0.697 (0.676)	Total loss 3.485 (3.228)
Epoch: [12][45/200]	Time 0.521 (0.658)	Total loss 3.568 (3.236)
Epoch: [12][50/200]	Time 0.503 (0.647)	Total loss 3.144 (3.238)
Epoch: [12][55/200]	Time 0.527 (0.635)	Total loss 3.747 (3.235)
Epoch: [12][60/200]	Time 0.536 (0.629)	Total loss 3.550 (3.233)
Epoch: [12][65/200]	Time 0.498 (0.622)	Total loss 2.865 (3.233)
Epoch: [12][70/200]	Time 0.492 (0.614)	Total loss 3.200 (3.221)
Epoch: [12][75/200]	Time 0.540 (0.611)	Total loss 3.164 (3.217)
Epoch: [12][80/200]	Time 0.651 (0.607)	Total loss 3.280 (3.215)
Epoch: [12][85/200]	Time 0.512 (0.601)	Total loss 3.601 (3.226)
Epoch: [12][90/200]	Time 0.511 (0.613)	Total loss 3.310 (3.234)
Epoch: [12][95/200]	Time 0.516 (0.608)	Total loss 2.961 (3.229)
Epoch: [12][100/200]	Time 0.506 (0.605)	Total loss 3.135 (3.219)
Epoch: [12][105/200]	Time 0.504 (0.603)	Total loss 3.050 (3.215)
Epoch: [12][110/200]	Time 0.523 (0.599)	Total loss 2.984 (3.214)
Epoch: [12][115/200]	Time 0.549 (0.607)	Total loss 2.871 (3.214)
Epoch: [12][120/200]	Time 0.677 (0.604)	Total loss 3.107 (3.216)
Epoch: [12][125/200]	Time 0.526 (0.602)	Total loss 3.344 (3.219)
Epoch: [12][130/200]	Time 0.520 (0.600)	Total loss 3.148 (3.220)
Epoch: [12][135/200]	Time 0.508 (0.597)	Total loss 3.382 (3.218)
Epoch: [12][140/200]	Time 0.475 (0.595)	Total loss 3.424 (3.219)
Epoch: [12][145/200]	Time 0.484 (0.592)	Total loss 2.974 (3.215)
Epoch: [12][150/200]	Time 0.523 (0.590)	Total loss 3.256 (3.214)
Epoch: [12][155/200]	Time 0.534 (0.589)	Total loss 3.121 (3.210)
Epoch: [12][160/200]	Time 0.630 (0.587)	Total loss 3.385 (3.214)
Epoch: [12][165/200]	Time 0.479 (0.593)	Total loss 3.425 (3.217)
Epoch: [12][170/200]	Time 0.518 (0.592)	Total loss 2.935 (3.214)
Epoch: [12][175/200]	Time 0.523 (0.590)	Total loss 3.031 (3.210)
Epoch: [12][180/200]	Time 0.485 (0.589)	Total loss 3.020 (3.205)
Epoch: [12][185/200]	Time 0.502 (0.588)	Total loss 3.043 (3.202)
Epoch: [12][190/200]	Time 0.484 (0.585)	Total loss 3.338 (3.202)
Epoch: [12][195/200]	Time 0.498 (0.584)	Total loss 3.278 (3.202)
Epoch: [12][200/200]	Time 1.777 (0.588)	Total loss 3.245 (3.199)
==> start training epoch 13 	 ==> learning rate = 0.00035
Epoch: [13][5/200]	Time 1.643 (1.398)	Total loss 3.038 (3.073)
Epoch: [13][10/200]	Time 0.528 (0.986)	Total loss 3.300 (3.065)
Epoch: [13][15/200]	Time 0.530 (0.823)	Total loss 3.026 (3.091)
Epoch: [13][20/200]	Time 0.513 (0.750)	Total loss 3.182 (3.100)
Epoch: [13][25/200]	Time 0.556 (0.712)	Total loss 3.411 (3.099)
Epoch: [13][30/200]	Time 0.554 (0.679)	Total loss 3.095 (3.074)
Epoch: [13][35/200]	Time 0.534 (0.660)	Total loss 2.687 (3.074)
Epoch: [13][40/200]	Time 0.636 (0.647)	Total loss 3.117 (3.063)
Epoch: [13][45/200]	Time 0.518 (0.636)	Total loss 3.215 (3.064)
Epoch: [13][50/200]	Time 0.537 (0.628)	Total loss 2.909 (3.055)
Epoch: [13][55/200]	Time 0.537 (0.618)	Total loss 2.815 (3.042)
Epoch: [13][60/200]	Time 0.512 (0.611)	Total loss 3.159 (3.055)
Epoch: [13][65/200]	Time 0.552 (0.607)	Total loss 3.177 (3.061)
Epoch: [13][70/200]	Time 0.546 (0.601)	Total loss 3.146 (3.062)
Epoch: [13][75/200]	Time 0.512 (0.596)	Total loss 2.839 (3.064)
Epoch: [13][80/200]	Time 0.651 (0.593)	Total loss 3.067 (3.072)
Epoch: [13][85/200]	Time 0.528 (0.590)	Total loss 3.449 (3.076)
Epoch: [13][90/200]	Time 0.497 (0.586)	Total loss 3.026 (3.072)
Epoch: [13][95/200]	Time 0.513 (0.582)	Total loss 3.362 (3.079)
Epoch: [13][100/200]	Time 0.534 (0.591)	Total loss 3.192 (3.081)
Epoch: [13][105/200]	Time 0.515 (0.589)	Total loss 3.051 (3.080)
Epoch: [13][110/200]	Time 0.513 (0.585)	Total loss 2.898 (3.075)
Epoch: [13][115/200]	Time 0.506 (0.594)	Total loss 3.280 (3.074)
Epoch: [13][120/200]	Time 0.661 (0.592)	Total loss 3.068 (3.071)
Epoch: [13][125/200]	Time 0.525 (0.589)	Total loss 3.127 (3.071)
Epoch: [13][130/200]	Time 0.539 (0.588)	Total loss 2.966 (3.071)
Epoch: [13][135/200]	Time 0.533 (0.585)	Total loss 3.045 (3.076)
Epoch: [13][140/200]	Time 0.527 (0.584)	Total loss 2.732 (3.072)
Epoch: [13][145/200]	Time 0.523 (0.583)	Total loss 3.099 (3.071)
Epoch: [13][150/200]	Time 0.495 (0.581)	Total loss 3.191 (3.072)
Epoch: [13][155/200]	Time 0.511 (0.579)	Total loss 3.024 (3.070)
Epoch: [13][160/200]	Time 0.645 (0.578)	Total loss 3.200 (3.072)
Epoch: [13][165/200]	Time 0.573 (0.577)	Total loss 3.580 (3.077)
Epoch: [13][170/200]	Time 0.513 (0.577)	Total loss 3.286 (3.084)
Epoch: [13][175/200]	Time 0.513 (0.575)	Total loss 3.044 (3.087)
Epoch: [13][180/200]	Time 0.558 (0.575)	Total loss 3.481 (3.090)
Epoch: [13][185/200]	Time 0.540 (0.575)	Total loss 3.005 (3.089)
Epoch: [13][190/200]	Time 0.520 (0.573)	Total loss 3.294 (3.088)
Epoch: [13][195/200]	Time 0.519 (0.579)	Total loss 2.978 (3.087)
Epoch: [13][200/200]	Time 0.696 (0.578)	Total loss 3.294 (3.089)
==> start training epoch 14 	 ==> learning rate = 0.00035
Epoch: [14][5/200]	Time 0.516 (1.331)	Total loss 2.936 (3.024)
Epoch: [14][10/200]	Time 0.488 (0.937)	Total loss 3.339 (3.122)
Epoch: [14][15/200]	Time 0.526 (0.797)	Total loss 3.019 (3.079)
Epoch: [14][20/200]	Time 0.521 (0.801)	Total loss 3.186 (3.062)
Epoch: [14][25/200]	Time 0.565 (0.753)	Total loss 3.180 (3.079)
Epoch: [14][30/200]	Time 0.544 (0.759)	Total loss 2.988 (3.084)
Epoch: [14][35/200]	Time 0.555 (0.734)	Total loss 3.056 (3.069)
Epoch: [14][40/200]	Time 0.653 (0.709)	Total loss 2.984 (3.078)
Epoch: [14][45/200]	Time 0.511 (0.689)	Total loss 2.826 (3.068)
Epoch: [14][50/200]	Time 0.504 (0.673)	Total loss 2.662 (3.054)
Epoch: [14][55/200]	Time 0.499 (0.659)	Total loss 3.549 (3.070)
Epoch: [14][60/200]	Time 0.491 (0.650)	Total loss 2.842 (3.063)
Epoch: [14][65/200]	Time 0.560 (0.644)	Total loss 2.891 (3.052)
Epoch: [14][70/200]	Time 0.557 (0.637)	Total loss 2.876 (3.053)
Epoch: [14][75/200]	Time 0.515 (0.631)	Total loss 2.920 (3.043)
Epoch: [14][80/200]	Time 0.706 (0.627)	Total loss 3.120 (3.041)
Epoch: [14][85/200]	Time 0.530 (0.634)	Total loss 2.832 (3.029)
Epoch: [14][90/200]	Time 0.520 (0.630)	Total loss 3.339 (3.027)
Epoch: [14][95/200]	Time 0.529 (0.625)	Total loss 3.228 (3.027)
Epoch: [14][100/200]	Time 0.526 (0.621)	Total loss 2.828 (3.029)
Epoch: [14][105/200]	Time 0.532 (0.619)	Total loss 3.000 (3.033)
Epoch: [14][110/200]	Time 0.517 (0.615)	Total loss 3.178 (3.031)
Epoch: [14][115/200]	Time 0.563 (0.613)	Total loss 2.559 (3.024)
Epoch: [14][120/200]	Time 0.704 (0.611)	Total loss 2.922 (3.024)
Epoch: [14][125/200]	Time 0.508 (0.608)	Total loss 2.859 (3.032)
Epoch: [14][130/200]	Time 0.521 (0.606)	Total loss 2.670 (3.035)
Epoch: [14][135/200]	Time 0.504 (0.602)	Total loss 2.992 (3.030)
Epoch: [14][140/200]	Time 0.559 (0.608)	Total loss 3.019 (3.034)
Epoch: [14][145/200]	Time 0.508 (0.606)	Total loss 3.066 (3.029)
Epoch: [14][150/200]	Time 0.519 (0.603)	Total loss 2.948 (3.029)
Epoch: [14][155/200]	Time 0.483 (0.600)	Total loss 2.803 (3.021)
Epoch: [14][160/200]	Time 0.607 (0.598)	Total loss 2.951 (3.016)
Epoch: [14][165/200]	Time 0.487 (0.596)	Total loss 3.161 (3.018)
Epoch: [14][170/200]	Time 0.465 (0.594)	Total loss 2.667 (3.016)
Epoch: [14][175/200]	Time 0.496 (0.591)	Total loss 2.626 (3.012)
Epoch: [14][180/200]	Time 0.488 (0.596)	Total loss 2.890 (3.010)
Epoch: [14][185/200]	Time 0.538 (0.594)	Total loss 2.950 (3.006)
Epoch: [14][190/200]	Time 0.578 (0.593)	Total loss 3.125 (3.012)
Epoch: [14][195/200]	Time 0.588 (0.591)	Total loss 2.839 (3.010)
Epoch: [14][200/200]	Time 0.535 (0.589)	Total loss 2.998 (3.011)
==> start training epoch 15 	 ==> learning rate = 0.00035
Epoch: [15][5/200]	Time 0.580 (1.184)	Total loss 3.120 (3.082)
Epoch: [15][10/200]	Time 0.680 (0.882)	Total loss 3.329 (3.026)
Epoch: [15][15/200]	Time 0.504 (0.768)	Total loss 3.589 (3.053)
Epoch: [15][20/200]	Time 0.500 (0.709)	Total loss 2.604 (3.022)
Epoch: [15][25/200]	Time 0.537 (0.678)	Total loss 3.008 (3.023)
Epoch: [15][30/200]	Time 0.503 (0.652)	Total loss 2.754 (2.994)
Epoch: [15][35/200]	Time 0.532 (0.636)	Total loss 2.881 (3.005)
Epoch: [15][40/200]	Time 0.515 (0.626)	Total loss 3.237 (3.021)
Epoch: [15][45/200]	Time 0.617 (0.616)	Total loss 3.221 (3.028)
Epoch: [15][50/200]	Time 0.539 (0.605)	Total loss 2.980 (3.029)
Epoch: [15][55/200]	Time 0.554 (0.621)	Total loss 3.210 (3.027)
Epoch: [15][60/200]	Time 0.550 (0.613)	Total loss 3.106 (3.021)
Epoch: [15][65/200]	Time 0.536 (0.608)	Total loss 2.731 (3.014)
Epoch: [15][70/200]	Time 1.664 (0.622)	Total loss 3.039 (3.013)
Epoch: [15][75/200]	Time 0.523 (0.632)	Total loss 3.225 (3.020)
Epoch: [15][80/200]	Time 0.536 (0.628)	Total loss 2.640 (3.012)
Epoch: [15][85/200]	Time 0.649 (0.624)	Total loss 2.778 (2.997)
Epoch: [15][90/200]	Time 0.507 (0.618)	Total loss 3.099 (2.992)
Epoch: [15][95/200]	Time 0.519 (0.615)	Total loss 2.826 (2.991)
Epoch: [15][100/200]	Time 0.494 (0.610)	Total loss 2.597 (2.989)
Epoch: [15][105/200]	Time 0.546 (0.607)	Total loss 3.079 (2.984)
Epoch: [15][110/200]	Time 0.532 (0.606)	Total loss 3.030 (2.979)
Epoch: [15][115/200]	Time 0.558 (0.603)	Total loss 3.201 (2.980)
Epoch: [15][120/200]	Time 0.502 (0.600)	Total loss 2.937 (2.980)
Epoch: [15][125/200]	Time 0.748 (0.599)	Total loss 2.817 (2.977)
Epoch: [15][130/200]	Time 0.510 (0.596)	Total loss 2.814 (2.970)
Epoch: [15][135/200]	Time 0.519 (0.595)	Total loss 3.143 (2.970)
Epoch: [15][140/200]	Time 0.516 (0.592)	Total loss 2.919 (2.968)
Epoch: [15][145/200]	Time 0.575 (0.591)	Total loss 2.805 (2.963)
Epoch: [15][150/200]	Time 0.519 (0.590)	Total loss 2.966 (2.965)
Epoch: [15][155/200]	Time 0.513 (0.588)	Total loss 3.513 (2.967)
Epoch: [15][160/200]	Time 0.506 (0.586)	Total loss 2.934 (2.969)
Epoch: [15][165/200]	Time 1.772 (0.598)	Total loss 2.438 (2.965)
Epoch: [15][170/200]	Time 0.482 (0.595)	Total loss 3.094 (2.966)
Epoch: [15][175/200]	Time 0.505 (0.594)	Total loss 2.720 (2.964)
Epoch: [15][180/200]	Time 0.538 (0.592)	Total loss 2.857 (2.965)
Epoch: [15][185/200]	Time 0.491 (0.590)	Total loss 2.581 (2.960)
Epoch: [15][190/200]	Time 0.587 (0.589)	Total loss 3.254 (2.963)
Epoch: [15][195/200]	Time 0.503 (0.588)	Total loss 3.180 (2.964)
Epoch: [15][200/200]	Time 0.494 (0.587)	Total loss 3.116 (2.967)
==> start training epoch 16 	 ==> learning rate = 0.00035
Epoch: [16][5/200]	Time 0.678 (1.232)	Total loss 2.891 (2.859)
Epoch: [16][10/200]	Time 0.522 (0.875)	Total loss 3.225 (2.928)
Epoch: [16][15/200]	Time 0.524 (0.768)	Total loss 3.044 (2.970)
Epoch: [16][20/200]	Time 0.518 (0.708)	Total loss 3.175 (2.953)
Epoch: [16][25/200]	Time 0.532 (0.676)	Total loss 2.812 (2.951)
Epoch: [16][30/200]	Time 0.541 (0.655)	Total loss 2.878 (2.943)
Epoch: [16][35/200]	Time 0.503 (0.635)	Total loss 2.484 (2.952)
Epoch: [16][40/200]	Time 0.558 (0.627)	Total loss 2.952 (2.949)
Epoch: [16][45/200]	Time 0.675 (0.618)	Total loss 3.057 (2.961)
Epoch: [16][50/200]	Time 0.495 (0.607)	Total loss 3.082 (2.972)
Epoch: [16][55/200]	Time 0.486 (0.601)	Total loss 3.098 (2.968)
Epoch: [16][60/200]	Time 0.519 (0.614)	Total loss 2.846 (2.968)
Epoch: [16][65/200]	Time 0.509 (0.609)	Total loss 2.992 (2.961)
Epoch: [16][70/200]	Time 0.483 (0.602)	Total loss 3.073 (2.955)
Epoch: [16][75/200]	Time 0.506 (0.597)	Total loss 2.917 (2.961)
Epoch: [16][80/200]	Time 0.509 (0.608)	Total loss 3.152 (2.973)
Epoch: [16][85/200]	Time 0.639 (0.604)	Total loss 2.735 (2.967)
Epoch: [16][90/200]	Time 0.520 (0.599)	Total loss 2.991 (2.968)
Epoch: [16][95/200]	Time 0.527 (0.595)	Total loss 2.802 (2.960)
Epoch: [16][100/200]	Time 0.492 (0.591)	Total loss 2.756 (2.960)
Epoch: [16][105/200]	Time 0.480 (0.588)	Total loss 2.644 (2.952)
Epoch: [16][110/200]	Time 0.489 (0.586)	Total loss 3.450 (2.964)
Epoch: [16][115/200]	Time 0.517 (0.583)	Total loss 2.590 (2.962)
Epoch: [16][120/200]	Time 0.528 (0.582)	Total loss 2.988 (2.960)
Epoch: [16][125/200]	Time 0.643 (0.581)	Total loss 2.798 (2.961)
Epoch: [16][130/200]	Time 0.511 (0.589)	Total loss 2.969 (2.961)
Epoch: [16][135/200]	Time 0.532 (0.588)	Total loss 2.723 (2.958)
Epoch: [16][140/200]	Time 0.526 (0.585)	Total loss 3.260 (2.962)
Epoch: [16][145/200]	Time 0.515 (0.583)	Total loss 3.029 (2.963)
Epoch: [16][150/200]	Time 0.550 (0.589)	Total loss 2.686 (2.959)
Epoch: [16][155/200]	Time 0.520 (0.587)	Total loss 2.600 (2.958)
Epoch: [16][160/200]	Time 0.522 (0.585)	Total loss 2.783 (2.955)
Epoch: [16][165/200]	Time 0.662 (0.584)	Total loss 3.088 (2.948)
Epoch: [16][170/200]	Time 0.513 (0.582)	Total loss 3.174 (2.946)
Epoch: [16][175/200]	Time 0.470 (0.581)	Total loss 2.578 (2.942)
Epoch: [16][180/200]	Time 0.511 (0.579)	Total loss 2.838 (2.937)
Epoch: [16][185/200]	Time 0.482 (0.578)	Total loss 2.612 (2.937)
Epoch: [16][190/200]	Time 0.498 (0.577)	Total loss 2.850 (2.937)
Epoch: [16][195/200]	Time 0.530 (0.582)	Total loss 2.622 (2.936)
Epoch: [16][200/200]	Time 0.528 (0.581)	Total loss 3.063 (2.935)
==> start training epoch 17 	 ==> learning rate = 0.00035
Epoch: [17][5/200]	Time 0.702 (1.111)	Total loss 2.776 (2.952)
Epoch: [17][10/200]	Time 0.511 (0.813)	Total loss 2.824 (2.927)
Epoch: [17][15/200]	Time 0.503 (0.729)	Total loss 2.878 (2.951)
Epoch: [17][20/200]	Time 0.547 (0.677)	Total loss 3.157 (2.947)
Epoch: [17][25/200]	Time 0.538 (0.652)	Total loss 3.063 (2.972)
Epoch: [17][30/200]	Time 0.515 (0.634)	Total loss 2.832 (2.952)
Epoch: [17][35/200]	Time 0.509 (0.618)	Total loss 2.887 (2.944)
Epoch: [17][40/200]	Time 0.514 (0.608)	Total loss 2.931 (2.938)
Epoch: [17][45/200]	Time 0.711 (0.625)	Total loss 2.699 (2.922)
Epoch: [17][50/200]	Time 0.521 (0.617)	Total loss 2.763 (2.916)
Epoch: [17][55/200]	Time 0.512 (0.609)	Total loss 3.058 (2.910)
Epoch: [17][60/200]	Time 0.530 (0.603)	Total loss 2.867 (2.910)
Epoch: [17][65/200]	Time 0.515 (0.600)	Total loss 3.227 (2.909)
Epoch: [17][70/200]	Time 0.520 (0.596)	Total loss 3.276 (2.916)
Epoch: [17][75/200]	Time 0.517 (0.591)	Total loss 3.136 (2.919)
Epoch: [17][80/200]	Time 0.494 (0.587)	Total loss 2.913 (2.922)
Epoch: [17][85/200]	Time 0.645 (0.584)	Total loss 2.909 (2.917)
Epoch: [17][90/200]	Time 0.533 (0.581)	Total loss 2.896 (2.914)
Epoch: [17][95/200]	Time 0.470 (0.578)	Total loss 2.916 (2.919)
Epoch: [17][100/200]	Time 0.476 (0.573)	Total loss 2.753 (2.916)
Epoch: [17][105/200]	Time 0.496 (0.581)	Total loss 2.872 (2.914)
Epoch: [17][110/200]	Time 0.526 (0.579)	Total loss 2.634 (2.903)
Epoch: [17][115/200]	Time 0.548 (0.578)	Total loss 3.143 (2.905)
Epoch: [17][120/200]	Time 0.526 (0.577)	Total loss 3.328 (2.912)
Epoch: [17][125/200]	Time 0.667 (0.576)	Total loss 3.179 (2.910)
Epoch: [17][130/200]	Time 0.578 (0.573)	Total loss 2.898 (2.912)
Epoch: [17][135/200]	Time 1.560 (0.580)	Total loss 3.165 (2.911)
Epoch: [17][140/200]	Time 0.527 (0.578)	Total loss 2.857 (2.908)
Epoch: [17][145/200]	Time 0.526 (0.576)	Total loss 2.730 (2.906)
Epoch: [17][150/200]	Time 0.504 (0.575)	Total loss 2.537 (2.900)
Epoch: [17][155/200]	Time 0.522 (0.573)	Total loss 2.983 (2.900)
Epoch: [17][160/200]	Time 0.523 (0.573)	Total loss 2.908 (2.899)
Epoch: [17][165/200]	Time 0.648 (0.571)	Total loss 2.862 (2.901)
Epoch: [17][170/200]	Time 0.508 (0.569)	Total loss 2.896 (2.903)
Epoch: [17][175/200]	Time 0.494 (0.569)	Total loss 3.492 (2.904)
Epoch: [17][180/200]	Time 0.485 (0.567)	Total loss 2.895 (2.905)
Epoch: [17][185/200]	Time 1.928 (0.574)	Total loss 3.036 (2.905)
Epoch: [17][190/200]	Time 0.514 (0.573)	Total loss 2.755 (2.906)
Epoch: [17][195/200]	Time 0.545 (0.572)	Total loss 2.888 (2.902)
Epoch: [17][200/200]	Time 0.579 (0.571)	Total loss 2.598 (2.900)
==> start training epoch 18 	 ==> learning rate = 0.00035
Epoch: [18][5/200]	Time 0.663 (1.237)	Total loss 2.761 (2.826)
Epoch: [18][10/200]	Time 0.541 (0.877)	Total loss 2.964 (2.862)
Epoch: [18][15/200]	Time 0.522 (0.762)	Total loss 3.000 (2.828)
Epoch: [18][20/200]	Time 0.503 (0.760)	Total loss 3.065 (2.794)
Epoch: [18][25/200]	Time 0.515 (0.718)	Total loss 2.962 (2.810)
Epoch: [18][30/200]	Time 0.537 (0.729)	Total loss 2.805 (2.787)
Epoch: [18][35/200]	Time 0.485 (0.700)	Total loss 3.186 (2.800)
Epoch: [18][40/200]	Time 0.484 (0.678)	Total loss 2.751 (2.811)
Epoch: [18][45/200]	Time 0.734 (0.664)	Total loss 2.890 (2.805)
Epoch: [18][50/200]	Time 0.487 (0.649)	Total loss 2.883 (2.804)
Epoch: [18][55/200]	Time 0.557 (0.639)	Total loss 2.538 (2.809)
Epoch: [18][60/200]	Time 0.524 (0.628)	Total loss 2.622 (2.816)
Epoch: [18][65/200]	Time 0.506 (0.623)	Total loss 2.806 (2.816)
Epoch: [18][70/200]	Time 0.516 (0.617)	Total loss 2.803 (2.813)
Epoch: [18][75/200]	Time 0.541 (0.612)	Total loss 3.035 (2.826)
Epoch: [18][80/200]	Time 0.546 (0.608)	Total loss 2.465 (2.822)
Epoch: [18][85/200]	Time 0.662 (0.605)	Total loss 2.955 (2.825)
Epoch: [18][90/200]	Time 0.529 (0.600)	Total loss 2.540 (2.820)
Epoch: [18][95/200]	Time 0.510 (0.598)	Total loss 2.732 (2.815)
Epoch: [18][100/200]	Time 0.524 (0.594)	Total loss 2.896 (2.824)
Epoch: [18][105/200]	Time 0.565 (0.593)	Total loss 2.809 (2.830)
Epoch: [18][110/200]	Time 0.530 (0.591)	Total loss 3.043 (2.835)
Epoch: [18][115/200]	Time 0.535 (0.588)	Total loss 3.127 (2.845)
Epoch: [18][120/200]	Time 0.497 (0.586)	Total loss 2.818 (2.840)
Epoch: [18][125/200]	Time 0.686 (0.593)	Total loss 2.607 (2.833)
Epoch: [18][130/200]	Time 1.710 (0.600)	Total loss 2.753 (2.833)
Epoch: [18][135/200]	Time 0.574 (0.598)	Total loss 3.151 (2.836)
Epoch: [18][140/200]	Time 0.490 (0.595)	Total loss 2.625 (2.836)
Epoch: [18][145/200]	Time 0.553 (0.594)	Total loss 2.747 (2.840)
Epoch: [18][150/200]	Time 0.511 (0.592)	Total loss 2.821 (2.837)
Epoch: [18][155/200]	Time 0.542 (0.590)	Total loss 2.617 (2.836)
Epoch: [18][160/200]	Time 0.508 (0.589)	Total loss 3.130 (2.840)
Epoch: [18][165/200]	Time 0.663 (0.588)	Total loss 2.588 (2.841)
Epoch: [18][170/200]	Time 0.505 (0.585)	Total loss 2.546 (2.842)
Epoch: [18][175/200]	Time 0.526 (0.584)	Total loss 2.548 (2.841)
Epoch: [18][180/200]	Time 0.514 (0.582)	Total loss 2.774 (2.846)
Epoch: [18][185/200]	Time 0.537 (0.582)	Total loss 2.704 (2.842)
Epoch: [18][190/200]	Time 0.504 (0.581)	Total loss 2.771 (2.842)
Epoch: [18][195/200]	Time 0.536 (0.579)	Total loss 3.033 (2.843)
Epoch: [18][200/200]	Time 0.514 (0.578)	Total loss 2.414 (2.838)
==> start training epoch 19 	 ==> learning rate = 0.00035
Epoch: [19][5/200]	Time 0.675 (1.343)	Total loss 2.666 (2.635)
Epoch: [19][10/200]	Time 0.505 (0.923)	Total loss 2.845 (2.789)
Epoch: [19][15/200]	Time 0.504 (0.872)	Total loss 2.619 (2.737)
Epoch: [19][20/200]	Time 0.507 (0.783)	Total loss 2.834 (2.768)
Epoch: [19][25/200]	Time 0.589 (0.739)	Total loss 2.601 (2.751)
Epoch: [19][30/200]	Time 0.501 (0.708)	Total loss 2.768 (2.774)
Epoch: [19][35/200]	Time 0.483 (0.679)	Total loss 2.696 (2.772)
Epoch: [19][40/200]	Time 0.520 (0.661)	Total loss 2.521 (2.775)
Epoch: [19][45/200]	Time 0.658 (0.699)	Total loss 2.723 (2.803)
Epoch: [19][50/200]	Time 0.555 (0.681)	Total loss 2.859 (2.808)
Epoch: [19][55/200]	Time 0.538 (0.669)	Total loss 2.922 (2.806)
Epoch: [19][60/200]	Time 0.524 (0.657)	Total loss 2.858 (2.813)
Epoch: [19][65/200]	Time 0.496 (0.648)	Total loss 2.660 (2.803)
Epoch: [19][70/200]	Time 0.518 (0.641)	Total loss 2.797 (2.812)
Epoch: [19][75/200]	Time 0.491 (0.633)	Total loss 2.782 (2.807)
Epoch: [19][80/200]	Time 0.520 (0.627)	Total loss 2.876 (2.815)
Epoch: [19][85/200]	Time 0.654 (0.623)	Total loss 2.765 (2.822)
Epoch: [19][90/200]	Time 0.490 (0.617)	Total loss 2.582 (2.812)
Epoch: [19][95/200]	Time 0.552 (0.613)	Total loss 2.866 (2.814)
Epoch: [19][100/200]	Time 0.517 (0.609)	Total loss 3.237 (2.817)
Epoch: [19][105/200]	Time 0.507 (0.605)	Total loss 2.796 (2.813)
Epoch: [19][110/200]	Time 0.536 (0.615)	Total loss 3.294 (2.818)
Epoch: [19][115/200]	Time 0.527 (0.611)	Total loss 2.691 (2.815)
Epoch: [19][120/200]	Time 0.503 (0.608)	Total loss 2.981 (2.813)
Epoch: [19][125/200]	Time 0.679 (0.606)	Total loss 2.962 (2.817)
Epoch: [19][130/200]	Time 0.504 (0.602)	Total loss 2.891 (2.813)
Epoch: [19][135/200]	Time 0.551 (0.601)	Total loss 3.142 (2.810)
Epoch: [19][140/200]	Time 0.502 (0.598)	Total loss 2.555 (2.808)
Epoch: [19][145/200]	Time 0.507 (0.597)	Total loss 2.367 (2.803)
Epoch: [19][150/200]	Time 0.507 (0.595)	Total loss 3.122 (2.807)
Epoch: [19][155/200]	Time 0.509 (0.593)	Total loss 3.000 (2.808)
Epoch: [19][160/200]	Time 0.536 (0.600)	Total loss 2.473 (2.809)
Epoch: [19][165/200]	Time 0.713 (0.599)	Total loss 2.989 (2.814)
Epoch: [19][170/200]	Time 0.553 (0.597)	Total loss 2.833 (2.814)
Epoch: [19][175/200]	Time 0.498 (0.596)	Total loss 2.728 (2.809)
Epoch: [19][180/200]	Time 0.526 (0.594)	Total loss 2.847 (2.809)
Epoch: [19][185/200]	Time 0.489 (0.593)	Total loss 2.675 (2.807)
Epoch: [19][190/200]	Time 0.564 (0.593)	Total loss 3.016 (2.808)
Epoch: [19][195/200]	Time 0.523 (0.591)	Total loss 2.319 (2.809)
Epoch: [19][200/200]	Time 1.786 (0.596)	Total loss 2.660 (2.808)
==> start training epoch 20 	 ==> learning rate = 0.00035
Epoch: [20][5/200]	Time 0.685 (1.200)	Total loss 2.852 (2.847)
Epoch: [20][10/200]	Time 0.556 (0.866)	Total loss 3.026 (2.886)
Epoch: [20][15/200]	Time 0.550 (0.769)	Total loss 2.652 (2.889)
Epoch: [20][20/200]	Time 0.536 (0.708)	Total loss 2.422 (2.845)
Epoch: [20][25/200]	Time 0.522 (0.681)	Total loss 2.575 (2.795)
Epoch: [20][30/200]	Time 0.560 (0.664)	Total loss 2.948 (2.805)
Epoch: [20][35/200]	Time 0.526 (0.646)	Total loss 2.859 (2.814)
Epoch: [20][40/200]	Time 0.524 (0.634)	Total loss 2.669 (2.808)
Epoch: [20][45/200]	Time 0.702 (0.626)	Total loss 2.991 (2.824)
Epoch: [20][50/200]	Time 0.506 (0.617)	Total loss 2.960 (2.814)
Epoch: [20][55/200]	Time 0.570 (0.612)	Total loss 2.718 (2.808)
Epoch: [20][60/200]	Time 0.557 (0.605)	Total loss 2.911 (2.814)
Epoch: [20][65/200]	Time 0.545 (0.602)	Total loss 2.695 (2.808)
Epoch: [20][70/200]	Time 0.536 (0.617)	Total loss 2.251 (2.802)
Epoch: [20][75/200]	Time 0.522 (0.612)	Total loss 2.602 (2.793)
Epoch: [20][80/200]	Time 0.534 (0.609)	Total loss 2.500 (2.789)
Epoch: [20][85/200]	Time 0.702 (0.606)	Total loss 2.646 (2.778)
Epoch: [20][90/200]	Time 0.520 (0.602)	Total loss 2.669 (2.776)
Epoch: [20][95/200]	Time 0.497 (0.612)	Total loss 2.697 (2.770)
Epoch: [20][100/200]	Time 0.561 (0.622)	Total loss 2.545 (2.765)
Epoch: [20][105/200]	Time 0.504 (0.618)	Total loss 2.835 (2.765)
Epoch: [20][110/200]	Time 0.508 (0.616)	Total loss 2.615 (2.763)
Epoch: [20][115/200]	Time 0.476 (0.611)	Total loss 2.783 (2.767)
Epoch: [20][120/200]	Time 0.513 (0.608)	Total loss 2.873 (2.766)
Epoch: [20][125/200]	Time 0.693 (0.605)	Total loss 3.185 (2.774)
Epoch: [20][130/200]	Time 0.522 (0.602)	Total loss 2.837 (2.770)
Epoch: [20][135/200]	Time 0.520 (0.601)	Total loss 2.780 (2.773)
Epoch: [20][140/200]	Time 0.507 (0.597)	Total loss 2.529 (2.765)
Epoch: [20][145/200]	Time 0.495 (0.596)	Total loss 3.274 (2.772)
Epoch: [20][150/200]	Time 0.544 (0.595)	Total loss 3.192 (2.771)
Epoch: [20][155/200]	Time 0.491 (0.593)	Total loss 2.787 (2.770)
Epoch: [20][160/200]	Time 0.564 (0.592)	Total loss 2.467 (2.772)
Epoch: [20][165/200]	Time 0.696 (0.591)	Total loss 2.743 (2.771)
Epoch: [20][170/200]	Time 0.545 (0.590)	Total loss 2.715 (2.771)
Epoch: [20][175/200]	Time 0.516 (0.589)	Total loss 2.607 (2.765)
Epoch: [20][180/200]	Time 0.476 (0.587)	Total loss 3.049 (2.763)
Epoch: [20][185/200]	Time 0.508 (0.591)	Total loss 2.210 (2.761)
Epoch: [20][190/200]	Time 0.532 (0.596)	Total loss 2.810 (2.762)
Epoch: [20][195/200]	Time 0.504 (0.594)	Total loss 2.726 (2.760)
Epoch: [20][200/200]	Time 0.495 (0.592)	Total loss 2.925 (2.759)
==> start training epoch 21 	 ==> learning rate = 0.00035
Epoch: [21][5/200]	Time 0.662 (1.072)	Total loss 2.881 (2.646)
Epoch: [21][10/200]	Time 0.501 (0.795)	Total loss 2.853 (2.720)
Epoch: [21][15/200]	Time 0.522 (0.716)	Total loss 2.759 (2.757)
Epoch: [21][20/200]	Time 0.560 (0.667)	Total loss 2.482 (2.770)
Epoch: [21][25/200]	Time 0.495 (0.646)	Total loss 3.127 (2.787)
Epoch: [21][30/200]	Time 0.502 (0.629)	Total loss 2.885 (2.785)
Epoch: [21][35/200]	Time 0.516 (0.614)	Total loss 2.797 (2.778)
Epoch: [21][40/200]	Time 0.508 (0.606)	Total loss 2.938 (2.790)
Epoch: [21][45/200]	Time 0.637 (0.600)	Total loss 2.774 (2.787)
Epoch: [21][50/200]	Time 0.501 (0.593)	Total loss 2.675 (2.774)
Epoch: [21][55/200]	Time 0.550 (0.589)	Total loss 2.475 (2.762)
Epoch: [21][60/200]	Time 0.503 (0.583)	Total loss 2.970 (2.775)
Epoch: [21][65/200]	Time 0.527 (0.581)	Total loss 2.716 (2.775)
Epoch: [21][70/200]	Time 0.469 (0.578)	Total loss 2.683 (2.775)
Epoch: [21][75/200]	Time 0.486 (0.573)	Total loss 2.725 (2.776)
Epoch: [21][80/200]	Time 0.509 (0.583)	Total loss 2.830 (2.778)
Epoch: [21][85/200]	Time 0.679 (0.582)	Total loss 2.439 (2.766)
Epoch: [21][90/200]	Time 0.496 (0.578)	Total loss 2.726 (2.765)
Epoch: [21][95/200]	Time 1.637 (0.588)	Total loss 2.717 (2.768)
Epoch: [21][100/200]	Time 0.490 (0.585)	Total loss 2.816 (2.769)
Epoch: [21][105/200]	Time 0.563 (0.583)	Total loss 2.741 (2.767)
Epoch: [21][110/200]	Time 0.521 (0.582)	Total loss 2.532 (2.762)
Epoch: [21][115/200]	Time 0.501 (0.580)	Total loss 3.264 (2.768)
Epoch: [21][120/200]	Time 0.496 (0.578)	Total loss 3.055 (2.776)
Epoch: [21][125/200]	Time 0.664 (0.577)	Total loss 2.996 (2.777)
Epoch: [21][130/200]	Time 0.578 (0.575)	Total loss 3.008 (2.777)
Epoch: [21][135/200]	Time 0.524 (0.574)	Total loss 2.756 (2.774)
Epoch: [21][140/200]	Time 0.490 (0.571)	Total loss 2.814 (2.775)
Epoch: [21][145/200]	Time 0.531 (0.571)	Total loss 2.817 (2.775)
Epoch: [21][150/200]	Time 0.527 (0.570)	Total loss 2.462 (2.776)
Epoch: [21][155/200]	Time 0.497 (0.577)	Total loss 2.751 (2.776)
Epoch: [21][160/200]	Time 0.501 (0.576)	Total loss 2.584 (2.773)
Epoch: [21][165/200]	Time 0.648 (0.574)	Total loss 2.720 (2.772)
Epoch: [21][170/200]	Time 0.505 (0.572)	Total loss 2.889 (2.769)
Epoch: [21][175/200]	Time 0.521 (0.578)	Total loss 3.007 (2.769)
Epoch: [21][180/200]	Time 0.498 (0.577)	Total loss 2.513 (2.764)
Epoch: [21][185/200]	Time 0.507 (0.576)	Total loss 2.620 (2.761)
Epoch: [21][190/200]	Time 0.541 (0.576)	Total loss 2.569 (2.759)
Epoch: [21][195/200]	Time 0.524 (0.575)	Total loss 2.356 (2.756)
Epoch: [21][200/200]	Time 0.542 (0.575)	Total loss 2.933 (2.761)
==> start training epoch 22 	 ==> learning rate = 0.00035
Epoch: [22][5/200]	Time 0.643 (1.153)	Total loss 2.700 (2.765)
Epoch: [22][10/200]	Time 0.483 (0.943)	Total loss 2.634 (2.767)
Epoch: [22][15/200]	Time 0.522 (0.812)	Total loss 2.904 (2.740)
Epoch: [22][20/200]	Time 0.500 (0.739)	Total loss 2.137 (2.730)
Epoch: [22][25/200]	Time 0.539 (0.701)	Total loss 2.939 (2.723)
Epoch: [22][30/200]	Time 0.524 (0.677)	Total loss 2.448 (2.761)
Epoch: [22][35/200]	Time 0.500 (0.654)	Total loss 2.362 (2.778)
Epoch: [22][40/200]	Time 0.500 (0.640)	Total loss 2.693 (2.763)
Epoch: [22][45/200]	Time 0.672 (0.629)	Total loss 2.550 (2.748)
Epoch: [22][50/200]	Time 0.478 (0.616)	Total loss 3.024 (2.742)
Epoch: [22][55/200]	Time 0.495 (0.609)	Total loss 3.070 (2.749)
Epoch: [22][60/200]	Time 0.500 (0.600)	Total loss 2.833 (2.756)
Epoch: [22][65/200]	Time 1.794 (0.615)	Total loss 2.578 (2.753)
Epoch: [22][70/200]	Time 0.501 (0.611)	Total loss 2.556 (2.734)
Epoch: [22][75/200]	Time 0.561 (0.606)	Total loss 2.403 (2.716)
Epoch: [22][80/200]	Time 0.516 (0.603)	Total loss 2.867 (2.710)
Epoch: [22][85/200]	Time 0.703 (0.601)	Total loss 2.698 (2.705)
Epoch: [22][90/200]	Time 0.532 (0.597)	Total loss 3.068 (2.713)
Epoch: [22][95/200]	Time 0.504 (0.595)	Total loss 2.763 (2.714)
Epoch: [22][100/200]	Time 0.492 (0.591)	Total loss 2.736 (2.716)
Epoch: [22][105/200]	Time 0.509 (0.589)	Total loss 2.599 (2.718)
Epoch: [22][110/200]	Time 0.511 (0.587)	Total loss 3.010 (2.722)
Epoch: [22][115/200]	Time 0.501 (0.584)	Total loss 2.693 (2.719)
Epoch: [22][120/200]	Time 0.518 (0.582)	Total loss 2.545 (2.718)
Epoch: [22][125/200]	Time 0.695 (0.590)	Total loss 2.371 (2.716)
Epoch: [22][130/200]	Time 0.478 (0.587)	Total loss 2.893 (2.716)
Epoch: [22][135/200]	Time 0.494 (0.585)	Total loss 2.710 (2.719)
Epoch: [22][140/200]	Time 0.515 (0.583)	Total loss 2.582 (2.718)
Epoch: [22][145/200]	Time 0.466 (0.581)	Total loss 2.697 (2.716)
Epoch: [22][150/200]	Time 0.653 (0.579)	Total loss 2.881 (2.713)
Epoch: [22][155/200]	Time 0.500 (0.577)	Total loss 2.751 (2.710)
Epoch: [22][160/200]	Time 0.500 (0.582)	Total loss 2.794 (2.706)
Epoch: [22][165/200]	Time 0.556 (0.580)	Total loss 2.363 (2.705)
Epoch: [22][170/200]	Time 0.543 (0.580)	Total loss 2.436 (2.702)
Epoch: [22][175/200]	Time 0.542 (0.578)	Total loss 3.158 (2.706)
Epoch: [22][180/200]	Time 0.526 (0.578)	Total loss 2.763 (2.706)
Epoch: [22][185/200]	Time 0.660 (0.577)	Total loss 2.686 (2.704)
Epoch: [22][190/200]	Time 0.496 (0.576)	Total loss 2.729 (2.701)
Epoch: [22][195/200]	Time 0.638 (0.575)	Total loss 2.977 (2.706)
Epoch: [22][200/200]	Time 0.525 (0.573)	Total loss 2.840 (2.709)
==> start training epoch 23 	 ==> learning rate = 0.00035
Epoch: [23][5/200]	Time 0.529 (1.215)	Total loss 2.904 (2.630)
Epoch: [23][10/200]	Time 0.540 (1.019)	Total loss 2.564 (2.702)
Epoch: [23][15/200]	Time 0.503 (0.856)	Total loss 2.662 (2.706)
Epoch: [23][20/200]	Time 0.499 (0.776)	Total loss 2.843 (2.728)
Epoch: [23][25/200]	Time 0.683 (0.732)	Total loss 2.627 (2.722)
Epoch: [23][30/200]	Time 0.506 (0.693)	Total loss 2.726 (2.728)
Epoch: [23][35/200]	Time 0.483 (0.701)	Total loss 2.544 (2.719)
Epoch: [23][40/200]	Time 0.536 (0.682)	Total loss 2.623 (2.715)
Epoch: [23][45/200]	Time 0.561 (0.664)	Total loss 2.270 (2.723)
Epoch: [23][50/200]	Time 0.539 (0.651)	Total loss 2.638 (2.719)
Epoch: [23][55/200]	Time 0.500 (0.662)	Total loss 2.893 (2.711)
Epoch: [23][60/200]	Time 0.508 (0.649)	Total loss 2.648 (2.724)
Epoch: [23][65/200]	Time 0.483 (0.640)	Total loss 2.555 (2.725)
Epoch: [23][70/200]	Time 0.640 (0.633)	Total loss 2.638 (2.729)
Epoch: [23][75/200]	Time 0.511 (0.626)	Total loss 2.529 (2.713)
Epoch: [23][80/200]	Time 0.514 (0.620)	Total loss 2.652 (2.713)
Epoch: [23][85/200]	Time 0.528 (0.615)	Total loss 2.439 (2.698)
Epoch: [23][90/200]	Time 0.507 (0.611)	Total loss 2.366 (2.697)
Epoch: [23][95/200]	Time 0.542 (0.607)	Total loss 2.661 (2.701)
Epoch: [23][100/200]	Time 0.510 (0.602)	Total loss 2.520 (2.694)
Epoch: [23][105/200]	Time 0.514 (0.599)	Total loss 2.675 (2.687)
Epoch: [23][110/200]	Time 0.498 (0.595)	Total loss 2.368 (2.686)
Epoch: [23][115/200]	Time 0.490 (0.592)	Total loss 2.799 (2.689)
Epoch: [23][120/200]	Time 0.635 (0.589)	Total loss 2.561 (2.691)
Epoch: [23][125/200]	Time 0.495 (0.586)	Total loss 2.819 (2.697)
Epoch: [23][130/200]	Time 0.533 (0.585)	Total loss 2.859 (2.700)
Epoch: [23][135/200]	Time 0.543 (0.583)	Total loss 2.530 (2.695)
Epoch: [23][140/200]	Time 0.529 (0.582)	Total loss 2.689 (2.690)
Epoch: [23][145/200]	Time 0.492 (0.586)	Total loss 2.399 (2.690)
Epoch: [23][150/200]	Time 0.495 (0.593)	Total loss 2.714 (2.688)
Epoch: [23][155/200]	Time 0.640 (0.591)	Total loss 2.811 (2.689)
Epoch: [23][160/200]	Time 0.527 (0.589)	Total loss 2.548 (2.687)
Epoch: [23][165/200]	Time 0.509 (0.587)	Total loss 2.713 (2.692)
Epoch: [23][170/200]	Time 0.641 (0.586)	Total loss 2.700 (2.690)
Epoch: [23][175/200]	Time 0.563 (0.585)	Total loss 2.683 (2.686)
Epoch: [23][180/200]	Time 0.540 (0.584)	Total loss 2.497 (2.685)
Epoch: [23][185/200]	Time 0.558 (0.582)	Total loss 3.136 (2.687)
Epoch: [23][190/200]	Time 0.507 (0.581)	Total loss 2.505 (2.685)
Epoch: [23][195/200]	Time 0.484 (0.580)	Total loss 2.758 (2.686)
Epoch: [23][200/200]	Time 0.651 (0.580)	Total loss 2.645 (2.684)
==> start training epoch 24 	 ==> learning rate = 0.00035
Epoch: [24][5/200]	Time 0.561 (1.312)	Total loss 2.606 (2.673)
Epoch: [24][10/200]	Time 0.520 (0.932)	Total loss 2.719 (2.701)
Epoch: [24][15/200]	Time 0.682 (0.804)	Total loss 2.373 (2.652)
Epoch: [24][20/200]	Time 0.508 (0.735)	Total loss 3.083 (2.715)
Epoch: [24][25/200]	Time 0.505 (0.701)	Total loss 2.404 (2.709)
Epoch: [24][30/200]	Time 0.512 (0.671)	Total loss 2.923 (2.702)
Epoch: [24][35/200]	Time 0.496 (0.652)	Total loss 2.805 (2.727)
Epoch: [24][40/200]	Time 0.505 (0.669)	Total loss 2.831 (2.726)
Epoch: [24][45/200]	Time 0.512 (0.653)	Total loss 2.680 (2.728)
Epoch: [24][50/200]	Time 0.554 (0.643)	Total loss 2.739 (2.729)
Epoch: [24][55/200]	Time 0.658 (0.634)	Total loss 2.556 (2.714)
Epoch: [24][60/200]	Time 1.700 (0.645)	Total loss 2.759 (2.724)
Epoch: [24][65/200]	Time 1.789 (0.655)	Total loss 2.688 (2.719)
Epoch: [24][70/200]	Time 0.485 (0.644)	Total loss 2.186 (2.705)
Epoch: [24][75/200]	Time 0.522 (0.638)	Total loss 2.857 (2.708)
Epoch: [24][80/200]	Time 0.491 (0.632)	Total loss 2.598 (2.700)
Epoch: [24][85/200]	Time 0.509 (0.625)	Total loss 2.376 (2.701)
Epoch: [24][90/200]	Time 0.513 (0.619)	Total loss 2.679 (2.697)
Epoch: [24][95/200]	Time 0.665 (0.616)	Total loss 2.780 (2.699)
Epoch: [24][100/200]	Time 0.536 (0.611)	Total loss 2.305 (2.701)
Epoch: [24][105/200]	Time 0.514 (0.609)	Total loss 2.568 (2.697)
Epoch: [24][110/200]	Time 0.498 (0.605)	Total loss 2.974 (2.706)
Epoch: [24][115/200]	Time 0.495 (0.602)	Total loss 2.695 (2.697)
Epoch: [24][120/200]	Time 0.596 (0.600)	Total loss 2.336 (2.693)
Epoch: [24][125/200]	Time 0.481 (0.596)	Total loss 2.549 (2.690)
Epoch: [24][130/200]	Time 1.766 (0.604)	Total loss 2.701 (2.690)
Epoch: [24][135/200]	Time 0.718 (0.602)	Total loss 2.443 (2.680)
Epoch: [24][140/200]	Time 0.517 (0.600)	Total loss 2.732 (2.681)
Epoch: [24][145/200]	Time 0.517 (0.598)	Total loss 2.985 (2.680)
Epoch: [24][150/200]	Time 0.500 (0.596)	Total loss 2.752 (2.679)
Epoch: [24][155/200]	Time 0.470 (0.594)	Total loss 3.123 (2.686)
Epoch: [24][160/200]	Time 0.519 (0.593)	Total loss 2.392 (2.686)
Epoch: [24][165/200]	Time 0.542 (0.591)	Total loss 2.368 (2.686)
Epoch: [24][170/200]	Time 0.556 (0.590)	Total loss 2.398 (2.686)
Epoch: [24][175/200]	Time 0.694 (0.597)	Total loss 3.046 (2.684)
Epoch: [24][180/200]	Time 0.539 (0.594)	Total loss 3.067 (2.690)
Epoch: [24][185/200]	Time 0.536 (0.593)	Total loss 2.817 (2.688)
Epoch: [24][190/200]	Time 0.512 (0.591)	Total loss 2.478 (2.688)
Epoch: [24][195/200]	Time 0.537 (0.590)	Total loss 2.445 (2.684)
Epoch: [24][200/200]	Time 0.522 (0.590)	Total loss 2.695 (2.682)
==> start training epoch 25 	 ==> learning rate = 0.00035
Epoch: [25][5/200]	Time 0.527 (1.191)	Total loss 2.933 (2.687)
Epoch: [25][10/200]	Time 0.530 (0.871)	Total loss 2.308 (2.605)
Epoch: [25][15/200]	Time 0.702 (0.768)	Total loss 2.771 (2.655)
Epoch: [25][20/200]	Time 0.526 (0.708)	Total loss 2.587 (2.624)
Epoch: [25][25/200]	Time 0.517 (0.725)	Total loss 3.167 (2.631)
Epoch: [25][30/200]	Time 0.545 (0.694)	Total loss 2.712 (2.638)
Epoch: [25][35/200]	Time 0.512 (0.673)	Total loss 2.951 (2.650)
Epoch: [25][40/200]	Time 0.550 (0.659)	Total loss 2.441 (2.634)
Epoch: [25][45/200]	Time 0.554 (0.645)	Total loss 2.475 (2.645)
Epoch: [25][50/200]	Time 0.518 (0.637)	Total loss 2.812 (2.638)
Epoch: [25][55/200]	Time 0.693 (0.629)	Total loss 2.773 (2.635)
Epoch: [25][60/200]	Time 0.502 (0.619)	Total loss 2.190 (2.640)
Epoch: [25][65/200]	Time 0.512 (0.614)	Total loss 2.568 (2.632)
Epoch: [25][70/200]	Time 0.516 (0.608)	Total loss 2.601 (2.629)
Epoch: [25][75/200]	Time 0.514 (0.604)	Total loss 2.430 (2.621)
Epoch: [25][80/200]	Time 0.495 (0.602)	Total loss 2.404 (2.619)
Epoch: [25][85/200]	Time 0.493 (0.597)	Total loss 2.726 (2.618)
Epoch: [25][90/200]	Time 0.509 (0.609)	Total loss 2.850 (2.622)
Epoch: [25][95/200]	Time 0.718 (0.606)	Total loss 2.547 (2.626)
Epoch: [25][100/200]	Time 0.546 (0.604)	Total loss 2.660 (2.620)
Epoch: [25][105/200]	Time 0.559 (0.602)	Total loss 2.474 (2.615)
Epoch: [25][110/200]	Time 0.521 (0.599)	Total loss 2.522 (2.616)
Epoch: [25][115/200]	Time 0.478 (0.595)	Total loss 2.517 (2.623)
Epoch: [25][120/200]	Time 0.535 (0.603)	Total loss 2.486 (2.621)
Epoch: [25][125/200]	Time 0.533 (0.612)	Total loss 2.670 (2.621)
Epoch: [25][130/200]	Time 0.481 (0.609)	Total loss 2.524 (2.616)
Epoch: [25][135/200]	Time 0.748 (0.607)	Total loss 2.507 (2.617)
Epoch: [25][140/200]	Time 0.510 (0.604)	Total loss 2.574 (2.615)
Epoch: [25][145/200]	Time 0.513 (0.602)	Total loss 2.468 (2.615)
Epoch: [25][150/200]	Time 0.530 (0.599)	Total loss 2.545 (2.616)
Epoch: [25][155/200]	Time 0.502 (0.598)	Total loss 2.763 (2.612)
Epoch: [25][160/200]	Time 0.514 (0.596)	Total loss 2.206 (2.611)
Epoch: [25][165/200]	Time 0.536 (0.594)	Total loss 2.547 (2.611)
Epoch: [25][170/200]	Time 0.513 (0.593)	Total loss 2.809 (2.614)
Epoch: [25][175/200]	Time 0.671 (0.592)	Total loss 2.747 (2.612)
Epoch: [25][180/200]	Time 0.526 (0.590)	Total loss 2.810 (2.611)
Epoch: [25][185/200]	Time 0.504 (0.589)	Total loss 2.690 (2.611)
Epoch: [25][190/200]	Time 0.509 (0.587)	Total loss 2.446 (2.608)
Epoch: [25][195/200]	Time 0.539 (0.586)	Total loss 2.234 (2.603)
Epoch: [25][200/200]	Time 0.533 (0.591)	Total loss 2.330 (2.598)
==> start training epoch 26 	 ==> learning rate = 0.00035
Epoch: [26][5/200]	Time 0.509 (1.150)	Total loss 2.760 (2.681)
Epoch: [26][10/200]	Time 0.490 (0.970)	Total loss 2.415 (2.570)
Epoch: [26][15/200]	Time 0.715 (0.824)	Total loss 2.597 (2.568)
Epoch: [26][20/200]	Time 0.523 (0.745)	Total loss 2.371 (2.564)
Epoch: [26][25/200]	Time 0.535 (0.707)	Total loss 2.508 (2.560)
Epoch: [26][30/200]	Time 0.525 (0.675)	Total loss 2.328 (2.572)
Epoch: [26][35/200]	Time 0.504 (0.657)	Total loss 2.259 (2.575)
Epoch: [26][40/200]	Time 0.516 (0.645)	Total loss 2.708 (2.574)
Epoch: [26][45/200]	Time 0.546 (0.633)	Total loss 2.520 (2.586)
Epoch: [26][50/200]	Time 0.502 (0.627)	Total loss 2.680 (2.592)
Epoch: [26][55/200]	Time 0.670 (0.620)	Total loss 2.777 (2.592)
Epoch: [26][60/200]	Time 0.518 (0.610)	Total loss 2.923 (2.586)
Epoch: [26][65/200]	Time 0.566 (0.607)	Total loss 2.303 (2.579)
Epoch: [26][70/200]	Time 0.568 (0.601)	Total loss 2.205 (2.585)
Epoch: [26][75/200]	Time 0.581 (0.598)	Total loss 2.766 (2.594)
Epoch: [26][80/200]	Time 0.493 (0.595)	Total loss 2.500 (2.601)
Epoch: [26][85/200]	Time 0.546 (0.591)	Total loss 2.855 (2.595)
Epoch: [26][90/200]	Time 0.515 (0.590)	Total loss 1.993 (2.581)
Epoch: [26][95/200]	Time 0.661 (0.587)	Total loss 2.449 (2.583)
Epoch: [26][100/200]	Time 0.545 (0.584)	Total loss 2.171 (2.585)
Epoch: [26][105/200]	Time 0.528 (0.595)	Total loss 2.838 (2.582)
Epoch: [26][110/200]	Time 0.524 (0.592)	Total loss 2.826 (2.586)
Epoch: [26][115/200]	Time 0.473 (0.599)	Total loss 2.901 (2.583)
Epoch: [26][120/200]	Time 0.560 (0.598)	Total loss 2.977 (2.585)
Epoch: [26][125/200]	Time 0.499 (0.596)	Total loss 2.680 (2.583)
Epoch: [26][130/200]	Time 0.517 (0.594)	Total loss 2.600 (2.579)
Epoch: [26][135/200]	Time 0.719 (0.593)	Total loss 2.825 (2.582)
Epoch: [26][140/200]	Time 0.515 (0.591)	Total loss 2.643 (2.580)
Epoch: [26][145/200]	Time 0.519 (0.590)	Total loss 2.581 (2.579)
Epoch: [26][150/200]	Time 0.503 (0.588)	Total loss 2.858 (2.581)
Epoch: [26][155/200]	Time 0.525 (0.587)	Total loss 3.078 (2.579)
Epoch: [26][160/200]	Time 0.534 (0.586)	Total loss 3.000 (2.581)
Epoch: [26][165/200]	Time 0.516 (0.584)	Total loss 2.461 (2.579)
Epoch: [26][170/200]	Time 0.514 (0.583)	Total loss 2.327 (2.583)
Epoch: [26][175/200]	Time 0.502 (0.582)	Total loss 2.681 (2.584)
Epoch: [26][180/200]	Time 0.507 (0.589)	Total loss 2.385 (2.580)
Epoch: [26][185/200]	Time 0.502 (0.588)	Total loss 2.523 (2.579)
Epoch: [26][190/200]	Time 0.506 (0.586)	Total loss 2.422 (2.580)
Epoch: [26][195/200]	Time 1.742 (0.591)	Total loss 2.489 (2.579)
Epoch: [26][200/200]	Time 0.523 (0.589)	Total loss 2.154 (2.579)
==> start training epoch 27 	 ==> learning rate = 0.00035
Epoch: [27][5/200]	Time 0.541 (1.128)	Total loss 2.516 (2.605)
Epoch: [27][10/200]	Time 0.528 (0.839)	Total loss 2.672 (2.669)
Epoch: [27][15/200]	Time 0.551 (0.741)	Total loss 2.284 (2.611)
Epoch: [27][20/200]	Time 0.521 (0.688)	Total loss 2.472 (2.600)
Epoch: [27][25/200]	Time 1.857 (0.713)	Total loss 2.196 (2.556)
Epoch: [27][30/200]	Time 0.501 (0.686)	Total loss 2.554 (2.554)
Epoch: [27][35/200]	Time 0.650 (0.665)	Total loss 2.585 (2.572)
Epoch: [27][40/200]	Time 0.498 (0.646)	Total loss 2.581 (2.562)
Epoch: [27][45/200]	Time 0.507 (0.635)	Total loss 2.099 (2.557)
Epoch: [27][50/200]	Time 0.549 (0.625)	Total loss 2.543 (2.555)
Epoch: [27][55/200]	Time 0.512 (0.618)	Total loss 2.685 (2.559)
Epoch: [27][60/200]	Time 0.507 (0.611)	Total loss 2.874 (2.575)
Epoch: [27][65/200]	Time 0.660 (0.605)	Total loss 2.409 (2.576)
Epoch: [27][70/200]	Time 0.508 (0.598)	Total loss 2.651 (2.577)
Epoch: [27][75/200]	Time 0.504 (0.595)	Total loss 2.672 (2.576)
Epoch: [27][80/200]	Time 0.493 (0.592)	Total loss 2.653 (2.576)
Epoch: [27][85/200]	Time 0.491 (0.586)	Total loss 2.973 (2.587)
Epoch: [27][90/200]	Time 0.501 (0.596)	Total loss 2.291 (2.568)
Epoch: [27][95/200]	Time 0.519 (0.594)	Total loss 2.514 (2.566)
Epoch: [27][100/200]	Time 0.491 (0.590)	Total loss 2.772 (2.567)
Epoch: [27][105/200]	Time 0.503 (0.588)	Total loss 2.250 (2.565)
Epoch: [27][110/200]	Time 0.667 (0.586)	Total loss 2.388 (2.561)
Epoch: [27][115/200]	Time 0.532 (0.583)	Total loss 2.653 (2.553)
Epoch: [27][120/200]	Time 0.519 (0.582)	Total loss 2.630 (2.551)
Epoch: [27][125/200]	Time 0.507 (0.579)	Total loss 2.843 (2.550)
Epoch: [27][130/200]	Time 0.533 (0.578)	Total loss 2.722 (2.551)
Epoch: [27][135/200]	Time 0.525 (0.577)	Total loss 2.847 (2.547)
Epoch: [27][140/200]	Time 0.472 (0.584)	Total loss 2.575 (2.552)
Epoch: [27][145/200]	Time 0.537 (0.582)	Total loss 2.707 (2.553)
Epoch: [27][150/200]	Time 0.659 (0.581)	Total loss 2.167 (2.553)
Epoch: [27][155/200]	Time 0.538 (0.579)	Total loss 2.908 (2.559)
Epoch: [27][160/200]	Time 0.519 (0.578)	Total loss 2.304 (2.553)
Epoch: [27][165/200]	Time 0.534 (0.577)	Total loss 2.486 (2.550)
Epoch: [27][170/200]	Time 0.535 (0.577)	Total loss 2.858 (2.556)
Epoch: [27][175/200]	Time 0.494 (0.576)	Total loss 2.012 (2.551)
Epoch: [27][180/200]	Time 0.504 (0.574)	Total loss 2.272 (2.551)
Epoch: [27][185/200]	Time 0.535 (0.579)	Total loss 2.915 (2.553)
Epoch: [27][190/200]	Time 0.709 (0.579)	Total loss 2.368 (2.555)
Epoch: [27][195/200]	Time 0.489 (0.577)	Total loss 2.772 (2.562)
Epoch: [27][200/200]	Time 0.505 (0.577)	Total loss 2.648 (2.564)
==> start training epoch 28 	 ==> learning rate = 0.00035
Epoch: [28][5/200]	Time 0.500 (1.145)	Total loss 2.558 (2.485)
Epoch: [28][10/200]	Time 0.511 (0.847)	Total loss 2.648 (2.566)
Epoch: [28][15/200]	Time 0.511 (0.749)	Total loss 2.820 (2.575)
Epoch: [28][20/200]	Time 0.499 (0.690)	Total loss 2.237 (2.563)
Epoch: [28][25/200]	Time 0.504 (0.661)	Total loss 2.768 (2.538)
Epoch: [28][30/200]	Time 0.679 (0.642)	Total loss 2.256 (2.518)
Epoch: [28][35/200]	Time 0.504 (0.663)	Total loss 2.401 (2.510)
Epoch: [28][40/200]	Time 0.508 (0.649)	Total loss 2.333 (2.505)
Epoch: [28][45/200]	Time 0.532 (0.636)	Total loss 2.708 (2.509)
Epoch: [28][50/200]	Time 0.525 (0.629)	Total loss 2.569 (2.512)
Epoch: [28][55/200]	Time 0.526 (0.642)	Total loss 2.582 (2.508)
Epoch: [28][60/200]	Time 0.520 (0.632)	Total loss 2.796 (2.497)
Epoch: [28][65/200]	Time 0.550 (0.627)	Total loss 2.531 (2.487)
Epoch: [28][70/200]	Time 0.637 (0.621)	Total loss 2.659 (2.493)
Epoch: [28][75/200]	Time 0.571 (0.633)	Total loss 2.588 (2.490)
Epoch: [28][80/200]	Time 0.534 (0.628)	Total loss 2.276 (2.495)
Epoch: [28][85/200]	Time 0.516 (0.622)	Total loss 2.060 (2.490)
Epoch: [28][90/200]	Time 0.527 (0.619)	Total loss 2.260 (2.481)
Epoch: [28][95/200]	Time 0.546 (0.615)	Total loss 2.166 (2.486)
Epoch: [28][100/200]	Time 0.529 (0.611)	Total loss 2.306 (2.484)
Epoch: [28][105/200]	Time 0.530 (0.609)	Total loss 2.440 (2.489)
Epoch: [28][110/200]	Time 0.685 (0.607)	Total loss 2.505 (2.480)
Epoch: [28][115/200]	Time 0.523 (0.603)	Total loss 2.497 (2.479)
Epoch: [28][120/200]	Time 0.522 (0.601)	Total loss 2.619 (2.482)
Epoch: [28][125/200]	Time 0.510 (0.597)	Total loss 2.147 (2.475)
Epoch: [28][130/200]	Time 0.507 (0.596)	Total loss 2.217 (2.471)
Epoch: [28][135/200]	Time 0.509 (0.593)	Total loss 2.441 (2.473)
Epoch: [28][140/200]	Time 0.548 (0.591)	Total loss 2.633 (2.473)
Epoch: [28][145/200]	Time 0.502 (0.590)	Total loss 2.755 (2.481)
Epoch: [28][150/200]	Time 0.656 (0.588)	Total loss 2.850 (2.484)
Epoch: [28][155/200]	Time 0.512 (0.586)	Total loss 2.567 (2.488)
Epoch: [28][160/200]	Time 0.510 (0.585)	Total loss 2.621 (2.486)
Epoch: [28][165/200]	Time 0.501 (0.591)	Total loss 2.066 (2.482)
Epoch: [28][170/200]	Time 0.476 (0.596)	Total loss 2.675 (2.487)
Epoch: [28][175/200]	Time 0.505 (0.595)	Total loss 2.449 (2.486)
Epoch: [28][180/200]	Time 0.521 (0.594)	Total loss 2.469 (2.485)
Epoch: [28][185/200]	Time 0.553 (0.593)	Total loss 2.309 (2.485)
Epoch: [28][190/200]	Time 0.672 (0.592)	Total loss 2.519 (2.484)
Epoch: [28][195/200]	Time 0.529 (0.590)	Total loss 2.633 (2.488)
Epoch: [28][200/200]	Time 0.561 (0.590)	Total loss 2.478 (2.488)
==> start training epoch 29 	 ==> learning rate = 0.00035
Epoch: [29][5/200]	Time 0.523 (1.227)	Total loss 2.441 (2.565)
Epoch: [29][10/200]	Time 0.494 (0.883)	Total loss 2.276 (2.513)
Epoch: [29][15/200]	Time 0.491 (0.768)	Total loss 2.394 (2.529)
Epoch: [29][20/200]	Time 0.545 (0.705)	Total loss 2.476 (2.512)
Epoch: [29][25/200]	Time 0.522 (0.672)	Total loss 2.671 (2.548)
Epoch: [29][30/200]	Time 0.658 (0.651)	Total loss 2.540 (2.564)
Epoch: [29][35/200]	Time 0.498 (0.632)	Total loss 2.580 (2.534)
Epoch: [29][40/200]	Time 0.504 (0.622)	Total loss 2.314 (2.517)
Epoch: [29][45/200]	Time 0.505 (0.609)	Total loss 2.470 (2.512)
Epoch: [29][50/200]	Time 0.521 (0.603)	Total loss 2.441 (2.505)
Epoch: [29][55/200]	Time 0.505 (0.597)	Total loss 2.548 (2.496)
Epoch: [29][60/200]	Time 1.803 (0.611)	Total loss 2.298 (2.500)
Epoch: [29][65/200]	Time 0.539 (0.609)	Total loss 2.433 (2.490)
Epoch: [29][70/200]	Time 0.699 (0.606)	Total loss 2.057 (2.476)
Epoch: [29][75/200]	Time 0.502 (0.600)	Total loss 2.131 (2.470)
Epoch: [29][80/200]	Time 0.540 (0.614)	Total loss 2.725 (2.469)
Epoch: [29][85/200]	Time 0.532 (0.609)	Total loss 2.426 (2.458)
Epoch: [29][90/200]	Time 0.507 (0.622)	Total loss 2.895 (2.475)
Epoch: [29][95/200]	Time 0.533 (0.619)	Total loss 2.712 (2.482)
Epoch: [29][100/200]	Time 0.545 (0.615)	Total loss 2.240 (2.478)
Epoch: [29][105/200]	Time 0.514 (0.612)	Total loss 2.666 (2.480)
Epoch: [29][110/200]	Time 0.706 (0.609)	Total loss 2.063 (2.473)
Epoch: [29][115/200]	Time 0.513 (0.605)	Total loss 2.654 (2.468)
Epoch: [29][120/200]	Time 0.490 (0.602)	Total loss 2.455 (2.466)
Epoch: [29][125/200]	Time 0.497 (0.599)	Total loss 2.481 (2.462)
Epoch: [29][130/200]	Time 0.511 (0.597)	Total loss 2.616 (2.467)
Epoch: [29][135/200]	Time 0.507 (0.595)	Total loss 2.388 (2.469)
Epoch: [29][140/200]	Time 0.504 (0.591)	Total loss 2.496 (2.471)
Epoch: [29][145/200]	Time 0.500 (0.589)	Total loss 2.251 (2.474)
Epoch: [29][150/200]	Time 0.666 (0.588)	Total loss 2.553 (2.480)
Epoch: [29][155/200]	Time 0.539 (0.594)	Total loss 2.382 (2.480)
Epoch: [29][160/200]	Time 0.518 (0.592)	Total loss 2.537 (2.482)
Epoch: [29][165/200]	Time 0.527 (0.590)	Total loss 2.434 (2.481)
Epoch: [29][170/200]	Time 0.511 (0.589)	Total loss 2.638 (2.482)
Epoch: [29][175/200]	Time 0.518 (0.587)	Total loss 2.753 (2.484)
Epoch: [29][180/200]	Time 0.520 (0.586)	Total loss 2.165 (2.482)
Epoch: [29][185/200]	Time 0.521 (0.585)	Total loss 2.198 (2.481)
Epoch: [29][190/200]	Time 1.996 (0.591)	Total loss 1.675 (2.473)
Epoch: [29][195/200]	Time 0.518 (0.589)	Total loss 2.528 (2.472)
Epoch: [29][200/200]	Time 0.525 (0.588)	Total loss 2.252 (2.471)
Extract Features: [50/53]	Time 0.124 (0.130)	Data 0.066 (0.063)	
Mean AP: 27.5%
CMC Scores:
  top-1          27.9%
  top-5          48.1%
  top-10         57.7%

 * Finished epoch  29  model mAP: 27.5%  best: 27.5% *

==> start training epoch 30 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [30][5/200]	Time 0.495 (1.258)	Total loss 2.503 (2.373)
Epoch: [30][10/200]	Time 0.584 (0.888)	Total loss 2.597 (2.401)
Epoch: [30][15/200]	Time 0.520 (0.772)	Total loss 2.420 (2.458)
Epoch: [30][20/200]	Time 0.492 (0.716)	Total loss 2.392 (2.441)
Epoch: [30][25/200]	Time 0.509 (0.675)	Total loss 2.085 (2.445)
Epoch: [30][30/200]	Time 0.505 (0.658)	Total loss 2.564 (2.438)
Epoch: [30][35/200]	Time 0.522 (0.643)	Total loss 2.435 (2.440)
Epoch: [30][40/200]	Time 0.494 (0.626)	Total loss 2.652 (2.441)
Epoch: [30][45/200]	Time 0.484 (0.614)	Total loss 2.237 (2.416)
Epoch: [30][50/200]	Time 0.715 (0.631)	Total loss 2.559 (2.402)
Epoch: [30][55/200]	Time 0.501 (0.621)	Total loss 2.211 (2.389)
Epoch: [30][60/200]	Time 0.513 (0.615)	Total loss 2.387 (2.379)
Epoch: [30][65/200]	Time 0.534 (0.609)	Total loss 2.483 (2.373)
Epoch: [30][70/200]	Time 0.684 (0.606)	Total loss 2.086 (2.363)
Epoch: [30][75/200]	Time 0.510 (0.601)	Total loss 2.022 (2.357)
Epoch: [30][80/200]	Time 0.531 (0.599)	Total loss 2.798 (2.359)
Epoch: [30][85/200]	Time 0.720 (0.597)	Total loss 2.565 (2.357)
Epoch: [30][90/200]	Time 0.536 (0.593)	Total loss 2.159 (2.351)
Epoch: [30][95/200]	Time 0.505 (0.591)	Total loss 2.858 (2.352)
Epoch: [30][100/200]	Time 0.497 (0.586)	Total loss 2.045 (2.340)
Epoch: [30][105/200]	Time 0.497 (0.596)	Total loss 2.140 (2.337)
Epoch: [30][110/200]	Time 0.504 (0.594)	Total loss 2.116 (2.323)
Epoch: [30][115/200]	Time 0.528 (0.590)	Total loss 2.299 (2.313)
Epoch: [30][120/200]	Time 0.521 (0.589)	Total loss 2.040 (2.305)
Epoch: [30][125/200]	Time 0.683 (0.587)	Total loss 2.249 (2.304)
Epoch: [30][130/200]	Time 0.514 (0.584)	Total loss 2.130 (2.291)
Epoch: [30][135/200]	Time 0.501 (0.583)	Total loss 2.124 (2.285)
Epoch: [30][140/200]	Time 0.531 (0.589)	Total loss 2.142 (2.280)
Epoch: [30][145/200]	Time 2.000 (0.598)	Total loss 2.181 (2.275)
Epoch: [30][150/200]	Time 0.536 (0.597)	Total loss 1.932 (2.261)
Epoch: [30][155/200]	Time 0.502 (0.594)	Total loss 1.952 (2.258)
Epoch: [30][160/200]	Time 0.507 (0.593)	Total loss 2.158 (2.247)
Epoch: [30][165/200]	Time 0.696 (0.591)	Total loss 2.427 (2.245)
Epoch: [30][170/200]	Time 0.499 (0.589)	Total loss 1.971 (2.237)
Epoch: [30][175/200]	Time 0.497 (0.588)	Total loss 1.897 (2.232)
Epoch: [30][180/200]	Time 0.528 (0.586)	Total loss 1.771 (2.230)
Epoch: [30][185/200]	Time 0.541 (0.585)	Total loss 1.938 (2.222)
Epoch: [30][190/200]	Time 0.537 (0.585)	Total loss 1.702 (2.212)
Epoch: [30][195/200]	Time 0.528 (0.583)	Total loss 1.975 (2.205)
Epoch: [30][200/200]	Time 0.538 (0.582)	Total loss 2.028 (2.201)
==> start training epoch 31 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [31][5/200]	Time 0.695 (1.086)	Total loss 2.218 (2.149)
Epoch: [31][10/200]	Time 0.510 (0.802)	Total loss 1.779 (2.057)
Epoch: [31][15/200]	Time 0.499 (0.715)	Total loss 1.586 (1.983)
Epoch: [31][20/200]	Time 0.518 (0.729)	Total loss 1.940 (1.980)
Epoch: [31][25/200]	Time 0.502 (0.694)	Total loss 2.109 (2.007)
Epoch: [31][30/200]	Time 0.505 (0.670)	Total loss 2.067 (2.020)
Epoch: [31][35/200]	Time 0.564 (0.685)	Total loss 1.874 (2.014)
Epoch: [31][40/200]	Time 0.519 (0.669)	Total loss 1.921 (1.997)
Epoch: [31][45/200]	Time 0.670 (0.655)	Total loss 1.644 (1.983)
Epoch: [31][50/200]	Time 0.536 (0.643)	Total loss 1.890 (1.990)
Epoch: [31][55/200]	Time 0.528 (0.635)	Total loss 1.903 (1.977)
Epoch: [31][60/200]	Time 0.511 (0.627)	Total loss 2.141 (1.968)
Epoch: [31][65/200]	Time 0.523 (0.622)	Total loss 2.183 (1.980)
Epoch: [31][70/200]	Time 0.507 (0.617)	Total loss 1.940 (1.976)
Epoch: [31][75/200]	Time 0.521 (0.610)	Total loss 1.872 (1.975)
Epoch: [31][80/200]	Time 0.515 (0.606)	Total loss 2.180 (1.970)
Epoch: [31][85/200]	Time 0.668 (0.604)	Total loss 1.950 (1.968)
Epoch: [31][90/200]	Time 0.539 (0.599)	Total loss 1.796 (1.968)
Epoch: [31][95/200]	Time 0.526 (0.596)	Total loss 2.030 (1.964)
Epoch: [31][100/200]	Time 0.519 (0.592)	Total loss 1.649 (1.957)
Epoch: [31][105/200]	Time 0.516 (0.590)	Total loss 2.001 (1.958)
Epoch: [31][110/200]	Time 0.522 (0.588)	Total loss 2.134 (1.962)
Epoch: [31][115/200]	Time 0.490 (0.584)	Total loss 1.817 (1.952)
Epoch: [31][120/200]	Time 0.533 (0.583)	Total loss 2.151 (1.954)
Epoch: [31][125/200]	Time 1.969 (0.591)	Total loss 1.973 (1.952)
Epoch: [31][130/200]	Time 0.505 (0.598)	Total loss 2.134 (1.954)
Epoch: [31][135/200]	Time 0.507 (0.596)	Total loss 2.201 (1.954)
Epoch: [31][140/200]	Time 0.499 (0.593)	Total loss 2.016 (1.957)
Epoch: [31][145/200]	Time 0.516 (0.591)	Total loss 2.131 (1.954)
Epoch: [31][150/200]	Time 0.522 (0.590)	Total loss 2.396 (1.955)
Epoch: [31][155/200]	Time 0.499 (0.589)	Total loss 2.026 (1.953)
Epoch: [31][160/200]	Time 0.512 (0.587)	Total loss 1.683 (1.949)
Epoch: [31][165/200]	Time 0.687 (0.586)	Total loss 2.408 (1.948)
Epoch: [31][170/200]	Time 0.536 (0.584)	Total loss 1.916 (1.949)
Epoch: [31][175/200]	Time 0.523 (0.584)	Total loss 1.974 (1.950)
Epoch: [31][180/200]	Time 0.516 (0.582)	Total loss 2.059 (1.950)
Epoch: [31][185/200]	Time 0.494 (0.581)	Total loss 1.760 (1.948)
Epoch: [31][190/200]	Time 0.528 (0.580)	Total loss 1.837 (1.943)
Epoch: [31][195/200]	Time 0.546 (0.579)	Total loss 1.990 (1.943)
Epoch: [31][200/200]	Time 0.497 (0.578)	Total loss 1.929 (1.943)
Extract Features: [50/53]	Time 0.047 (0.139)	Data 0.000 (0.075)	
Mean AP: 34.8%
CMC Scores:
  top-1          36.6%
  top-5          56.1%
  top-10         65.6%

 * Finished epoch  31  model mAP: 34.8%  best: 34.8% *

==> start training epoch 32 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [32][5/200]	Time 0.521 (1.442)	Total loss 1.744 (1.964)
Epoch: [32][10/200]	Time 0.504 (1.008)	Total loss 1.603 (1.845)
Epoch: [32][15/200]	Time 0.657 (0.846)	Total loss 1.864 (1.859)
Epoch: [32][20/200]	Time 0.515 (0.828)	Total loss 1.993 (1.841)
Epoch: [32][25/200]	Time 0.552 (0.776)	Total loss 1.898 (1.826)
Epoch: [32][30/200]	Time 0.489 (0.737)	Total loss 1.879 (1.825)
Epoch: [32][35/200]	Time 0.715 (0.711)	Total loss 1.678 (1.835)
Epoch: [32][40/200]	Time 0.512 (0.686)	Total loss 2.036 (1.848)
Epoch: [32][45/200]	Time 0.490 (0.699)	Total loss 1.757 (1.836)
Epoch: [32][50/200]	Time 0.685 (0.685)	Total loss 1.849 (1.847)
Epoch: [32][55/200]	Time 0.513 (0.669)	Total loss 1.832 (1.856)
Epoch: [32][60/200]	Time 0.501 (0.659)	Total loss 1.514 (1.844)
Epoch: [32][65/200]	Time 0.494 (0.647)	Total loss 2.013 (1.842)
Epoch: [32][70/200]	Time 0.524 (0.642)	Total loss 1.849 (1.851)
Epoch: [32][75/200]	Time 0.513 (0.637)	Total loss 1.967 (1.860)
Epoch: [32][80/200]	Time 0.534 (0.629)	Total loss 1.700 (1.856)
Epoch: [32][85/200]	Time 0.507 (0.625)	Total loss 1.842 (1.865)
Epoch: [32][90/200]	Time 0.694 (0.621)	Total loss 1.882 (1.869)
Epoch: [32][95/200]	Time 0.500 (0.615)	Total loss 1.516 (1.864)
Epoch: [32][100/200]	Time 0.508 (0.612)	Total loss 1.941 (1.864)
Epoch: [32][105/200]	Time 0.504 (0.607)	Total loss 1.879 (1.858)
Epoch: [32][110/200]	Time 0.509 (0.604)	Total loss 2.104 (1.859)
Epoch: [32][115/200]	Time 0.508 (0.612)	Total loss 2.150 (1.861)
Epoch: [32][120/200]	Time 0.517 (0.608)	Total loss 1.687 (1.854)
Epoch: [32][125/200]	Time 0.522 (0.606)	Total loss 1.788 (1.855)
Epoch: [32][130/200]	Time 0.697 (0.604)	Total loss 2.032 (1.855)
Epoch: [32][135/200]	Time 0.496 (0.601)	Total loss 1.839 (1.851)
Epoch: [32][140/200]	Time 0.526 (0.600)	Total loss 2.120 (1.848)
Epoch: [32][145/200]	Time 0.535 (0.598)	Total loss 1.656 (1.848)
Epoch: [32][150/200]	Time 0.510 (0.596)	Total loss 1.652 (1.845)
Epoch: [32][155/200]	Time 1.825 (0.603)	Total loss 1.876 (1.846)
Epoch: [32][160/200]	Time 0.494 (0.601)	Total loss 2.023 (1.848)
Epoch: [32][165/200]	Time 0.543 (0.599)	Total loss 1.602 (1.846)
Epoch: [32][170/200]	Time 0.698 (0.598)	Total loss 1.728 (1.843)
Epoch: [32][175/200]	Time 0.510 (0.596)	Total loss 1.614 (1.843)
Epoch: [32][180/200]	Time 0.510 (0.594)	Total loss 2.080 (1.843)
Epoch: [32][185/200]	Time 0.501 (0.592)	Total loss 2.006 (1.842)
Epoch: [32][190/200]	Time 0.520 (0.591)	Total loss 1.739 (1.842)
Epoch: [32][195/200]	Time 0.522 (0.590)	Total loss 2.001 (1.844)
Epoch: [32][200/200]	Time 0.523 (0.588)	Total loss 1.936 (1.841)
==> start training epoch 33 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [33][5/200]	Time 0.485 (1.284)	Total loss 1.646 (1.809)
Epoch: [33][10/200]	Time 0.746 (0.924)	Total loss 1.690 (1.755)
Epoch: [33][15/200]	Time 0.531 (0.794)	Total loss 1.907 (1.810)
Epoch: [33][20/200]	Time 0.546 (0.737)	Total loss 1.772 (1.820)
Epoch: [33][25/200]	Time 0.550 (0.696)	Total loss 1.547 (1.848)
Epoch: [33][30/200]	Time 0.511 (0.670)	Total loss 2.043 (1.837)
Epoch: [33][35/200]	Time 0.512 (0.654)	Total loss 1.568 (1.830)
Epoch: [33][40/200]	Time 0.514 (0.637)	Total loss 1.903 (1.828)
Epoch: [33][45/200]	Time 0.507 (0.628)	Total loss 2.062 (1.841)
Epoch: [33][50/200]	Time 0.649 (0.620)	Total loss 1.584 (1.839)
Epoch: [33][55/200]	Time 0.552 (0.614)	Total loss 1.994 (1.841)
Epoch: [33][60/200]	Time 0.507 (0.634)	Total loss 1.821 (1.830)
Epoch: [33][65/200]	Time 0.539 (0.624)	Total loss 2.200 (1.834)
Epoch: [33][70/200]	Time 0.551 (0.637)	Total loss 1.306 (1.829)
Epoch: [33][75/200]	Time 0.533 (0.633)	Total loss 2.223 (1.831)
Epoch: [33][80/200]	Time 0.543 (0.628)	Total loss 1.903 (1.833)
Epoch: [33][85/200]	Time 0.492 (0.623)	Total loss 1.606 (1.831)
Epoch: [33][90/200]	Time 0.716 (0.620)	Total loss 1.542 (1.830)
Epoch: [33][95/200]	Time 0.531 (0.616)	Total loss 1.845 (1.828)
Epoch: [33][100/200]	Time 0.518 (0.625)	Total loss 1.851 (1.829)
Epoch: [33][105/200]	Time 0.493 (0.619)	Total loss 1.791 (1.830)
Epoch: [33][110/200]	Time 0.526 (0.616)	Total loss 1.986 (1.828)
Epoch: [33][115/200]	Time 0.509 (0.613)	Total loss 1.626 (1.826)
Epoch: [33][120/200]	Time 0.515 (0.610)	Total loss 1.952 (1.826)
Epoch: [33][125/200]	Time 0.555 (0.607)	Total loss 1.705 (1.825)
Epoch: [33][130/200]	Time 0.687 (0.606)	Total loss 1.938 (1.820)
Epoch: [33][135/200]	Time 0.494 (0.602)	Total loss 1.803 (1.819)
Epoch: [33][140/200]	Time 0.512 (0.600)	Total loss 1.957 (1.818)
Epoch: [33][145/200]	Time 0.555 (0.598)	Total loss 1.943 (1.817)
Epoch: [33][150/200]	Time 0.527 (0.597)	Total loss 1.808 (1.817)
Epoch: [33][155/200]	Time 0.536 (0.596)	Total loss 1.356 (1.814)
Epoch: [33][160/200]	Time 0.519 (0.593)	Total loss 1.800 (1.812)
Epoch: [33][165/200]	Time 0.546 (0.593)	Total loss 1.783 (1.811)
Epoch: [33][170/200]	Time 0.691 (0.592)	Total loss 1.668 (1.809)
Epoch: [33][175/200]	Time 0.512 (0.590)	Total loss 2.004 (1.809)
Epoch: [33][180/200]	Time 0.529 (0.588)	Total loss 1.635 (1.808)
Epoch: [33][185/200]	Time 0.551 (0.592)	Total loss 1.651 (1.806)
Epoch: [33][190/200]	Time 1.790 (0.598)	Total loss 1.677 (1.808)
Epoch: [33][195/200]	Time 0.540 (0.598)	Total loss 1.788 (1.807)
Epoch: [33][200/200]	Time 0.517 (0.596)	Total loss 1.803 (1.806)
Extract Features: [50/53]	Time 0.212 (0.136)	Data 0.146 (0.067)	
Mean AP: 34.7%
CMC Scores:
  top-1          36.3%
  top-5          55.7%
  top-10         65.6%

 * Finished epoch  33  model mAP: 34.7%  best: 34.8%

==> start training epoch 34 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [34][5/200]	Time 0.510 (1.084)	Total loss 1.795 (1.758)
Epoch: [34][10/200]	Time 0.526 (0.819)	Total loss 1.585 (1.746)
Epoch: [34][15/200]	Time 0.536 (0.735)	Total loss 1.670 (1.803)
Epoch: [34][20/200]	Time 0.519 (0.690)	Total loss 1.740 (1.789)
Epoch: [34][25/200]	Time 0.530 (0.661)	Total loss 2.287 (1.817)
Epoch: [34][30/200]	Time 0.531 (0.642)	Total loss 1.936 (1.806)
Epoch: [34][35/200]	Time 0.522 (0.630)	Total loss 1.774 (1.802)
Epoch: [34][40/200]	Time 0.522 (0.616)	Total loss 1.874 (1.813)
Epoch: [34][45/200]	Time 0.568 (0.609)	Total loss 1.759 (1.806)
Epoch: [34][50/200]	Time 0.522 (0.602)	Total loss 1.787 (1.799)
Epoch: [34][55/200]	Time 0.523 (0.595)	Total loss 1.854 (1.795)
Epoch: [34][60/200]	Time 0.530 (0.593)	Total loss 2.312 (1.817)
Epoch: [34][65/200]	Time 0.668 (0.590)	Total loss 1.874 (1.813)
Epoch: [34][70/200]	Time 0.525 (0.586)	Total loss 1.277 (1.805)
Epoch: [34][75/200]	Time 0.516 (0.584)	Total loss 1.805 (1.807)
Epoch: [34][80/200]	Time 0.568 (0.580)	Total loss 1.726 (1.808)
Epoch: [34][85/200]	Time 0.532 (0.592)	Total loss 1.519 (1.801)
Epoch: [34][90/200]	Time 0.480 (0.588)	Total loss 1.501 (1.799)
Epoch: [34][95/200]	Time 0.528 (0.596)	Total loss 1.555 (1.802)
Epoch: [34][100/200]	Time 0.571 (0.594)	Total loss 1.872 (1.799)
Epoch: [34][105/200]	Time 0.637 (0.592)	Total loss 1.490 (1.796)
Epoch: [34][110/200]	Time 0.524 (0.589)	Total loss 1.465 (1.791)
Epoch: [34][115/200]	Time 0.512 (0.599)	Total loss 1.567 (1.784)
Epoch: [34][120/200]	Time 0.527 (0.595)	Total loss 1.947 (1.785)
Epoch: [34][125/200]	Time 0.518 (0.593)	Total loss 1.528 (1.781)
Epoch: [34][130/200]	Time 0.513 (0.592)	Total loss 1.808 (1.786)
Epoch: [34][135/200]	Time 0.514 (0.589)	Total loss 1.616 (1.784)
Epoch: [34][140/200]	Time 0.546 (0.588)	Total loss 2.005 (1.785)
Epoch: [34][145/200]	Time 0.664 (0.587)	Total loss 1.802 (1.783)
Epoch: [34][150/200]	Time 0.516 (0.585)	Total loss 1.628 (1.781)
Epoch: [34][155/200]	Time 0.501 (0.584)	Total loss 1.762 (1.777)
Epoch: [34][160/200]	Time 0.527 (0.583)	Total loss 1.839 (1.779)
Epoch: [34][165/200]	Time 0.537 (0.582)	Total loss 1.624 (1.779)
Epoch: [34][170/200]	Time 0.543 (0.581)	Total loss 1.666 (1.782)
Epoch: [34][175/200]	Time 0.567 (0.580)	Total loss 1.467 (1.778)
Epoch: [34][180/200]	Time 0.525 (0.585)	Total loss 1.659 (1.775)
Epoch: [34][185/200]	Time 0.674 (0.584)	Total loss 1.626 (1.771)
Epoch: [34][190/200]	Time 0.526 (0.582)	Total loss 1.777 (1.768)
Epoch: [34][195/200]	Time 0.525 (0.581)	Total loss 1.972 (1.770)
Epoch: [34][200/200]	Time 0.575 (0.581)	Total loss 1.660 (1.769)
==> start training epoch 35 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [35][5/200]	Time 0.526 (0.851)	Total loss 1.798 (1.832)
Epoch: [35][10/200]	Time 0.555 (0.834)	Total loss 1.830 (1.817)
Epoch: [35][15/200]	Time 0.570 (0.734)	Total loss 1.966 (1.809)
Epoch: [35][20/200]	Time 0.544 (0.689)	Total loss 1.806 (1.796)
Epoch: [35][25/200]	Time 0.510 (0.659)	Total loss 1.680 (1.816)
Epoch: [35][30/200]	Time 0.564 (0.637)	Total loss 1.689 (1.809)
Epoch: [35][35/200]	Time 0.668 (0.627)	Total loss 2.113 (1.825)
Epoch: [35][40/200]	Time 0.502 (0.612)	Total loss 1.995 (1.813)
Epoch: [35][45/200]	Time 0.509 (0.608)	Total loss 2.154 (1.809)
Epoch: [35][50/200]	Time 0.506 (0.600)	Total loss 1.856 (1.808)
Epoch: [35][55/200]	Time 0.507 (0.596)	Total loss 1.676 (1.804)
Epoch: [35][60/200]	Time 0.514 (0.591)	Total loss 1.859 (1.794)
Epoch: [35][65/200]	Time 0.490 (0.587)	Total loss 1.848 (1.792)
Epoch: [35][70/200]	Time 0.535 (0.599)	Total loss 1.519 (1.793)
Epoch: [35][75/200]	Time 0.520 (0.596)	Total loss 1.989 (1.804)
Epoch: [35][80/200]	Time 0.536 (0.591)	Total loss 1.730 (1.796)
Epoch: [35][85/200]	Time 0.534 (0.589)	Total loss 1.690 (1.795)
Epoch: [35][90/200]	Time 0.532 (0.586)	Total loss 1.885 (1.787)
Epoch: [35][95/200]	Time 0.616 (0.585)	Total loss 1.561 (1.785)
Epoch: [35][100/200]	Time 0.559 (0.582)	Total loss 1.527 (1.776)
Epoch: [35][105/200]	Time 0.510 (0.581)	Total loss 1.608 (1.776)
Epoch: [35][110/200]	Time 0.540 (0.578)	Total loss 1.617 (1.778)
Epoch: [35][115/200]	Time 0.564 (0.577)	Total loss 1.872 (1.777)
Epoch: [35][120/200]	Time 1.642 (0.584)	Total loss 2.114 (1.782)
Epoch: [35][125/200]	Time 0.718 (0.583)	Total loss 2.056 (1.787)
Epoch: [35][130/200]	Time 0.502 (0.581)	Total loss 1.998 (1.789)
Epoch: [35][135/200]	Time 0.498 (0.579)	Total loss 2.157 (1.787)
Epoch: [35][140/200]	Time 0.647 (0.578)	Total loss 1.528 (1.781)
Epoch: [35][145/200]	Time 0.552 (0.576)	Total loss 1.624 (1.780)
Epoch: [35][150/200]	Time 0.530 (0.575)	Total loss 1.551 (1.778)
Epoch: [35][155/200]	Time 0.497 (0.573)	Total loss 1.541 (1.774)
Epoch: [35][160/200]	Time 0.495 (0.572)	Total loss 1.615 (1.766)
Epoch: [35][165/200]	Time 0.495 (0.577)	Total loss 2.094 (1.767)
Epoch: [35][170/200]	Time 0.528 (0.583)	Total loss 1.363 (1.762)
Epoch: [35][175/200]	Time 0.517 (0.582)	Total loss 1.947 (1.759)
Epoch: [35][180/200]	Time 0.670 (0.581)	Total loss 2.186 (1.764)
Epoch: [35][185/200]	Time 0.479 (0.579)	Total loss 1.618 (1.766)
Epoch: [35][190/200]	Time 0.570 (0.580)	Total loss 1.665 (1.766)
Epoch: [35][195/200]	Time 0.536 (0.579)	Total loss 1.844 (1.768)
Epoch: [35][200/200]	Time 0.520 (0.579)	Total loss 1.671 (1.767)
Extract Features: [50/53]	Time 0.064 (0.139)	Data 0.000 (0.073)	
Mean AP: 36.6%
CMC Scores:
  top-1          38.0%
  top-5          57.9%
  top-10         68.1%

 * Finished epoch  35  model mAP: 36.6%  best: 36.6% *

==> start training epoch 36 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [36][5/200]	Time 0.527 (0.826)	Total loss 1.741 (1.598)
Epoch: [36][10/200]	Time 0.513 (0.685)	Total loss 1.492 (1.598)
Epoch: [36][15/200]	Time 0.497 (0.629)	Total loss 1.790 (1.639)
Epoch: [36][20/200]	Time 0.539 (0.608)	Total loss 2.097 (1.680)
Epoch: [36][25/200]	Time 0.517 (0.595)	Total loss 1.783 (1.684)
Epoch: [36][30/200]	Time 0.734 (0.594)	Total loss 1.602 (1.676)
Epoch: [36][35/200]	Time 0.509 (0.620)	Total loss 1.760 (1.695)
Epoch: [36][40/200]	Time 0.513 (0.612)	Total loss 1.628 (1.704)
Epoch: [36][45/200]	Time 0.534 (0.608)	Total loss 1.718 (1.717)
Epoch: [36][50/200]	Time 0.682 (0.602)	Total loss 1.778 (1.720)
Epoch: [36][55/200]	Time 1.900 (0.620)	Total loss 1.622 (1.724)
Epoch: [36][60/200]	Time 0.528 (0.616)	Total loss 2.033 (1.742)
Epoch: [36][65/200]	Time 0.736 (0.614)	Total loss 1.537 (1.739)
Epoch: [36][70/200]	Time 0.562 (0.609)	Total loss 1.751 (1.745)
Epoch: [36][75/200]	Time 0.528 (0.607)	Total loss 1.714 (1.748)
Epoch: [36][80/200]	Time 0.527 (0.603)	Total loss 1.766 (1.750)
Epoch: [36][85/200]	Time 0.577 (0.601)	Total loss 1.414 (1.736)
Epoch: [36][90/200]	Time 0.548 (0.599)	Total loss 1.461 (1.735)
Epoch: [36][95/200]	Time 0.555 (0.595)	Total loss 1.821 (1.739)
Epoch: [36][100/200]	Time 0.537 (0.594)	Total loss 1.791 (1.734)
Epoch: [36][105/200]	Time 0.698 (0.593)	Total loss 1.893 (1.735)
Epoch: [36][110/200]	Time 0.555 (0.591)	Total loss 1.445 (1.741)
Epoch: [36][115/200]	Time 0.529 (0.589)	Total loss 1.576 (1.731)
Epoch: [36][120/200]	Time 0.546 (0.587)	Total loss 1.724 (1.727)
Epoch: [36][125/200]	Time 0.538 (0.586)	Total loss 1.915 (1.724)
Epoch: [36][130/200]	Time 0.531 (0.585)	Total loss 1.905 (1.721)
Epoch: [36][135/200]	Time 0.529 (0.584)	Total loss 1.895 (1.722)
Epoch: [36][140/200]	Time 0.510 (0.584)	Total loss 1.845 (1.720)
Epoch: [36][145/200]	Time 0.664 (0.582)	Total loss 1.773 (1.722)
Epoch: [36][150/200]	Time 0.523 (0.597)	Total loss 1.760 (1.726)
Epoch: [36][155/200]	Time 0.529 (0.596)	Total loss 1.865 (1.724)
Epoch: [36][160/200]	Time 0.496 (0.593)	Total loss 1.641 (1.726)
Epoch: [36][165/200]	Time 0.512 (0.593)	Total loss 1.644 (1.729)
Epoch: [36][170/200]	Time 0.555 (0.592)	Total loss 1.806 (1.729)
Epoch: [36][175/200]	Time 0.607 (0.591)	Total loss 1.516 (1.728)
Epoch: [36][180/200]	Time 0.555 (0.590)	Total loss 1.830 (1.733)
Epoch: [36][185/200]	Time 0.726 (0.590)	Total loss 1.699 (1.731)
Epoch: [36][190/200]	Time 0.567 (0.589)	Total loss 2.113 (1.729)
Epoch: [36][195/200]	Time 0.523 (0.589)	Total loss 1.784 (1.729)
Epoch: [36][200/200]	Time 0.496 (0.587)	Total loss 1.958 (1.727)
==> start training epoch 37 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [37][5/200]	Time 0.540 (0.986)	Total loss 1.675 (1.742)
Epoch: [37][10/200]	Time 0.503 (0.770)	Total loss 1.302 (1.697)
Epoch: [37][15/200]	Time 0.563 (0.689)	Total loss 1.809 (1.746)
Epoch: [37][20/200]	Time 0.581 (0.657)	Total loss 1.713 (1.772)
Epoch: [37][25/200]	Time 1.944 (0.702)	Total loss 1.394 (1.747)
Epoch: [37][30/200]	Time 0.575 (0.681)	Total loss 1.777 (1.766)
Epoch: [37][35/200]	Time 0.661 (0.664)	Total loss 1.756 (1.736)
Epoch: [37][40/200]	Time 0.515 (0.643)	Total loss 1.835 (1.734)
Epoch: [37][45/200]	Time 0.522 (0.660)	Total loss 1.923 (1.731)
Epoch: [37][50/200]	Time 0.554 (0.649)	Total loss 1.736 (1.725)
Epoch: [37][55/200]	Time 0.506 (0.640)	Total loss 1.704 (1.733)
Epoch: [37][60/200]	Time 0.576 (0.652)	Total loss 1.851 (1.743)
Epoch: [37][65/200]	Time 0.497 (0.644)	Total loss 1.769 (1.735)
Epoch: [37][70/200]	Time 0.594 (0.639)	Total loss 1.939 (1.733)
Epoch: [37][75/200]	Time 0.514 (0.632)	Total loss 1.457 (1.724)
Epoch: [37][80/200]	Time 0.525 (0.628)	Total loss 1.513 (1.721)
Epoch: [37][85/200]	Time 0.702 (0.625)	Total loss 1.844 (1.723)
Epoch: [37][90/200]	Time 0.509 (0.620)	Total loss 1.727 (1.723)
Epoch: [37][95/200]	Time 0.532 (0.618)	Total loss 1.624 (1.725)
Epoch: [37][100/200]	Time 0.512 (0.615)	Total loss 1.813 (1.731)
Epoch: [37][105/200]	Time 0.529 (0.612)	Total loss 1.764 (1.731)
Epoch: [37][110/200]	Time 0.522 (0.610)	Total loss 2.148 (1.732)
Epoch: [37][115/200]	Time 0.532 (0.610)	Total loss 1.680 (1.730)
Epoch: [37][120/200]	Time 0.721 (0.609)	Total loss 1.935 (1.732)
Epoch: [37][125/200]	Time 0.506 (0.606)	Total loss 1.567 (1.733)
Epoch: [37][130/200]	Time 0.530 (0.604)	Total loss 1.823 (1.730)
Epoch: [37][135/200]	Time 0.554 (0.611)	Total loss 1.724 (1.728)
Epoch: [37][140/200]	Time 0.503 (0.609)	Total loss 1.967 (1.727)
Epoch: [37][145/200]	Time 0.541 (0.608)	Total loss 2.285 (1.731)
Epoch: [37][150/200]	Time 0.538 (0.606)	Total loss 2.068 (1.728)
Epoch: [37][155/200]	Time 0.581 (0.606)	Total loss 1.738 (1.730)
Epoch: [37][160/200]	Time 0.704 (0.605)	Total loss 1.619 (1.731)
Epoch: [37][165/200]	Time 0.537 (0.603)	Total loss 1.701 (1.733)
Epoch: [37][170/200]	Time 0.530 (0.601)	Total loss 1.818 (1.735)
Epoch: [37][175/200]	Time 0.526 (0.608)	Total loss 1.975 (1.736)
Epoch: [37][180/200]	Time 0.522 (0.607)	Total loss 1.704 (1.735)
Epoch: [37][185/200]	Time 0.519 (0.606)	Total loss 2.055 (1.739)
Epoch: [37][190/200]	Time 0.537 (0.604)	Total loss 1.728 (1.736)
Epoch: [37][195/200]	Time 0.538 (0.603)	Total loss 1.645 (1.733)
Epoch: [37][200/200]	Time 0.699 (0.602)	Total loss 1.759 (1.732)
Extract Features: [50/53]	Time 0.057 (0.136)	Data 0.000 (0.073)	
Mean AP: 36.8%
CMC Scores:
  top-1          37.9%
  top-5          58.5%
  top-10         68.6%

 * Finished epoch  37  model mAP: 36.8%  best: 36.8% *

==> start training epoch 38 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [38][5/200]	Time 0.542 (1.309)	Total loss 1.745 (1.642)
Epoch: [38][10/200]	Time 0.566 (0.931)	Total loss 1.516 (1.687)
Epoch: [38][15/200]	Time 0.512 (0.809)	Total loss 1.387 (1.635)
Epoch: [38][20/200]	Time 0.507 (0.749)	Total loss 1.821 (1.649)
Epoch: [38][25/200]	Time 0.683 (0.711)	Total loss 1.688 (1.657)
Epoch: [38][30/200]	Time 0.566 (0.720)	Total loss 1.608 (1.638)
Epoch: [38][35/200]	Time 0.519 (0.700)	Total loss 1.578 (1.639)
Epoch: [38][40/200]	Time 0.512 (0.683)	Total loss 1.570 (1.644)
Epoch: [38][45/200]	Time 0.545 (0.667)	Total loss 1.672 (1.654)
Epoch: [38][50/200]	Time 0.550 (0.658)	Total loss 1.694 (1.657)
Epoch: [38][55/200]	Time 0.719 (0.651)	Total loss 1.354 (1.633)
Epoch: [38][60/200]	Time 0.533 (0.640)	Total loss 1.685 (1.636)
Epoch: [38][65/200]	Time 0.529 (0.633)	Total loss 1.694 (1.633)
Epoch: [38][70/200]	Time 0.563 (0.627)	Total loss 1.938 (1.646)
Epoch: [38][75/200]	Time 0.534 (0.623)	Total loss 1.748 (1.648)
Epoch: [38][80/200]	Time 0.517 (0.619)	Total loss 1.795 (1.653)
Epoch: [38][85/200]	Time 1.759 (0.645)	Total loss 1.619 (1.652)
Epoch: [38][90/200]	Time 0.537 (0.640)	Total loss 1.549 (1.645)
Epoch: [38][95/200]	Time 0.704 (0.636)	Total loss 1.833 (1.647)
Epoch: [38][100/200]	Time 0.509 (0.631)	Total loss 1.472 (1.648)
Epoch: [38][105/200]	Time 0.538 (0.627)	Total loss 1.729 (1.641)
Epoch: [38][110/200]	Time 0.540 (0.623)	Total loss 1.366 (1.647)
Epoch: [38][115/200]	Time 0.488 (0.618)	Total loss 1.627 (1.653)
Epoch: [38][120/200]	Time 1.755 (0.625)	Total loss 1.600 (1.655)
Epoch: [38][125/200]	Time 0.533 (0.621)	Total loss 1.723 (1.653)
Epoch: [38][130/200]	Time 0.545 (0.619)	Total loss 1.728 (1.650)
Epoch: [38][135/200]	Time 0.733 (0.618)	Total loss 1.556 (1.649)
Epoch: [38][140/200]	Time 0.538 (0.614)	Total loss 1.496 (1.650)
Epoch: [38][145/200]	Time 0.527 (0.612)	Total loss 1.894 (1.649)
Epoch: [38][150/200]	Time 0.592 (0.610)	Total loss 1.763 (1.654)
Epoch: [38][155/200]	Time 0.536 (0.609)	Total loss 1.726 (1.656)
Epoch: [38][160/200]	Time 0.526 (0.607)	Total loss 1.391 (1.660)
Epoch: [38][165/200]	Time 0.566 (0.605)	Total loss 1.812 (1.660)
Epoch: [38][170/200]	Time 0.491 (0.603)	Total loss 1.768 (1.661)
Epoch: [38][175/200]	Time 0.667 (0.602)	Total loss 1.897 (1.660)
Epoch: [38][180/200]	Time 0.544 (0.599)	Total loss 1.896 (1.663)
Epoch: [38][185/200]	Time 0.517 (0.598)	Total loss 1.664 (1.663)
Epoch: [38][190/200]	Time 0.502 (0.596)	Total loss 1.588 (1.662)
Epoch: [38][195/200]	Time 0.524 (0.594)	Total loss 1.531 (1.666)
Epoch: [38][200/200]	Time 0.530 (0.599)	Total loss 1.360 (1.663)
==> start training epoch 39 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [39][5/200]	Time 0.517 (1.020)	Total loss 2.014 (1.805)
Epoch: [39][10/200]	Time 0.562 (0.791)	Total loss 1.920 (1.803)
Epoch: [39][15/200]	Time 0.716 (0.803)	Total loss 1.591 (1.774)
Epoch: [39][20/200]	Time 0.513 (0.733)	Total loss 1.507 (1.718)
Epoch: [39][25/200]	Time 0.532 (0.697)	Total loss 1.722 (1.697)
Epoch: [39][30/200]	Time 0.539 (0.668)	Total loss 1.822 (1.690)
Epoch: [39][35/200]	Time 0.544 (0.653)	Total loss 1.409 (1.686)
Epoch: [39][40/200]	Time 0.481 (0.641)	Total loss 1.615 (1.675)
Epoch: [39][45/200]	Time 0.511 (0.628)	Total loss 1.763 (1.678)
Epoch: [39][50/200]	Time 0.512 (0.621)	Total loss 1.710 (1.685)
Epoch: [39][55/200]	Time 0.676 (0.616)	Total loss 1.835 (1.695)
Epoch: [39][60/200]	Time 0.554 (0.610)	Total loss 1.767 (1.685)
Epoch: [39][65/200]	Time 0.507 (0.607)	Total loss 1.513 (1.684)
Epoch: [39][70/200]	Time 0.524 (0.600)	Total loss 1.727 (1.686)
Epoch: [39][75/200]	Time 0.501 (0.597)	Total loss 1.548 (1.693)
Epoch: [39][80/200]	Time 0.526 (0.595)	Total loss 1.350 (1.688)
Epoch: [39][85/200]	Time 0.524 (0.590)	Total loss 1.941 (1.692)
Epoch: [39][90/200]	Time 0.531 (0.588)	Total loss 1.294 (1.686)
Epoch: [39][95/200]	Time 0.736 (0.588)	Total loss 1.807 (1.686)
Epoch: [39][100/200]	Time 0.530 (0.585)	Total loss 1.407 (1.686)
Epoch: [39][105/200]	Time 0.512 (0.583)	Total loss 1.840 (1.689)
Epoch: [39][110/200]	Time 0.510 (0.591)	Total loss 1.607 (1.690)
Epoch: [39][115/200]	Time 0.506 (0.601)	Total loss 1.796 (1.695)
Epoch: [39][120/200]	Time 0.532 (0.599)	Total loss 1.506 (1.689)
Epoch: [39][125/200]	Time 0.538 (0.596)	Total loss 1.765 (1.688)
Epoch: [39][130/200]	Time 0.514 (0.595)	Total loss 1.654 (1.690)
Epoch: [39][135/200]	Time 0.709 (0.594)	Total loss 1.452 (1.684)
Epoch: [39][140/200]	Time 0.554 (0.602)	Total loss 1.747 (1.686)
Epoch: [39][145/200]	Time 0.536 (0.602)	Total loss 1.463 (1.685)
Epoch: [39][150/200]	Time 0.499 (0.599)	Total loss 1.761 (1.686)
Epoch: [39][155/200]	Time 0.530 (0.598)	Total loss 1.749 (1.689)
Epoch: [39][160/200]	Time 0.570 (0.597)	Total loss 1.475 (1.683)
Epoch: [39][165/200]	Time 0.567 (0.595)	Total loss 1.914 (1.681)
Epoch: [39][170/200]	Time 0.524 (0.594)	Total loss 1.467 (1.681)
Epoch: [39][175/200]	Time 0.689 (0.593)	Total loss 1.366 (1.681)
Epoch: [39][180/200]	Time 0.559 (0.591)	Total loss 1.786 (1.679)
Epoch: [39][185/200]	Time 0.549 (0.590)	Total loss 1.656 (1.680)
Epoch: [39][190/200]	Time 0.533 (0.589)	Total loss 1.862 (1.682)
Epoch: [39][195/200]	Time 0.537 (0.588)	Total loss 1.415 (1.679)
Epoch: [39][200/200]	Time 0.525 (0.593)	Total loss 1.651 (1.678)
Extract Features: [50/53]	Time 0.053 (0.135)	Data 0.000 (0.069)	
Mean AP: 35.6%
CMC Scores:
  top-1          36.8%
  top-5          57.8%
  top-10         67.6%

 * Finished epoch  39  model mAP: 35.6%  best: 36.8%

==> start training epoch 40 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [40][5/200]	Time 0.510 (1.260)	Total loss 1.485 (1.581)
Epoch: [40][10/200]	Time 0.566 (0.890)	Total loss 1.581 (1.627)
Epoch: [40][15/200]	Time 0.535 (0.780)	Total loss 1.877 (1.645)
Epoch: [40][20/200]	Time 0.503 (0.712)	Total loss 1.643 (1.647)
Epoch: [40][25/200]	Time 0.504 (0.732)	Total loss 1.590 (1.648)
Epoch: [40][30/200]	Time 0.515 (0.693)	Total loss 1.565 (1.641)
Epoch: [40][35/200]	Time 0.533 (0.673)	Total loss 1.426 (1.629)
Epoch: [40][40/200]	Time 0.559 (0.661)	Total loss 2.096 (1.620)
Epoch: [40][45/200]	Time 0.666 (0.648)	Total loss 1.635 (1.626)
Epoch: [40][50/200]	Time 0.528 (0.638)	Total loss 1.590 (1.656)
Epoch: [40][55/200]	Time 0.521 (0.630)	Total loss 1.419 (1.652)
Epoch: [40][60/200]	Time 0.522 (0.623)	Total loss 1.816 (1.663)
Epoch: [40][65/200]	Time 0.548 (0.619)	Total loss 1.654 (1.674)
Epoch: [40][70/200]	Time 0.563 (0.615)	Total loss 1.624 (1.672)
Epoch: [40][75/200]	Time 0.518 (0.611)	Total loss 1.703 (1.669)
Epoch: [40][80/200]	Time 0.517 (0.606)	Total loss 1.722 (1.676)
Epoch: [40][85/200]	Time 0.519 (0.603)	Total loss 1.661 (1.678)
Epoch: [40][90/200]	Time 0.495 (0.600)	Total loss 1.492 (1.679)
Epoch: [40][95/200]	Time 0.583 (0.609)	Total loss 1.626 (1.678)
Epoch: [40][100/200]	Time 0.511 (0.608)	Total loss 1.418 (1.672)
Epoch: [40][105/200]	Time 0.503 (0.604)	Total loss 1.441 (1.673)
Epoch: [40][110/200]	Time 0.515 (0.601)	Total loss 1.939 (1.672)
Epoch: [40][115/200]	Time 0.512 (0.599)	Total loss 1.491 (1.671)
Epoch: [40][120/200]	Time 0.709 (0.596)	Total loss 1.400 (1.662)
Epoch: [40][125/200]	Time 0.521 (0.594)	Total loss 1.444 (1.662)
Epoch: [40][130/200]	Time 0.531 (0.592)	Total loss 2.011 (1.661)
Epoch: [40][135/200]	Time 0.519 (0.590)	Total loss 1.750 (1.660)
Epoch: [40][140/200]	Time 0.505 (0.597)	Total loss 1.361 (1.659)
Epoch: [40][145/200]	Time 0.525 (0.596)	Total loss 1.449 (1.659)
Epoch: [40][150/200]	Time 0.527 (0.593)	Total loss 1.655 (1.659)
Epoch: [40][155/200]	Time 0.507 (0.592)	Total loss 1.604 (1.659)
Epoch: [40][160/200]	Time 0.677 (0.591)	Total loss 1.485 (1.658)
Epoch: [40][165/200]	Time 0.537 (0.589)	Total loss 1.646 (1.658)
Epoch: [40][170/200]	Time 0.502 (0.588)	Total loss 1.768 (1.657)
Epoch: [40][175/200]	Time 0.570 (0.587)	Total loss 1.761 (1.657)
Epoch: [40][180/200]	Time 0.498 (0.585)	Total loss 1.376 (1.657)
Epoch: [40][185/200]	Time 1.693 (0.591)	Total loss 1.639 (1.658)
Epoch: [40][190/200]	Time 0.516 (0.589)	Total loss 1.654 (1.661)
Epoch: [40][195/200]	Time 0.480 (0.595)	Total loss 1.454 (1.661)
Epoch: [40][200/200]	Time 0.700 (0.594)	Total loss 1.511 (1.660)
==> start training epoch 41 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [41][5/200]	Time 0.535 (1.222)	Total loss 1.873 (1.723)
Epoch: [41][10/200]	Time 0.535 (0.905)	Total loss 1.632 (1.703)
Epoch: [41][15/200]	Time 0.569 (0.783)	Total loss 1.781 (1.682)
Epoch: [41][20/200]	Time 0.511 (0.725)	Total loss 1.654 (1.693)
Epoch: [41][25/200]	Time 0.517 (0.693)	Total loss 1.706 (1.683)
Epoch: [41][30/200]	Time 0.517 (0.665)	Total loss 1.703 (1.689)
Epoch: [41][35/200]	Time 0.538 (0.650)	Total loss 1.672 (1.689)
Epoch: [41][40/200]	Time 0.704 (0.638)	Total loss 1.739 (1.688)
Epoch: [41][45/200]	Time 0.505 (0.626)	Total loss 1.402 (1.679)
Epoch: [41][50/200]	Time 1.761 (0.644)	Total loss 1.630 (1.697)
Epoch: [41][55/200]	Time 0.542 (0.633)	Total loss 1.779 (1.701)
Epoch: [41][60/200]	Time 0.505 (0.628)	Total loss 1.757 (1.699)
Epoch: [41][65/200]	Time 0.522 (0.622)	Total loss 1.617 (1.694)
Epoch: [41][70/200]	Time 0.499 (0.614)	Total loss 1.462 (1.688)
Epoch: [41][75/200]	Time 0.539 (0.609)	Total loss 1.458 (1.685)
Epoch: [41][80/200]	Time 0.687 (0.620)	Total loss 2.114 (1.683)
Epoch: [41][85/200]	Time 0.529 (0.616)	Total loss 1.224 (1.667)
Epoch: [41][90/200]	Time 0.510 (0.612)	Total loss 1.424 (1.656)
Epoch: [41][95/200]	Time 0.487 (0.607)	Total loss 1.823 (1.661)
Epoch: [41][100/200]	Time 0.523 (0.604)	Total loss 1.462 (1.656)
Epoch: [41][105/200]	Time 0.493 (0.601)	Total loss 1.906 (1.657)
Epoch: [41][110/200]	Time 0.527 (0.596)	Total loss 1.737 (1.659)
Epoch: [41][115/200]	Time 0.557 (0.594)	Total loss 1.474 (1.656)
Epoch: [41][120/200]	Time 0.636 (0.592)	Total loss 1.671 (1.652)
Epoch: [41][125/200]	Time 0.482 (0.589)	Total loss 2.106 (1.657)
Epoch: [41][130/200]	Time 0.495 (0.587)	Total loss 2.117 (1.660)
Epoch: [41][135/200]	Time 0.554 (0.584)	Total loss 1.601 (1.660)
Epoch: [41][140/200]	Time 0.512 (0.582)	Total loss 1.690 (1.660)
Epoch: [41][145/200]	Time 0.528 (0.581)	Total loss 1.716 (1.664)
Epoch: [41][150/200]	Time 0.499 (0.579)	Total loss 1.630 (1.667)
Epoch: [41][155/200]	Time 0.486 (0.578)	Total loss 1.631 (1.670)
Epoch: [41][160/200]	Time 0.640 (0.577)	Total loss 1.497 (1.665)
Epoch: [41][165/200]	Time 0.481 (0.582)	Total loss 2.140 (1.668)
Epoch: [41][170/200]	Time 0.491 (0.580)	Total loss 1.991 (1.667)
Epoch: [41][175/200]	Time 0.514 (0.584)	Total loss 1.657 (1.667)
Epoch: [41][180/200]	Time 0.528 (0.584)	Total loss 1.609 (1.665)
Epoch: [41][185/200]	Time 0.499 (0.583)	Total loss 1.913 (1.669)
Epoch: [41][190/200]	Time 0.555 (0.582)	Total loss 1.360 (1.663)
Epoch: [41][195/200]	Time 0.510 (0.582)	Total loss 1.626 (1.662)
Epoch: [41][200/200]	Time 0.706 (0.582)	Total loss 1.544 (1.661)
Extract Features: [50/53]	Time 0.134 (0.130)	Data 0.075 (0.066)	
Mean AP: 38.1%
CMC Scores:
  top-1          39.1%
  top-5          60.5%
  top-10         69.6%

 * Finished epoch  41  model mAP: 38.1%  best: 38.1% *

==> start training epoch 42 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [42][5/200]	Time 0.714 (1.172)	Total loss 1.685 (1.622)
Epoch: [42][10/200]	Time 0.505 (0.844)	Total loss 1.849 (1.648)
Epoch: [42][15/200]	Time 0.497 (0.741)	Total loss 1.703 (1.642)
Epoch: [42][20/200]	Time 0.523 (0.684)	Total loss 1.737 (1.613)
Epoch: [42][25/200]	Time 0.559 (0.659)	Total loss 2.038 (1.641)
Epoch: [42][30/200]	Time 0.499 (0.639)	Total loss 1.457 (1.631)
Epoch: [42][35/200]	Time 0.508 (0.626)	Total loss 1.540 (1.634)
Epoch: [42][40/200]	Time 0.579 (0.615)	Total loss 2.181 (1.656)
Epoch: [42][45/200]	Time 0.543 (0.606)	Total loss 2.025 (1.667)
Epoch: [42][50/200]	Time 0.505 (0.629)	Total loss 2.042 (1.674)
Epoch: [42][55/200]	Time 0.474 (0.617)	Total loss 1.657 (1.681)
Epoch: [42][60/200]	Time 0.487 (0.608)	Total loss 1.434 (1.680)
Epoch: [42][65/200]	Time 0.497 (0.618)	Total loss 1.637 (1.677)
Epoch: [42][70/200]	Time 0.554 (0.611)	Total loss 1.385 (1.681)
Epoch: [42][75/200]	Time 0.535 (0.607)	Total loss 1.628 (1.672)
Epoch: [42][80/200]	Time 0.487 (0.618)	Total loss 1.407 (1.668)
Epoch: [42][85/200]	Time 0.693 (0.613)	Total loss 1.721 (1.665)
Epoch: [42][90/200]	Time 0.472 (0.604)	Total loss 2.056 (1.673)
Epoch: [42][95/200]	Time 0.494 (0.600)	Total loss 1.745 (1.674)
Epoch: [42][100/200]	Time 0.691 (0.597)	Total loss 1.261 (1.666)
Epoch: [42][105/200]	Time 0.508 (0.593)	Total loss 1.691 (1.663)
Epoch: [42][110/200]	Time 0.499 (0.591)	Total loss 1.397 (1.661)
Epoch: [42][115/200]	Time 0.664 (0.589)	Total loss 1.657 (1.659)
Epoch: [42][120/200]	Time 0.494 (0.586)	Total loss 1.758 (1.663)
Epoch: [42][125/200]	Time 0.533 (0.585)	Total loss 1.356 (1.658)
Epoch: [42][130/200]	Time 0.519 (0.582)	Total loss 1.505 (1.658)
Epoch: [42][135/200]	Time 0.631 (0.582)	Total loss 1.501 (1.653)
Epoch: [42][140/200]	Time 0.520 (0.582)	Total loss 1.632 (1.655)
Epoch: [42][145/200]	Time 0.541 (0.580)	Total loss 1.669 (1.656)
Epoch: [42][150/200]	Time 0.536 (0.579)	Total loss 1.208 (1.654)
Epoch: [42][155/200]	Time 0.651 (0.578)	Total loss 1.714 (1.651)
Epoch: [42][160/200]	Time 0.508 (0.583)	Total loss 1.509 (1.652)
Epoch: [42][165/200]	Time 0.507 (0.582)	Total loss 1.756 (1.648)
Epoch: [42][170/200]	Time 0.518 (0.581)	Total loss 1.720 (1.651)
Epoch: [42][175/200]	Time 0.538 (0.580)	Total loss 1.857 (1.655)
Epoch: [42][180/200]	Time 0.551 (0.580)	Total loss 1.961 (1.655)
Epoch: [42][185/200]	Time 0.521 (0.578)	Total loss 1.782 (1.653)
Epoch: [42][190/200]	Time 0.514 (0.583)	Total loss 1.540 (1.651)
Epoch: [42][195/200]	Time 0.677 (0.583)	Total loss 1.555 (1.650)
Epoch: [42][200/200]	Time 0.536 (0.581)	Total loss 1.662 (1.650)
==> start training epoch 43 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [43][5/200]	Time 0.506 (0.930)	Total loss 1.763 (1.657)
Epoch: [43][10/200]	Time 0.523 (0.725)	Total loss 1.707 (1.604)
Epoch: [43][15/200]	Time 0.555 (0.667)	Total loss 1.663 (1.604)
Epoch: [43][20/200]	Time 0.512 (0.630)	Total loss 1.301 (1.590)
Epoch: [43][25/200]	Time 0.537 (0.617)	Total loss 1.494 (1.612)
Epoch: [43][30/200]	Time 0.624 (0.605)	Total loss 1.754 (1.619)
Epoch: [43][35/200]	Time 0.510 (0.596)	Total loss 1.702 (1.630)
Epoch: [43][40/200]	Time 0.517 (0.589)	Total loss 2.010 (1.642)
Epoch: [43][45/200]	Time 0.527 (0.582)	Total loss 1.389 (1.626)
Epoch: [43][50/200]	Time 1.905 (0.607)	Total loss 1.824 (1.640)
Epoch: [43][55/200]	Time 0.581 (0.601)	Total loss 1.265 (1.631)
Epoch: [43][60/200]	Time 0.544 (0.596)	Total loss 1.307 (1.626)
Epoch: [43][65/200]	Time 0.553 (0.590)	Total loss 1.606 (1.619)
Epoch: [43][70/200]	Time 0.510 (0.586)	Total loss 2.301 (1.628)
Epoch: [43][75/200]	Time 0.524 (0.582)	Total loss 1.848 (1.634)
Epoch: [43][80/200]	Time 0.514 (0.580)	Total loss 1.484 (1.635)
Epoch: [43][85/200]	Time 0.530 (0.576)	Total loss 1.476 (1.632)
Epoch: [43][90/200]	Time 0.534 (0.574)	Total loss 1.833 (1.633)
Epoch: [43][95/200]	Time 0.605 (0.572)	Total loss 2.010 (1.634)
Epoch: [43][100/200]	Time 0.522 (0.569)	Total loss 1.472 (1.633)
Epoch: [43][105/200]	Time 2.055 (0.593)	Total loss 1.367 (1.632)
Epoch: [43][110/200]	Time 0.518 (0.590)	Total loss 1.546 (1.633)
Epoch: [43][115/200]	Time 0.521 (0.588)	Total loss 1.355 (1.627)
Epoch: [43][120/200]	Time 0.519 (0.584)	Total loss 1.460 (1.624)
Epoch: [43][125/200]	Time 0.491 (0.583)	Total loss 1.536 (1.626)
Epoch: [43][130/200]	Time 0.529 (0.581)	Total loss 1.555 (1.623)
Epoch: [43][135/200]	Time 0.487 (0.579)	Total loss 1.803 (1.624)
Epoch: [43][140/200]	Time 0.593 (0.578)	Total loss 1.422 (1.623)
Epoch: [43][145/200]	Time 0.532 (0.584)	Total loss 1.826 (1.629)
Epoch: [43][150/200]	Time 0.522 (0.583)	Total loss 1.488 (1.632)
Epoch: [43][155/200]	Time 0.725 (0.582)	Total loss 1.676 (1.632)
Epoch: [43][160/200]	Time 0.586 (0.581)	Total loss 1.759 (1.630)
Epoch: [43][165/200]	Time 0.565 (0.581)	Total loss 1.898 (1.628)
Epoch: [43][170/200]	Time 0.557 (0.581)	Total loss 2.021 (1.626)
Epoch: [43][175/200]	Time 0.518 (0.580)	Total loss 1.534 (1.625)
Epoch: [43][180/200]	Time 0.514 (0.579)	Total loss 1.392 (1.621)
Epoch: [43][185/200]	Time 0.513 (0.578)	Total loss 1.763 (1.622)
Epoch: [43][190/200]	Time 0.665 (0.577)	Total loss 1.497 (1.619)
Epoch: [43][195/200]	Time 0.552 (0.576)	Total loss 1.697 (1.616)
Epoch: [43][200/200]	Time 0.513 (0.575)	Total loss 1.509 (1.617)
Extract Features: [50/53]	Time 0.050 (0.130)	Data 0.000 (0.067)	
Mean AP: 37.7%
CMC Scores:
  top-1          39.4%
  top-5          60.0%
  top-10         69.1%

 * Finished epoch  43  model mAP: 37.7%  best: 38.1%

==> start training epoch 44 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [44][5/200]	Time 0.492 (1.274)	Total loss 1.480 (1.862)
Epoch: [44][10/200]	Time 0.522 (0.893)	Total loss 1.518 (1.723)
Epoch: [44][15/200]	Time 1.783 (0.859)	Total loss 1.872 (1.695)
Epoch: [44][20/200]	Time 0.709 (0.783)	Total loss 1.535 (1.700)
Epoch: [44][25/200]	Time 0.550 (0.733)	Total loss 1.622 (1.682)
Epoch: [44][30/200]	Time 0.707 (0.704)	Total loss 1.444 (1.658)
Epoch: [44][35/200]	Time 0.521 (0.676)	Total loss 1.680 (1.654)
Epoch: [44][40/200]	Time 0.548 (0.693)	Total loss 1.555 (1.650)
Epoch: [44][45/200]	Time 0.529 (0.674)	Total loss 1.531 (1.627)
Epoch: [44][50/200]	Time 0.514 (0.663)	Total loss 1.254 (1.635)
Epoch: [44][55/200]	Time 0.540 (0.651)	Total loss 1.656 (1.651)
Epoch: [44][60/200]	Time 0.521 (0.644)	Total loss 1.754 (1.637)
Epoch: [44][65/200]	Time 0.543 (0.635)	Total loss 1.801 (1.635)
Epoch: [44][70/200]	Time 0.548 (0.630)	Total loss 1.625 (1.631)
Epoch: [44][75/200]	Time 0.560 (0.623)	Total loss 1.786 (1.631)
Epoch: [44][80/200]	Time 0.549 (0.618)	Total loss 1.479 (1.617)
Epoch: [44][85/200]	Time 0.545 (0.615)	Total loss 1.441 (1.611)
Epoch: [44][90/200]	Time 0.676 (0.612)	Total loss 1.543 (1.607)
Epoch: [44][95/200]	Time 0.524 (0.607)	Total loss 1.275 (1.601)
Epoch: [44][100/200]	Time 0.505 (0.604)	Total loss 1.608 (1.603)
Epoch: [44][105/200]	Time 0.508 (0.600)	Total loss 1.618 (1.608)
Epoch: [44][110/200]	Time 0.562 (0.599)	Total loss 1.355 (1.605)
Epoch: [44][115/200]	Time 0.509 (0.598)	Total loss 1.367 (1.605)
Epoch: [44][120/200]	Time 0.512 (0.596)	Total loss 1.731 (1.610)
Epoch: [44][125/200]	Time 0.506 (0.592)	Total loss 1.321 (1.608)
Epoch: [44][130/200]	Time 0.504 (0.610)	Total loss 2.330 (1.613)
Epoch: [44][135/200]	Time 0.518 (0.608)	Total loss 1.415 (1.610)
Epoch: [44][140/200]	Time 0.553 (0.605)	Total loss 1.478 (1.603)
Epoch: [44][145/200]	Time 0.550 (0.604)	Total loss 1.714 (1.608)
Epoch: [44][150/200]	Time 0.529 (0.601)	Total loss 1.842 (1.612)
Epoch: [44][155/200]	Time 0.529 (0.600)	Total loss 1.364 (1.610)
Epoch: [44][160/200]	Time 0.511 (0.599)	Total loss 1.075 (1.607)
Epoch: [44][165/200]	Time 0.477 (0.604)	Total loss 1.753 (1.605)
Epoch: [44][170/200]	Time 0.494 (0.602)	Total loss 1.688 (1.607)
Epoch: [44][175/200]	Time 0.517 (0.600)	Total loss 1.804 (1.608)
Epoch: [44][180/200]	Time 0.541 (0.598)	Total loss 1.552 (1.606)
Epoch: [44][185/200]	Time 0.692 (0.597)	Total loss 1.671 (1.606)
Epoch: [44][190/200]	Time 0.534 (0.595)	Total loss 1.766 (1.606)
Epoch: [44][195/200]	Time 0.529 (0.594)	Total loss 1.618 (1.605)
Epoch: [44][200/200]	Time 0.536 (0.593)	Total loss 1.379 (1.609)
==> start training epoch 45 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [45][5/200]	Time 0.546 (1.027)	Total loss 1.516 (1.640)
Epoch: [45][10/200]	Time 0.522 (0.785)	Total loss 1.260 (1.556)
Epoch: [45][15/200]	Time 0.510 (0.709)	Total loss 1.310 (1.503)
Epoch: [45][20/200]	Time 0.559 (0.663)	Total loss 1.367 (1.514)
Epoch: [45][25/200]	Time 0.522 (0.686)	Total loss 1.348 (1.527)
Epoch: [45][30/200]	Time 0.545 (0.668)	Total loss 1.436 (1.521)
Epoch: [45][35/200]	Time 0.707 (0.653)	Total loss 1.254 (1.495)
Epoch: [45][40/200]	Time 0.510 (0.636)	Total loss 1.741 (1.517)
Epoch: [45][45/200]	Time 0.559 (0.658)	Total loss 1.856 (1.543)
Epoch: [45][50/200]	Time 0.489 (0.646)	Total loss 1.961 (1.556)
Epoch: [45][55/200]	Time 0.497 (0.635)	Total loss 1.849 (1.556)
Epoch: [45][60/200]	Time 0.525 (0.628)	Total loss 1.702 (1.568)
Epoch: [45][65/200]	Time 0.519 (0.623)	Total loss 1.635 (1.568)
Epoch: [45][70/200]	Time 0.707 (0.619)	Total loss 1.544 (1.570)
Epoch: [45][75/200]	Time 0.519 (0.613)	Total loss 2.098 (1.579)
Epoch: [45][80/200]	Time 0.513 (0.609)	Total loss 1.840 (1.589)
Epoch: [45][85/200]	Time 0.504 (0.604)	Total loss 1.444 (1.584)
Epoch: [45][90/200]	Time 0.519 (0.601)	Total loss 1.962 (1.589)
Epoch: [45][95/200]	Time 0.516 (0.598)	Total loss 1.824 (1.601)
Epoch: [45][100/200]	Time 0.578 (0.595)	Total loss 1.411 (1.600)
Epoch: [45][105/200]	Time 0.515 (0.594)	Total loss 1.581 (1.600)
Epoch: [45][110/200]	Time 0.680 (0.591)	Total loss 1.612 (1.598)
Epoch: [45][115/200]	Time 1.604 (0.597)	Total loss 1.446 (1.596)
Epoch: [45][120/200]	Time 0.550 (0.596)	Total loss 1.772 (1.604)
Epoch: [45][125/200]	Time 0.525 (0.593)	Total loss 2.022 (1.609)
Epoch: [45][130/200]	Time 0.487 (0.591)	Total loss 1.862 (1.606)
Epoch: [45][135/200]	Time 0.483 (0.589)	Total loss 1.292 (1.600)
Epoch: [45][140/200]	Time 0.512 (0.587)	Total loss 1.433 (1.592)
Epoch: [45][145/200]	Time 0.535 (0.586)	Total loss 1.587 (1.590)
Epoch: [45][150/200]	Time 0.717 (0.585)	Total loss 1.534 (1.588)
Epoch: [45][155/200]	Time 0.537 (0.591)	Total loss 1.312 (1.586)
Epoch: [45][160/200]	Time 0.525 (0.591)	Total loss 1.491 (1.586)
Epoch: [45][165/200]	Time 0.553 (0.589)	Total loss 1.400 (1.583)
Epoch: [45][170/200]	Time 0.504 (0.588)	Total loss 1.586 (1.581)
Epoch: [45][175/200]	Time 0.501 (0.587)	Total loss 1.286 (1.582)
Epoch: [45][180/200]	Time 0.529 (0.585)	Total loss 1.697 (1.581)
Epoch: [45][185/200]	Time 0.512 (0.584)	Total loss 1.963 (1.589)
Epoch: [45][190/200]	Time 0.685 (0.584)	Total loss 1.800 (1.591)
Epoch: [45][195/200]	Time 0.526 (0.582)	Total loss 1.443 (1.591)
Epoch: [45][200/200]	Time 0.511 (0.581)	Total loss 1.855 (1.597)
Extract Features: [50/53]	Time 0.050 (0.129)	Data 0.000 (0.064)	
Mean AP: 37.8%
CMC Scores:
  top-1          39.4%
  top-5          61.1%
  top-10         68.4%

 * Finished epoch  45  model mAP: 37.8%  best: 38.1%

==> start training epoch 46 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [46][5/200]	Time 0.492 (1.120)	Total loss 1.335 (1.542)
Epoch: [46][10/200]	Time 0.491 (0.919)	Total loss 1.960 (1.616)
Epoch: [46][15/200]	Time 0.555 (0.796)	Total loss 1.487 (1.591)
Epoch: [46][20/200]	Time 0.695 (0.799)	Total loss 1.330 (1.573)
Epoch: [46][25/200]	Time 0.514 (0.741)	Total loss 1.963 (1.583)
Epoch: [46][30/200]	Time 0.684 (0.708)	Total loss 1.552 (1.565)
Epoch: [46][35/200]	Time 0.538 (0.681)	Total loss 1.549 (1.575)
Epoch: [46][40/200]	Time 0.538 (0.664)	Total loss 1.596 (1.585)
Epoch: [46][45/200]	Time 0.466 (0.652)	Total loss 1.700 (1.591)
Epoch: [46][50/200]	Time 0.559 (0.638)	Total loss 1.542 (1.604)
Epoch: [46][55/200]	Time 0.551 (0.632)	Total loss 1.533 (1.619)
Epoch: [46][60/200]	Time 0.704 (0.626)	Total loss 1.508 (1.604)
Epoch: [46][65/200]	Time 0.510 (0.617)	Total loss 1.903 (1.605)
Epoch: [46][70/200]	Time 0.530 (0.633)	Total loss 1.778 (1.607)
Epoch: [46][75/200]	Time 0.503 (0.627)	Total loss 1.501 (1.598)
Epoch: [46][80/200]	Time 0.489 (0.620)	Total loss 1.431 (1.591)
Epoch: [46][85/200]	Time 0.563 (0.616)	Total loss 1.399 (1.586)
Epoch: [46][90/200]	Time 0.505 (0.612)	Total loss 1.698 (1.585)
Epoch: [46][95/200]	Time 0.508 (0.606)	Total loss 1.535 (1.584)
Epoch: [46][100/200]	Time 0.514 (0.603)	Total loss 1.803 (1.594)
Epoch: [46][105/200]	Time 0.703 (0.612)	Total loss 1.172 (1.587)
Epoch: [46][110/200]	Time 0.548 (0.608)	Total loss 1.426 (1.588)
Epoch: [46][115/200]	Time 0.528 (0.606)	Total loss 1.496 (1.586)
Epoch: [46][120/200]	Time 0.512 (0.603)	Total loss 1.289 (1.589)
Epoch: [46][125/200]	Time 0.545 (0.601)	Total loss 1.707 (1.586)
Epoch: [46][130/200]	Time 0.518 (0.600)	Total loss 1.861 (1.588)
Epoch: [46][135/200]	Time 0.539 (0.597)	Total loss 1.377 (1.581)
Epoch: [46][140/200]	Time 0.524 (0.596)	Total loss 1.694 (1.581)
Epoch: [46][145/200]	Time 0.681 (0.595)	Total loss 1.644 (1.587)
Epoch: [46][150/200]	Time 0.517 (0.592)	Total loss 1.479 (1.585)
Epoch: [46][155/200]	Time 0.551 (0.591)	Total loss 1.705 (1.584)
Epoch: [46][160/200]	Time 0.517 (0.589)	Total loss 1.707 (1.584)
Epoch: [46][165/200]	Time 0.518 (0.588)	Total loss 1.293 (1.584)
Epoch: [46][170/200]	Time 0.532 (0.587)	Total loss 1.841 (1.588)
Epoch: [46][175/200]	Time 0.567 (0.585)	Total loss 1.714 (1.587)
Epoch: [46][180/200]	Time 1.669 (0.590)	Total loss 1.575 (1.592)
Epoch: [46][185/200]	Time 0.656 (0.589)	Total loss 1.721 (1.592)
Epoch: [46][190/200]	Time 0.507 (0.586)	Total loss 1.405 (1.593)
Epoch: [46][195/200]	Time 0.546 (0.591)	Total loss 1.512 (1.592)
Epoch: [46][200/200]	Time 0.546 (0.590)	Total loss 1.565 (1.588)
==> start training epoch 47 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [47][5/200]	Time 0.472 (0.809)	Total loss 1.770 (1.505)
Epoch: [47][10/200]	Time 0.477 (0.652)	Total loss 1.558 (1.468)
Epoch: [47][15/200]	Time 0.499 (0.605)	Total loss 1.465 (1.468)
Epoch: [47][20/200]	Time 0.508 (0.586)	Total loss 1.290 (1.486)
Epoch: [47][25/200]	Time 0.507 (0.572)	Total loss 1.483 (1.492)
Epoch: [47][30/200]	Time 0.504 (0.562)	Total loss 1.606 (1.520)
Epoch: [47][35/200]	Time 0.621 (0.560)	Total loss 1.859 (1.545)
Epoch: [47][40/200]	Time 0.516 (0.554)	Total loss 1.642 (1.536)
Epoch: [47][45/200]	Time 0.493 (0.553)	Total loss 1.295 (1.544)
Epoch: [47][50/200]	Time 0.511 (0.549)	Total loss 2.330 (1.572)
Epoch: [47][55/200]	Time 0.523 (0.548)	Total loss 1.341 (1.571)
Epoch: [47][60/200]	Time 0.570 (0.548)	Total loss 1.541 (1.577)
Epoch: [47][65/200]	Time 0.557 (0.548)	Total loss 1.657 (1.580)
Epoch: [47][70/200]	Time 0.521 (0.547)	Total loss 1.960 (1.591)
Epoch: [47][75/200]	Time 0.514 (0.563)	Total loss 1.432 (1.592)
Epoch: [47][80/200]	Time 0.491 (0.560)	Total loss 1.848 (1.596)
Epoch: [47][85/200]	Time 0.614 (0.558)	Total loss 1.669 (1.601)
Epoch: [47][90/200]	Time 0.485 (0.567)	Total loss 1.647 (1.599)
Epoch: [47][95/200]	Time 0.546 (0.577)	Total loss 1.739 (1.610)
Epoch: [47][100/200]	Time 0.651 (0.576)	Total loss 1.798 (1.605)
Epoch: [47][105/200]	Time 0.533 (0.574)	Total loss 1.677 (1.607)
Epoch: [47][110/200]	Time 0.503 (0.572)	Total loss 1.629 (1.610)
Epoch: [47][115/200]	Time 0.664 (0.571)	Total loss 1.599 (1.612)
Epoch: [47][120/200]	Time 0.501 (0.569)	Total loss 1.513 (1.608)
Epoch: [47][125/200]	Time 0.514 (0.568)	Total loss 1.627 (1.604)
Epoch: [47][130/200]	Time 0.660 (0.567)	Total loss 1.683 (1.601)
Epoch: [47][135/200]	Time 0.517 (0.565)	Total loss 1.549 (1.595)
Epoch: [47][140/200]	Time 0.570 (0.565)	Total loss 1.449 (1.595)
Epoch: [47][145/200]	Time 0.569 (0.564)	Total loss 1.585 (1.606)
Epoch: [47][150/200]	Time 0.487 (0.563)	Total loss 1.726 (1.605)
Epoch: [47][155/200]	Time 0.542 (0.563)	Total loss 1.459 (1.603)
Epoch: [47][160/200]	Time 0.512 (0.561)	Total loss 1.709 (1.602)
Epoch: [47][165/200]	Time 0.507 (0.561)	Total loss 1.343 (1.603)
Epoch: [47][170/200]	Time 0.667 (0.561)	Total loss 1.707 (1.603)
Epoch: [47][175/200]	Time 0.480 (0.559)	Total loss 1.490 (1.600)
Epoch: [47][180/200]	Time 1.703 (0.565)	Total loss 1.645 (1.597)
Epoch: [47][185/200]	Time 0.494 (0.564)	Total loss 1.749 (1.596)
Epoch: [47][190/200]	Time 0.520 (0.563)	Total loss 1.458 (1.592)
Epoch: [47][195/200]	Time 0.534 (0.563)	Total loss 1.650 (1.590)
Epoch: [47][200/200]	Time 0.509 (0.562)	Total loss 1.248 (1.586)
Extract Features: [50/53]	Time 0.091 (0.127)	Data 0.038 (0.061)	
Mean AP: 38.2%
CMC Scores:
  top-1          40.7%
  top-5          59.6%
  top-10         68.6%

 * Finished epoch  47  model mAP: 38.2%  best: 38.2% *

==> start training epoch 48 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [48][5/200]	Time 0.526 (1.215)	Total loss 1.179 (1.440)
Epoch: [48][10/200]	Time 0.548 (0.997)	Total loss 1.554 (1.579)
Epoch: [48][15/200]	Time 0.522 (0.846)	Total loss 1.791 (1.630)
Epoch: [48][20/200]	Time 0.489 (0.772)	Total loss 1.708 (1.625)
Epoch: [48][25/200]	Time 0.547 (0.719)	Total loss 1.441 (1.594)
Epoch: [48][30/200]	Time 0.519 (0.690)	Total loss 1.880 (1.606)
Epoch: [48][35/200]	Time 0.512 (0.669)	Total loss 1.467 (1.604)
Epoch: [48][40/200]	Time 0.502 (0.649)	Total loss 1.512 (1.623)
Epoch: [48][45/200]	Time 0.516 (0.638)	Total loss 1.546 (1.616)
Epoch: [48][50/200]	Time 0.501 (0.629)	Total loss 1.443 (1.613)
Epoch: [48][55/200]	Time 0.516 (0.619)	Total loss 1.539 (1.605)
Epoch: [48][60/200]	Time 0.525 (0.613)	Total loss 1.546 (1.599)
Epoch: [48][65/200]	Time 0.633 (0.608)	Total loss 1.417 (1.589)
Epoch: [48][70/200]	Time 0.497 (0.601)	Total loss 1.072 (1.581)
Epoch: [48][75/200]	Time 0.507 (0.611)	Total loss 1.381 (1.587)
Epoch: [48][80/200]	Time 0.500 (0.607)	Total loss 1.501 (1.585)
Epoch: [48][85/200]	Time 0.534 (0.604)	Total loss 1.469 (1.583)
Epoch: [48][90/200]	Time 0.506 (0.601)	Total loss 1.842 (1.587)
Epoch: [48][95/200]	Time 0.518 (0.597)	Total loss 1.550 (1.586)
Epoch: [48][100/200]	Time 0.511 (0.595)	Total loss 1.500 (1.579)
Epoch: [48][105/200]	Time 0.704 (0.593)	Total loss 1.630 (1.581)
Epoch: [48][110/200]	Time 0.513 (0.589)	Total loss 2.099 (1.594)
Epoch: [48][115/200]	Time 0.498 (0.587)	Total loss 1.843 (1.590)
Epoch: [48][120/200]	Time 0.506 (0.594)	Total loss 1.482 (1.587)
Epoch: [48][125/200]	Time 0.570 (0.593)	Total loss 1.606 (1.586)
Epoch: [48][130/200]	Time 0.589 (0.602)	Total loss 1.521 (1.585)
Epoch: [48][135/200]	Time 0.517 (0.599)	Total loss 1.634 (1.585)
Epoch: [48][140/200]	Time 0.479 (0.597)	Total loss 1.849 (1.586)
Epoch: [48][145/200]	Time 0.647 (0.594)	Total loss 1.354 (1.583)
Epoch: [48][150/200]	Time 0.496 (0.591)	Total loss 1.570 (1.586)
Epoch: [48][155/200]	Time 0.529 (0.590)	Total loss 1.938 (1.590)
Epoch: [48][160/200]	Time 0.473 (0.587)	Total loss 1.261 (1.586)
Epoch: [48][165/200]	Time 0.489 (0.585)	Total loss 1.391 (1.582)
Epoch: [48][170/200]	Time 0.545 (0.590)	Total loss 1.873 (1.583)
Epoch: [48][175/200]	Time 0.529 (0.588)	Total loss 1.383 (1.581)
Epoch: [48][180/200]	Time 0.535 (0.587)	Total loss 1.659 (1.580)
Epoch: [48][185/200]	Time 0.648 (0.586)	Total loss 1.635 (1.577)
Epoch: [48][190/200]	Time 0.506 (0.584)	Total loss 1.487 (1.575)
Epoch: [48][195/200]	Time 0.514 (0.583)	Total loss 1.402 (1.574)
Epoch: [48][200/200]	Time 0.522 (0.582)	Total loss 1.446 (1.573)
==> start training epoch 49 	 ==> learning rate = 3.5000000000000004e-05
Epoch: [49][5/200]	Time 0.529 (1.082)	Total loss 1.498 (1.807)
Epoch: [49][10/200]	Time 0.498 (0.808)	Total loss 1.659 (1.649)
Epoch: [49][15/200]	Time 0.528 (0.711)	Total loss 1.816 (1.643)
Epoch: [49][20/200]	Time 0.502 (0.672)	Total loss 1.463 (1.609)
Epoch: [49][25/200]	Time 0.508 (0.639)	Total loss 1.498 (1.593)
Epoch: [49][30/200]	Time 0.503 (0.621)	Total loss 1.303 (1.572)
Epoch: [49][35/200]	Time 0.509 (0.642)	Total loss 1.427 (1.579)
Epoch: [49][40/200]	Time 0.517 (0.627)	Total loss 1.531 (1.580)
Epoch: [49][45/200]	Time 0.506 (0.618)	Total loss 1.285 (1.559)
Epoch: [49][50/200]	Time 0.518 (0.608)	Total loss 1.739 (1.574)
Epoch: [49][55/200]	Time 0.523 (0.602)	Total loss 1.208 (1.560)
Epoch: [49][60/200]	Time 0.488 (0.615)	Total loss 1.156 (1.554)
Epoch: [49][65/200]	Time 0.528 (0.607)	Total loss 1.459 (1.551)
Epoch: [49][70/200]	Time 0.543 (0.602)	Total loss 1.508 (1.550)
Epoch: [49][75/200]	Time 0.675 (0.600)	Total loss 1.657 (1.557)
Epoch: [49][80/200]	Time 0.534 (0.596)	Total loss 1.475 (1.558)
Epoch: [49][85/200]	Time 0.543 (0.594)	Total loss 1.402 (1.553)
Epoch: [49][90/200]	Time 0.619 (0.594)	Total loss 1.247 (1.552)
Epoch: [49][95/200]	Time 0.613 (0.590)	Total loss 1.795 (1.552)
Epoch: [49][100/200]	Time 0.505 (0.585)	Total loss 1.581 (1.547)
Epoch: [49][105/200]	Time 0.459 (0.581)	Total loss 1.696 (1.552)
Epoch: [49][110/200]	Time 0.623 (0.577)	Total loss 1.564 (1.550)
Epoch: [49][115/200]	Time 0.491 (0.574)	Total loss 1.175 (1.544)
Epoch: [49][120/200]	Time 0.509 (0.573)	Total loss 1.686 (1.543)
Epoch: [49][125/200]	Time 0.514 (0.571)	Total loss 1.551 (1.544)
Epoch: [49][130/200]	Time 0.507 (0.570)	Total loss 1.402 (1.547)
Epoch: [49][135/200]	Time 0.551 (0.570)	Total loss 1.933 (1.550)
Epoch: [49][140/200]	Time 0.531 (0.568)	Total loss 1.317 (1.549)
Epoch: [49][145/200]	Time 1.667 (0.575)	Total loss 1.549 (1.550)
Epoch: [49][150/200]	Time 0.656 (0.573)	Total loss 1.624 (1.552)
Epoch: [49][155/200]	Time 0.500 (0.580)	Total loss 1.375 (1.547)
Epoch: [49][160/200]	Time 0.510 (0.578)	Total loss 1.542 (1.551)
Epoch: [49][165/200]	Time 0.560 (0.577)	Total loss 1.718 (1.554)
Epoch: [49][170/200]	Time 0.504 (0.576)	Total loss 1.379 (1.553)
Epoch: [49][175/200]	Time 0.512 (0.575)	Total loss 1.789 (1.559)
Epoch: [49][180/200]	Time 0.521 (0.574)	Total loss 1.794 (1.560)
Epoch: [49][185/200]	Time 1.841 (0.580)	Total loss 1.374 (1.561)
Epoch: [49][190/200]	Time 0.689 (0.580)	Total loss 1.464 (1.560)
Epoch: [49][195/200]	Time 0.510 (0.578)	Total loss 1.469 (1.560)
Epoch: [49][200/200]	Time 0.493 (0.577)	Total loss 1.804 (1.561)
Extract Features: [50/53]	Time 0.067 (0.129)	Data 0.000 (0.067)	
Mean AP: 37.8%
CMC Scores:
  top-1          39.9%
  top-5          58.9%
  top-10         68.7%

 * Finished epoch  49  model mAP: 37.8%  best: 38.2%

==> start training epoch 50 	 ==> learning rate = 3.500000000000001e-06
Epoch: [50][5/200]	Time 0.526 (1.107)	Total loss 1.173 (1.634)
Epoch: [50][10/200]	Time 0.527 (0.821)	Total loss 1.615 (1.565)
Epoch: [50][15/200]	Time 0.480 (0.724)	Total loss 1.654 (1.564)
Epoch: [50][20/200]	Time 0.522 (0.673)	Total loss 1.654 (1.520)
Epoch: [50][25/200]	Time 0.517 (0.644)	Total loss 1.584 (1.529)
Epoch: [50][30/200]	Time 0.532 (0.629)	Total loss 1.367 (1.521)
Epoch: [50][35/200]	Time 0.503 (0.615)	Total loss 1.360 (1.530)
Epoch: [50][40/200]	Time 0.559 (0.603)	Total loss 1.562 (1.524)
Epoch: [50][45/200]	Time 1.642 (0.623)	Total loss 1.275 (1.508)
Epoch: [50][50/200]	Time 0.703 (0.617)	Total loss 1.681 (1.519)
Epoch: [50][55/200]	Time 0.518 (0.606)	Total loss 1.687 (1.526)
Epoch: [50][60/200]	Time 0.527 (0.618)	Total loss 1.293 (1.520)
Epoch: [50][65/200]	Time 0.550 (0.614)	Total loss 1.285 (1.518)
Epoch: [50][70/200]	Time 0.497 (0.607)	Total loss 1.654 (1.519)
Epoch: [50][75/200]	Time 0.517 (0.603)	Total loss 1.703 (1.521)
Epoch: [50][80/200]	Time 0.511 (0.601)	Total loss 1.617 (1.515)
Epoch: [50][85/200]	Time 0.499 (0.596)	Total loss 2.045 (1.530)
Epoch: [50][90/200]	Time 0.517 (0.594)	Total loss 1.561 (1.533)
Epoch: [50][95/200]	Time 0.679 (0.592)	Total loss 1.171 (1.529)
Epoch: [50][100/200]	Time 0.509 (0.588)	Total loss 1.762 (1.532)
Epoch: [50][105/200]	Time 0.521 (0.587)	Total loss 1.714 (1.534)
Epoch: [50][110/200]	Time 0.524 (0.583)	Total loss 1.995 (1.534)
Epoch: [50][115/200]	Time 0.532 (0.583)	Total loss 1.555 (1.532)
Epoch: [50][120/200]	Time 0.507 (0.582)	Total loss 1.599 (1.542)
Epoch: [50][125/200]	Time 0.597 (0.581)	Total loss 1.453 (1.534)
Epoch: [50][130/200]	Time 0.491 (0.579)	Total loss 1.239 (1.535)
Epoch: [50][135/200]	Time 0.663 (0.578)	Total loss 2.028 (1.535)
Epoch: [50][140/200]	Time 0.520 (0.584)	Total loss 1.575 (1.534)
Epoch: [50][145/200]	Time 0.516 (0.583)	Total loss 1.271 (1.528)
Epoch: [50][150/200]	Time 0.552 (0.582)	Total loss 1.358 (1.529)
Epoch: [50][155/200]	Time 0.515 (0.581)	Total loss 1.415 (1.525)
Epoch: [50][160/200]	Time 0.541 (0.580)	Total loss 1.600 (1.525)
Epoch: [50][165/200]	Time 0.558 (0.579)	Total loss 1.706 (1.527)
Epoch: [50][170/200]	Time 0.530 (0.578)	Total loss 1.517 (1.524)
Epoch: [50][175/200]	Time 0.694 (0.584)	Total loss 1.484 (1.523)
Epoch: [50][180/200]	Time 0.538 (0.583)	Total loss 1.493 (1.522)
Epoch: [50][185/200]	Time 0.509 (0.582)	Total loss 1.533 (1.524)
Epoch: [50][190/200]	Time 0.490 (0.580)	Total loss 1.334 (1.521)
Epoch: [50][195/200]	Time 0.514 (0.579)	Total loss 1.338 (1.520)
Epoch: [50][200/200]	Time 0.539 (0.578)	Total loss 1.522 (1.521)
==> start training epoch 51 	 ==> learning rate = 3.500000000000001e-06
Epoch: [51][5/200]	Time 0.524 (0.916)	Total loss 1.271 (1.620)
Epoch: [51][10/200]	Time 0.523 (0.731)	Total loss 1.595 (1.539)
Epoch: [51][15/200]	Time 0.680 (0.669)	Total loss 1.263 (1.493)
Epoch: [51][20/200]	Time 0.535 (0.632)	Total loss 1.358 (1.482)
Epoch: [51][25/200]	Time 0.507 (0.620)	Total loss 2.116 (1.509)
Epoch: [51][30/200]	Time 0.534 (0.601)	Total loss 1.977 (1.532)
Epoch: [51][35/200]	Time 0.579 (0.633)	Total loss 1.554 (1.516)
Epoch: [51][40/200]	Time 0.526 (0.625)	Total loss 1.333 (1.501)
Epoch: [51][45/200]	Time 0.520 (0.643)	Total loss 1.748 (1.509)
Epoch: [51][50/200]	Time 0.563 (0.633)	Total loss 1.617 (1.498)
Epoch: [51][55/200]	Time 0.546 (0.624)	Total loss 1.267 (1.494)
Epoch: [51][60/200]	Time 0.524 (0.617)	Total loss 1.247 (1.490)
Epoch: [51][65/200]	Time 0.719 (0.614)	Total loss 1.531 (1.486)
Epoch: [51][70/200]	Time 0.524 (0.607)	Total loss 1.357 (1.487)
Epoch: [51][75/200]	Time 0.515 (0.604)	Total loss 1.323 (1.496)
Epoch: [51][80/200]	Time 0.550 (0.599)	Total loss 1.540 (1.507)
Epoch: [51][85/200]	Time 0.520 (0.611)	Total loss 1.414 (1.513)
Epoch: [51][90/200]	Time 0.514 (0.606)	Total loss 1.464 (1.512)
Epoch: [51][95/200]	Time 0.523 (0.603)	Total loss 1.500 (1.516)
Epoch: [51][100/200]	Time 0.681 (0.600)	Total loss 1.233 (1.518)
Epoch: [51][105/200]	Time 0.495 (0.595)	Total loss 1.399 (1.509)
Epoch: [51][110/200]	Time 0.519 (0.593)	Total loss 1.239 (1.501)
Epoch: [51][115/200]	Time 0.653 (0.591)	Total loss 1.507 (1.509)
Epoch: [51][120/200]	Time 0.519 (0.588)	Total loss 1.575 (1.507)
Epoch: [51][125/200]	Time 0.510 (0.595)	Total loss 1.613 (1.509)
Epoch: [51][130/200]	Time 0.531 (0.593)	Total loss 1.487 (1.509)
Epoch: [51][135/200]	Time 0.519 (0.591)	Total loss 1.429 (1.503)
Epoch: [51][140/200]	Time 0.528 (0.590)	Total loss 1.624 (1.506)
Epoch: [51][145/200]	Time 0.517 (0.589)	Total loss 1.989 (1.506)
Epoch: [51][150/200]	Time 0.730 (0.588)	Total loss 1.287 (1.504)
Epoch: [51][155/200]	Time 0.524 (0.587)	Total loss 1.435 (1.508)
Epoch: [51][160/200]	Time 0.553 (0.586)	Total loss 1.785 (1.506)
Epoch: [51][165/200]	Time 0.536 (0.584)	Total loss 1.521 (1.505)
Epoch: [51][170/200]	Time 0.555 (0.585)	Total loss 1.257 (1.502)
Epoch: [51][175/200]	Time 0.496 (0.584)	Total loss 1.669 (1.502)
Epoch: [51][180/200]	Time 0.499 (0.582)	Total loss 1.446 (1.503)
Epoch: [51][185/200]	Time 0.511 (0.580)	Total loss 1.489 (1.501)
Epoch: [51][190/200]	Time 0.618 (0.580)	Total loss 1.313 (1.500)
Epoch: [51][195/200]	Time 0.496 (0.578)	Total loss 1.486 (1.501)
Epoch: [51][200/200]	Time 0.472 (0.582)	Total loss 1.332 (1.505)
Extract Features: [50/53]	Time 0.188 (0.125)	Data 0.131 (0.061)	
Mean AP: 37.6%
CMC Scores:
  top-1          40.2%
  top-5          59.4%
  top-10         69.1%

 * Finished epoch  51  model mAP: 37.6%  best: 38.2%

==> start training epoch 52 	 ==> learning rate = 3.500000000000001e-06
Epoch: [52][5/200]	Time 0.568 (1.021)	Total loss 1.522 (1.473)
Epoch: [52][10/200]	Time 0.525 (0.776)	Total loss 1.588 (1.404)
Epoch: [52][15/200]	Time 0.509 (0.701)	Total loss 1.122 (1.382)
Epoch: [52][20/200]	Time 0.545 (0.718)	Total loss 1.321 (1.409)
Epoch: [52][25/200]	Time 0.523 (0.679)	Total loss 1.300 (1.427)
Epoch: [52][30/200]	Time 0.494 (0.654)	Total loss 1.270 (1.430)
Epoch: [52][35/200]	Time 0.667 (0.640)	Total loss 1.515 (1.432)
Epoch: [52][40/200]	Time 0.529 (0.627)	Total loss 1.315 (1.432)
Epoch: [52][45/200]	Time 0.550 (0.619)	Total loss 1.752 (1.445)
Epoch: [52][50/200]	Time 0.532 (0.613)	Total loss 1.201 (1.447)
Epoch: [52][55/200]	Time 0.579 (0.607)	Total loss 1.329 (1.446)
Epoch: [52][60/200]	Time 0.536 (0.603)	Total loss 1.488 (1.454)
Epoch: [52][65/200]	Time 0.701 (0.601)	Total loss 1.647 (1.464)
Epoch: [52][70/200]	Time 0.511 (0.595)	Total loss 1.410 (1.474)
Epoch: [52][75/200]	Time 0.490 (0.591)	Total loss 1.373 (1.476)
Epoch: [52][80/200]	Time 0.544 (0.588)	Total loss 1.627 (1.473)
Epoch: [52][85/200]	Time 0.468 (0.584)	Total loss 1.200 (1.474)
Epoch: [52][90/200]	Time 0.551 (0.582)	Total loss 1.756 (1.474)
Epoch: [52][95/200]	Time 0.571 (0.580)	Total loss 1.695 (1.480)
Epoch: [52][100/200]	Time 0.514 (0.593)	Total loss 1.292 (1.486)
Epoch: [52][105/200]	Time 0.646 (0.591)	Total loss 1.616 (1.488)
Epoch: [52][110/200]	Time 2.748 (0.607)	Total loss 1.524 (1.489)
Epoch: [52][115/200]	Time 0.488 (0.605)	Total loss 1.501 (1.492)
Epoch: [52][120/200]	Time 0.549 (0.602)	Total loss 1.329 (1.494)
Epoch: [52][125/200]	Time 0.526 (0.600)	Total loss 1.416 (1.491)
Epoch: [52][130/200]	Time 0.522 (0.599)	Total loss 1.272 (1.494)
Epoch: [52][135/200]	Time 0.535 (0.597)	Total loss 1.307 (1.492)
Epoch: [52][140/200]	Time 0.546 (0.596)	Total loss 1.408 (1.496)
Epoch: [52][145/200]	Time 0.668 (0.596)	Total loss 1.367 (1.498)
Epoch: [52][150/200]	Time 0.537 (0.594)	Total loss 1.850 (1.497)
Epoch: [52][155/200]	Time 0.528 (0.592)	Total loss 1.400 (1.498)
Epoch: [52][160/200]	Time 0.516 (0.590)	Total loss 1.490 (1.497)
Epoch: [52][165/200]	Time 0.507 (0.589)	Total loss 1.465 (1.498)
Epoch: [52][170/200]	Time 0.467 (0.588)	Total loss 1.449 (1.498)
Epoch: [52][175/200]	Time 0.510 (0.586)	Total loss 1.535 (1.495)
Epoch: [52][180/200]	Time 0.520 (0.585)	Total loss 1.464 (1.498)
Epoch: [52][185/200]	Time 0.709 (0.584)	Total loss 1.417 (1.496)
Epoch: [52][190/200]	Time 0.505 (0.582)	Total loss 1.820 (1.494)
Epoch: [52][195/200]	Time 0.516 (0.582)	Total loss 1.320 (1.495)
Epoch: [52][200/200]	Time 0.512 (0.580)	Total loss 1.135 (1.494)
==> start training epoch 53 	 ==> learning rate = 3.500000000000001e-06
Epoch: [53][5/200]	Time 0.549 (1.471)	Total loss 1.566 (1.433)
Epoch: [53][10/200]	Time 0.505 (1.010)	Total loss 1.683 (1.562)
Epoch: [53][15/200]	Time 0.523 (0.847)	Total loss 1.390 (1.531)
Epoch: [53][20/200]	Time 0.503 (0.774)	Total loss 1.305 (1.488)
Epoch: [53][25/200]	Time 0.563 (0.773)	Total loss 1.558 (1.483)
Epoch: [53][30/200]	Time 0.513 (0.733)	Total loss 1.225 (1.470)
Epoch: [53][35/200]	Time 0.704 (0.708)	Total loss 1.176 (1.461)
Epoch: [53][40/200]	Time 0.513 (0.685)	Total loss 1.741 (1.482)
Epoch: [53][45/200]	Time 0.494 (0.670)	Total loss 1.692 (1.484)
Epoch: [53][50/200]	Time 0.545 (0.657)	Total loss 1.295 (1.480)
Epoch: [53][55/200]	Time 0.501 (0.649)	Total loss 1.928 (1.501)
Epoch: [53][60/200]	Time 0.545 (0.638)	Total loss 1.701 (1.509)
Epoch: [53][65/200]	Time 0.502 (0.631)	Total loss 1.596 (1.505)
Epoch: [53][70/200]	Time 0.712 (0.625)	Total loss 1.788 (1.514)
Epoch: [53][75/200]	Time 0.507 (0.618)	Total loss 1.387 (1.501)
Epoch: [53][80/200]	Time 0.510 (0.614)	Total loss 1.834 (1.503)
Epoch: [53][85/200]	Time 0.708 (0.610)	Total loss 1.173 (1.494)
Epoch: [53][90/200]	Time 0.510 (0.605)	Total loss 1.659 (1.493)
Epoch: [53][95/200]	Time 0.506 (0.602)	Total loss 1.068 (1.487)
Epoch: [53][100/200]	Time 0.554 (0.613)	Total loss 1.495 (1.485)
Epoch: [53][105/200]	Time 0.536 (0.609)	Total loss 1.501 (1.486)
Epoch: [53][110/200]	Time 0.522 (0.607)	Total loss 1.566 (1.486)
Epoch: [53][115/200]	Time 0.530 (0.605)	Total loss 1.382 (1.487)
Epoch: [53][120/200]	Time 0.711 (0.603)	Total loss 1.403 (1.483)
Epoch: [53][125/200]	Time 0.523 (0.600)	Total loss 1.353 (1.480)
Epoch: [53][130/200]	Time 0.505 (0.599)	Total loss 1.556 (1.479)
Epoch: [53][135/200]	Time 0.488 (0.596)	Total loss 1.719 (1.479)
Epoch: [53][140/200]	Time 0.547 (0.604)	Total loss 1.435 (1.483)
Epoch: [53][145/200]	Time 0.532 (0.603)	Total loss 1.680 (1.484)
Epoch: [53][150/200]	Time 0.502 (0.601)	Total loss 2.031 (1.488)
Epoch: [53][155/200]	Time 0.508 (0.609)	Total loss 1.407 (1.485)
Epoch: [53][160/200]	Time 0.705 (0.608)	Total loss 1.652 (1.488)
Epoch: [53][165/200]	Time 0.522 (0.606)	Total loss 1.375 (1.488)
Epoch: [53][170/200]	Time 0.531 (0.605)	Total loss 1.194 (1.487)
Epoch: [53][175/200]	Time 0.539 (0.603)	Total loss 1.251 (1.486)
Epoch: [53][180/200]	Time 0.523 (0.601)	Total loss 1.710 (1.489)
Epoch: [53][185/200]	Time 0.533 (0.600)	Total loss 1.492 (1.489)
Epoch: [53][190/200]	Time 0.519 (0.604)	Total loss 1.580 (1.488)
Epoch: [53][195/200]	Time 0.579 (0.604)	Total loss 1.106 (1.487)
Epoch: [53][200/200]	Time 0.662 (0.603)	Total loss 1.233 (1.485)
Extract Features: [50/53]	Time 0.066 (0.135)	Data 0.000 (0.067)	
Mean AP: 37.3%
CMC Scores:
  top-1          40.0%
  top-5          59.4%
  top-10         69.4%

 * Finished epoch  53  model mAP: 37.3%  best: 38.2%

==> start training epoch 54 	 ==> learning rate = 3.500000000000001e-06
Epoch: [54][5/200]	Time 0.503 (1.145)	Total loss 1.339 (1.528)
Epoch: [54][10/200]	Time 0.544 (0.835)	Total loss 2.181 (1.487)
Epoch: [54][15/200]	Time 0.521 (0.752)	Total loss 1.641 (1.505)
Epoch: [54][20/200]	Time 0.652 (0.702)	Total loss 1.235 (1.474)
Epoch: [54][25/200]	Time 0.519 (0.670)	Total loss 1.722 (1.497)
Epoch: [54][30/200]	Time 0.517 (0.653)	Total loss 1.478 (1.491)
Epoch: [54][35/200]	Time 0.506 (0.637)	Total loss 1.747 (1.505)
Epoch: [54][40/200]	Time 0.638 (0.625)	Total loss 1.627 (1.510)
Epoch: [54][45/200]	Time 0.512 (0.612)	Total loss 1.431 (1.493)
Epoch: [54][50/200]	Time 0.510 (0.627)	Total loss 1.978 (1.491)
Epoch: [54][55/200]	Time 0.694 (0.619)	Total loss 1.280 (1.488)
Epoch: [54][60/200]	Time 0.469 (0.608)	Total loss 1.415 (1.503)
Epoch: [54][65/200]	Time 0.533 (0.603)	Total loss 1.174 (1.497)
Epoch: [54][70/200]	Time 0.508 (0.598)	Total loss 1.447 (1.489)
Epoch: [54][75/200]	Time 0.528 (0.595)	Total loss 1.582 (1.489)
Epoch: [54][80/200]	Time 0.535 (0.592)	Total loss 1.523 (1.497)
Epoch: [54][85/200]	Time 0.523 (0.600)	Total loss 2.068 (1.500)
Epoch: [54][90/200]	Time 0.534 (0.599)	Total loss 1.262 (1.495)
Epoch: [54][95/200]	Time 0.664 (0.596)	Total loss 1.521 (1.494)
Epoch: [54][100/200]	Time 0.535 (0.593)	Total loss 1.642 (1.498)
Epoch: [54][105/200]	Time 0.526 (0.592)	Total loss 1.848 (1.501)
Epoch: [54][110/200]	Time 0.509 (0.589)	Total loss 1.433 (1.501)
Epoch: [54][115/200]	Time 0.479 (0.587)	Total loss 1.299 (1.499)
Epoch: [54][120/200]	Time 0.537 (0.586)	Total loss 1.316 (1.498)
Epoch: [54][125/200]	Time 0.514 (0.584)	Total loss 1.742 (1.499)
Epoch: [54][130/200]	Time 0.561 (0.583)	Total loss 1.397 (1.498)
Epoch: [54][135/200]	Time 0.655 (0.582)	Total loss 1.848 (1.495)
Epoch: [54][140/200]	Time 0.519 (0.580)	Total loss 1.465 (1.493)
Epoch: [54][145/200]	Time 0.523 (0.579)	Total loss 1.360 (1.494)
Epoch: [54][150/200]	Time 0.553 (0.577)	Total loss 1.423 (1.496)
Epoch: [54][155/200]	Time 0.525 (0.576)	Total loss 1.570 (1.497)
Epoch: [54][160/200]	Time 0.517 (0.576)	Total loss 1.549 (1.496)
Epoch: [54][165/200]	Time 0.545 (0.581)	Total loss 1.258 (1.496)
Epoch: [54][170/200]	Time 0.496 (0.580)	Total loss 1.495 (1.495)
Epoch: [54][175/200]	Time 2.030 (0.587)	Total loss 1.507 (1.496)
Epoch: [54][180/200]	Time 0.522 (0.585)	Total loss 1.279 (1.494)
Epoch: [54][185/200]	Time 0.573 (0.584)	Total loss 1.309 (1.490)
Epoch: [54][190/200]	Time 0.498 (0.583)	Total loss 1.455 (1.489)
Epoch: [54][195/200]	Time 0.560 (0.582)	Total loss 1.396 (1.487)
Epoch: [54][200/200]	Time 0.551 (0.582)	Total loss 1.390 (1.483)
==> start training epoch 55 	 ==> learning rate = 3.500000000000001e-06
Epoch: [55][5/200]	Time 0.544 (0.978)	Total loss 1.560 (1.420)
Epoch: [55][10/200]	Time 0.481 (0.928)	Total loss 1.720 (1.488)
Epoch: [55][15/200]	Time 0.735 (0.809)	Total loss 1.338 (1.477)
Epoch: [55][20/200]	Time 0.541 (0.738)	Total loss 1.291 (1.470)
Epoch: [55][25/200]	Time 0.502 (0.701)	Total loss 1.368 (1.484)
Epoch: [55][30/200]	Time 0.501 (0.672)	Total loss 1.585 (1.496)
Epoch: [55][35/200]	Time 0.494 (0.654)	Total loss 0.965 (1.478)
Epoch: [55][40/200]	Time 0.508 (0.643)	Total loss 1.590 (1.502)
Epoch: [55][45/200]	Time 0.511 (0.628)	Total loss 1.268 (1.498)
Epoch: [55][50/200]	Time 0.528 (0.621)	Total loss 1.798 (1.505)
Epoch: [55][55/200]	Time 0.677 (0.616)	Total loss 1.521 (1.507)
Epoch: [55][60/200]	Time 0.494 (0.609)	Total loss 1.421 (1.517)
Epoch: [55][65/200]	Time 0.522 (0.605)	Total loss 1.287 (1.505)
Epoch: [55][70/200]	Time 0.526 (0.616)	Total loss 1.516 (1.498)
Epoch: [55][75/200]	Time 1.806 (0.629)	Total loss 1.844 (1.511)
Epoch: [55][80/200]	Time 0.535 (0.625)	Total loss 1.690 (1.514)
Epoch: [55][85/200]	Time 0.509 (0.620)	Total loss 1.109 (1.508)
Epoch: [55][90/200]	Time 0.510 (0.616)	Total loss 1.389 (1.510)
Epoch: [55][95/200]	Time 0.712 (0.613)	Total loss 1.184 (1.505)
Epoch: [55][100/200]	Time 0.497 (0.608)	Total loss 1.472 (1.502)
Epoch: [55][105/200]	Time 0.518 (0.606)	Total loss 1.340 (1.497)
Epoch: [55][110/200]	Time 0.551 (0.602)	Total loss 1.425 (1.496)
Epoch: [55][115/200]	Time 0.556 (0.601)	Total loss 1.516 (1.495)
Epoch: [55][120/200]	Time 0.547 (0.600)	Total loss 1.617 (1.493)
Epoch: [55][125/200]	Time 0.543 (0.597)	Total loss 1.669 (1.493)
Epoch: [55][130/200]	Time 0.504 (0.595)	Total loss 1.318 (1.489)
Epoch: [55][135/200]	Time 0.679 (0.594)	Total loss 1.670 (1.491)
Epoch: [55][140/200]	Time 0.513 (0.591)	Total loss 1.392 (1.488)
Epoch: [55][145/200]	Time 0.506 (0.589)	Total loss 1.445 (1.487)
Epoch: [55][150/200]	Time 0.550 (0.587)	Total loss 1.259 (1.485)
Epoch: [55][155/200]	Time 0.522 (0.585)	Total loss 1.724 (1.488)
Epoch: [55][160/200]	Time 0.503 (0.585)	Total loss 1.560 (1.492)
Epoch: [55][165/200]	Time 0.515 (0.590)	Total loss 1.273 (1.493)
Epoch: [55][170/200]	Time 0.506 (0.589)	Total loss 1.276 (1.490)
Epoch: [55][175/200]	Time 0.670 (0.587)	Total loss 1.299 (1.490)
Epoch: [55][180/200]	Time 0.531 (0.585)	Total loss 1.490 (1.491)
Epoch: [55][185/200]	Time 0.512 (0.584)	Total loss 1.500 (1.491)
Epoch: [55][190/200]	Time 0.520 (0.589)	Total loss 1.669 (1.492)
Epoch: [55][195/200]	Time 0.520 (0.588)	Total loss 1.534 (1.492)
Epoch: [55][200/200]	Time 0.559 (0.587)	Total loss 1.620 (1.494)
Extract Features: [50/53]	Time 0.059 (0.133)	Data 0.000 (0.067)	
Mean AP: 37.9%
CMC Scores:
  top-1          40.2%
  top-5          59.6%
  top-10         69.1%

 * Finished epoch  55  model mAP: 37.9%  best: 38.2%

==> start training epoch 56 	 ==> learning rate = 3.500000000000001e-06
Epoch: [56][5/200]	Time 0.547 (1.051)	Total loss 1.618 (1.308)
Epoch: [56][10/200]	Time 0.541 (0.796)	Total loss 1.631 (1.399)
Epoch: [56][15/200]	Time 0.529 (0.706)	Total loss 1.737 (1.463)
Epoch: [56][20/200]	Time 0.547 (0.663)	Total loss 1.194 (1.431)
Epoch: [56][25/200]	Time 0.554 (0.647)	Total loss 1.368 (1.436)
Epoch: [56][30/200]	Time 0.546 (0.626)	Total loss 1.635 (1.451)
Epoch: [56][35/200]	Time 0.509 (0.616)	Total loss 1.455 (1.463)
Epoch: [56][40/200]	Time 0.619 (0.606)	Total loss 1.462 (1.458)
Epoch: [56][45/200]	Time 0.534 (0.597)	Total loss 1.378 (1.466)
Epoch: [56][50/200]	Time 0.522 (0.593)	Total loss 1.256 (1.456)
Epoch: [56][55/200]	Time 0.535 (0.610)	Total loss 1.353 (1.457)
Epoch: [56][60/200]	Time 0.500 (0.604)	Total loss 1.441 (1.458)
Epoch: [56][65/200]	Time 2.044 (0.621)	Total loss 1.416 (1.465)
Epoch: [56][70/200]	Time 0.528 (0.616)	Total loss 1.308 (1.479)
Epoch: [56][75/200]	Time 0.510 (0.613)	Total loss 1.715 (1.486)
Epoch: [56][80/200]	Time 0.525 (0.607)	Total loss 1.636 (1.479)
Epoch: [56][85/200]	Time 0.533 (0.605)	Total loss 1.541 (1.480)
Epoch: [56][90/200]	Time 0.532 (0.603)	Total loss 1.254 (1.470)
Epoch: [56][95/200]	Time 0.501 (0.599)	Total loss 1.583 (1.470)
Epoch: [56][100/200]	Time 0.504 (0.596)	Total loss 1.402 (1.472)
Epoch: [56][105/200]	Time 0.504 (0.608)	Total loss 1.537 (1.470)
Epoch: [56][110/200]	Time 0.704 (0.605)	Total loss 1.067 (1.468)
Epoch: [56][115/200]	Time 0.523 (0.602)	Total loss 1.453 (1.463)
Epoch: [56][120/200]	Time 0.545 (0.601)	Total loss 1.271 (1.466)
Epoch: [56][125/200]	Time 0.524 (0.599)	Total loss 1.600 (1.464)
Epoch: [56][130/200]	Time 0.495 (0.596)	Total loss 1.404 (1.461)
Epoch: [56][135/200]	Time 0.503 (0.594)	Total loss 1.385 (1.461)
Epoch: [56][140/200]	Time 0.723 (0.592)	Total loss 1.736 (1.464)
Epoch: [56][145/200]	Time 0.514 (0.589)	Total loss 1.817 (1.466)
Epoch: [56][150/200]	Time 0.522 (0.597)	Total loss 1.422 (1.463)
Epoch: [56][155/200]	Time 0.528 (0.595)	Total loss 1.493 (1.464)
Epoch: [56][160/200]	Time 0.541 (0.594)	Total loss 1.457 (1.463)
Epoch: [56][165/200]	Time 0.494 (0.593)	Total loss 1.599 (1.467)
Epoch: [56][170/200]	Time 0.514 (0.591)	Total loss 1.538 (1.469)
Epoch: [56][175/200]	Time 0.540 (0.591)	Total loss 1.660 (1.473)
Epoch: [56][180/200]	Time 0.671 (0.590)	Total loss 1.457 (1.472)
Epoch: [56][185/200]	Time 0.554 (0.589)	Total loss 1.687 (1.470)
Epoch: [56][190/200]	Time 0.529 (0.588)	Total loss 1.669 (1.475)
Epoch: [56][195/200]	Time 0.529 (0.586)	Total loss 1.599 (1.474)
Epoch: [56][200/200]	Time 0.532 (0.586)	Total loss 1.790 (1.479)
==> start training epoch 57 	 ==> learning rate = 3.500000000000001e-06
Epoch: [57][5/200]	Time 0.519 (1.077)	Total loss 1.416 (1.464)
Epoch: [57][10/200]	Time 0.533 (0.796)	Total loss 1.695 (1.524)
Epoch: [57][15/200]	Time 0.545 (0.803)	Total loss 1.238 (1.518)
Epoch: [57][20/200]	Time 0.707 (0.742)	Total loss 1.343 (1.493)
Epoch: [57][25/200]	Time 0.518 (0.699)	Total loss 1.389 (1.490)
Epoch: [57][30/200]	Time 0.515 (0.675)	Total loss 1.454 (1.502)
Epoch: [57][35/200]	Time 0.526 (0.652)	Total loss 1.724 (1.503)
Epoch: [57][40/200]	Time 1.759 (0.671)	Total loss 1.379 (1.491)
Epoch: [57][45/200]	Time 0.511 (0.658)	Total loss 1.620 (1.477)
Epoch: [57][50/200]	Time 0.488 (0.643)	Total loss 1.696 (1.477)
Epoch: [57][55/200]	Time 0.543 (0.635)	Total loss 1.471 (1.469)
Epoch: [57][60/200]	Time 0.719 (0.629)	Total loss 1.690 (1.476)
Epoch: [57][65/200]	Time 0.522 (0.620)	Total loss 1.613 (1.485)
Epoch: [57][70/200]	Time 0.514 (0.615)	Total loss 1.257 (1.489)
Epoch: [57][75/200]	Time 0.539 (0.610)	Total loss 1.358 (1.490)
Epoch: [57][80/200]	Time 0.501 (0.606)	Total loss 1.521 (1.494)
Epoch: [57][85/200]	Time 0.568 (0.603)	Total loss 1.623 (1.495)
Epoch: [57][90/200]	Time 0.535 (0.599)	Total loss 1.654 (1.488)
Epoch: [57][95/200]	Time 0.514 (0.597)	Total loss 1.283 (1.488)
Epoch: [57][100/200]	Time 0.633 (0.594)	Total loss 1.586 (1.491)
Epoch: [57][105/200]	Time 0.531 (0.590)	Total loss 1.566 (1.492)
Epoch: [57][110/200]	Time 0.534 (0.589)	Total loss 1.358 (1.490)
Epoch: [57][115/200]	Time 0.522 (0.586)	Total loss 1.552 (1.489)
Epoch: [57][120/200]	Time 0.563 (0.585)	Total loss 1.223 (1.485)
Epoch: [57][125/200]	Time 0.510 (0.596)	Total loss 1.290 (1.489)
Epoch: [57][130/200]	Time 0.522 (0.602)	Total loss 1.591 (1.493)
Epoch: [57][135/200]	Time 0.554 (0.610)	Total loss 1.536 (1.495)
Epoch: [57][140/200]	Time 0.721 (0.609)	Total loss 1.717 (1.500)
Epoch: [57][145/200]	Time 0.517 (0.606)	Total loss 1.719 (1.502)
Epoch: [57][150/200]	Time 0.530 (0.604)	Total loss 1.809 (1.504)
Epoch: [57][155/200]	Time 0.492 (0.601)	Total loss 1.719 (1.507)
Epoch: [57][160/200]	Time 0.527 (0.599)	Total loss 1.394 (1.504)
Epoch: [57][165/200]	Time 0.488 (0.597)	Total loss 1.583 (1.504)
Epoch: [57][170/200]	Time 0.543 (0.595)	Total loss 1.460 (1.503)
Epoch: [57][175/200]	Time 0.538 (0.595)	Total loss 1.750 (1.506)
Epoch: [57][180/200]	Time 0.681 (0.594)	Total loss 1.194 (1.504)
Epoch: [57][185/200]	Time 0.526 (0.592)	Total loss 1.545 (1.501)
Epoch: [57][190/200]	Time 0.520 (0.591)	Total loss 1.368 (1.500)
Epoch: [57][195/200]	Time 0.516 (0.589)	Total loss 1.644 (1.498)
Epoch: [57][200/200]	Time 0.557 (0.588)	Total loss 1.527 (1.499)
Extract Features: [50/53]	Time 0.130 (0.138)	Data 0.073 (0.072)	
Mean AP: 37.6%
CMC Scores:
  top-1          39.8%
  top-5          59.6%
  top-10         68.5%

 * Finished epoch  57  model mAP: 37.6%  best: 38.2%

==> start training epoch 58 	 ==> learning rate = 3.500000000000001e-06
Epoch: [58][5/200]	Time 0.521 (1.380)	Total loss 1.363 (1.570)
Epoch: [58][10/200]	Time 0.529 (0.968)	Total loss 1.732 (1.601)
Epoch: [58][15/200]	Time 0.525 (0.825)	Total loss 1.504 (1.580)
Epoch: [58][20/200]	Time 0.498 (0.754)	Total loss 1.420 (1.565)
Epoch: [58][25/200]	Time 0.503 (0.713)	Total loss 1.210 (1.520)
Epoch: [58][30/200]	Time 0.744 (0.729)	Total loss 1.834 (1.522)
Epoch: [58][35/200]	Time 0.516 (0.698)	Total loss 1.181 (1.497)
Epoch: [58][40/200]	Time 1.790 (0.710)	Total loss 1.591 (1.502)
Epoch: [58][45/200]	Time 0.525 (0.694)	Total loss 1.321 (1.476)
Epoch: [58][50/200]	Time 0.547 (0.680)	Total loss 1.572 (1.484)
Epoch: [58][55/200]	Time 0.488 (0.668)	Total loss 1.336 (1.468)
Epoch: [58][60/200]	Time 0.558 (0.659)	Total loss 1.495 (1.453)
Epoch: [58][65/200]	Time 0.499 (0.649)	Total loss 1.475 (1.461)
Epoch: [58][70/200]	Time 0.509 (0.642)	Total loss 1.252 (1.467)
Epoch: [58][75/200]	Time 0.697 (0.637)	Total loss 1.488 (1.466)
Epoch: [58][80/200]	Time 0.523 (0.629)	Total loss 1.436 (1.469)
Epoch: [58][85/200]	Time 0.516 (0.626)	Total loss 1.327 (1.466)
Epoch: [58][90/200]	Time 0.539 (0.620)	Total loss 1.436 (1.470)
Epoch: [58][95/200]	Time 0.508 (0.617)	Total loss 1.432 (1.476)
Epoch: [58][100/200]	Time 0.514 (0.613)	Total loss 1.385 (1.475)
Epoch: [58][105/200]	Time 0.515 (0.608)	Total loss 1.515 (1.472)
Epoch: [58][110/200]	Time 0.513 (0.605)	Total loss 1.356 (1.474)
Epoch: [58][115/200]	Time 0.739 (0.603)	Total loss 1.312 (1.470)
Epoch: [58][120/200]	Time 0.521 (0.610)	Total loss 1.483 (1.474)
Epoch: [58][125/200]	Time 0.516 (0.608)	Total loss 1.477 (1.484)
Epoch: [58][130/200]	Time 0.531 (0.605)	Total loss 1.396 (1.486)
Epoch: [58][135/200]	Time 0.527 (0.603)	Total loss 1.601 (1.486)
Epoch: [58][140/200]	Time 0.535 (0.602)	Total loss 1.426 (1.481)
Epoch: [58][145/200]	Time 0.525 (0.599)	Total loss 1.531 (1.484)
Epoch: [58][150/200]	Time 0.507 (0.597)	Total loss 1.461 (1.487)
Epoch: [58][155/200]	Time 0.680 (0.602)	Total loss 1.553 (1.493)
Epoch: [58][160/200]	Time 0.552 (0.600)	Total loss 1.606 (1.492)
Epoch: [58][165/200]	Time 0.518 (0.599)	Total loss 1.491 (1.491)
Epoch: [58][170/200]	Time 0.502 (0.596)	Total loss 1.445 (1.492)
Epoch: [58][175/200]	Time 0.516 (0.595)	Total loss 1.201 (1.487)
Epoch: [58][180/200]	Time 0.518 (0.602)	Total loss 1.526 (1.488)
Epoch: [58][185/200]	Time 0.540 (0.600)	Total loss 1.727 (1.487)
Epoch: [58][190/200]	Time 0.512 (0.599)	Total loss 2.036 (1.490)
Epoch: [58][195/200]	Time 0.695 (0.598)	Total loss 1.651 (1.492)
Epoch: [58][200/200]	Time 0.523 (0.596)	Total loss 1.776 (1.492)
==> start training epoch 59 	 ==> learning rate = 3.500000000000001e-06
Epoch: [59][5/200]	Time 0.511 (0.714)	Total loss 1.354 (1.578)
Epoch: [59][10/200]	Time 0.517 (0.615)	Total loss 1.253 (1.559)
Epoch: [59][15/200]	Time 0.600 (0.688)	Total loss 1.490 (1.502)
Epoch: [59][20/200]	Time 0.522 (0.660)	Total loss 1.668 (1.490)
Epoch: [59][25/200]	Time 0.540 (0.633)	Total loss 1.346 (1.496)
Epoch: [59][30/200]	Time 0.536 (0.622)	Total loss 1.424 (1.492)
Epoch: [59][35/200]	Time 0.696 (0.614)	Total loss 1.529 (1.495)
Epoch: [59][40/200]	Time 0.520 (0.602)	Total loss 1.428 (1.502)
Epoch: [59][45/200]	Time 0.559 (0.599)	Total loss 1.301 (1.501)
Epoch: [59][50/200]	Time 0.546 (0.593)	Total loss 1.596 (1.505)
Epoch: [59][55/200]	Time 0.519 (0.591)	Total loss 1.326 (1.495)
Epoch: [59][60/200]	Time 0.506 (0.587)	Total loss 1.908 (1.503)
Epoch: [59][65/200]	Time 0.533 (0.583)	Total loss 1.375 (1.506)
Epoch: [59][70/200]	Time 0.506 (0.599)	Total loss 1.410 (1.500)
Epoch: [59][75/200]	Time 0.680 (0.596)	Total loss 1.693 (1.500)
Epoch: [59][80/200]	Time 0.518 (0.592)	Total loss 1.402 (1.497)
Epoch: [59][85/200]	Time 0.527 (0.590)	Total loss 1.474 (1.498)
Epoch: [59][90/200]	Time 0.520 (0.586)	Total loss 1.274 (1.491)
Epoch: [59][95/200]	Time 0.537 (0.584)	Total loss 1.851 (1.497)
Epoch: [59][100/200]	Time 0.492 (0.582)	Total loss 1.736 (1.492)
Epoch: [59][105/200]	Time 1.701 (0.589)	Total loss 1.068 (1.482)
Epoch: [59][110/200]	Time 0.503 (0.588)	Total loss 1.518 (1.491)
Epoch: [59][115/200]	Time 0.687 (0.586)	Total loss 1.729 (1.492)
Epoch: [59][120/200]	Time 0.534 (0.583)	Total loss 1.547 (1.487)
Epoch: [59][125/200]	Time 0.510 (0.582)	Total loss 1.163 (1.493)
Epoch: [59][130/200]	Time 0.509 (0.579)	Total loss 1.248 (1.491)
Epoch: [59][135/200]	Time 0.513 (0.579)	Total loss 1.580 (1.494)
Epoch: [59][140/200]	Time 0.554 (0.578)	Total loss 1.428 (1.499)
Epoch: [59][145/200]	Time 0.534 (0.577)	Total loss 1.713 (1.499)
Epoch: [59][150/200]	Time 0.532 (0.576)	Total loss 1.678 (1.499)
Epoch: [59][155/200]	Time 0.687 (0.575)	Total loss 1.482 (1.499)
Epoch: [59][160/200]	Time 0.533 (0.574)	Total loss 1.324 (1.501)
Epoch: [59][165/200]	Time 0.510 (0.573)	Total loss 1.474 (1.501)
Epoch: [59][170/200]	Time 0.491 (0.571)	Total loss 1.491 (1.502)
Epoch: [59][175/200]	Time 0.496 (0.570)	Total loss 1.735 (1.502)
Epoch: [59][180/200]	Time 0.646 (0.576)	Total loss 1.474 (1.501)
Epoch: [59][185/200]	Time 0.510 (0.575)	Total loss 1.131 (1.499)
Epoch: [59][190/200]	Time 0.506 (0.574)	Total loss 1.714 (1.498)
Epoch: [59][195/200]	Time 0.494 (0.573)	Total loss 1.415 (1.500)
Epoch: [59][200/200]	Time 0.522 (0.579)	Total loss 1.110 (1.497)
Extract Features: [50/53]	Time 0.197 (0.133)	Data 0.138 (0.065)	
Mean AP: 37.4%
CMC Scores:
  top-1          39.1%
  top-5          59.1%
  top-10         68.4%

 * Finished epoch  59  model mAP: 37.4%  best: 38.2%

==> start training epoch 60 	 ==> learning rate = 3.500000000000001e-06
Epoch: [60][5/200]	Time 0.494 (0.974)	Total loss 1.454 (1.548)
Epoch: [60][10/200]	Time 0.509 (0.772)	Total loss 1.317 (1.503)
Epoch: [60][15/200]	Time 0.532 (0.692)	Total loss 1.800 (1.511)
Epoch: [60][20/200]	Time 0.510 (0.657)	Total loss 2.209 (1.555)
Epoch: [60][25/200]	Time 0.549 (0.637)	Total loss 1.425 (1.543)
Epoch: [60][30/200]	Time 0.548 (0.621)	Total loss 1.474 (1.528)
Epoch: [60][35/200]	Time 0.511 (0.656)	Total loss 1.350 (1.525)
Epoch: [60][40/200]	Time 0.717 (0.644)	Total loss 1.558 (1.516)
Epoch: [60][45/200]	Time 0.515 (0.629)	Total loss 1.499 (1.518)
Epoch: [60][50/200]	Time 0.514 (0.620)	Total loss 1.341 (1.516)
Epoch: [60][55/200]	Time 0.527 (0.611)	Total loss 1.486 (1.512)
Epoch: [60][60/200]	Time 0.514 (0.609)	Total loss 1.214 (1.504)
Epoch: [60][65/200]	Time 0.466 (0.604)	Total loss 2.054 (1.519)
Epoch: [60][70/200]	Time 0.512 (0.598)	Total loss 1.432 (1.519)
Epoch: [60][75/200]	Time 0.497 (0.595)	Total loss 1.521 (1.510)
Epoch: [60][80/200]	Time 0.701 (0.593)	Total loss 1.547 (1.511)
Epoch: [60][85/200]	Time 0.557 (0.589)	Total loss 1.440 (1.514)
Epoch: [60][90/200]	Time 0.494 (0.586)	Total loss 1.578 (1.522)
Epoch: [60][95/200]	Time 0.522 (0.609)	Total loss 1.463 (1.526)
Epoch: [60][100/200]	Time 0.517 (0.607)	Total loss 1.734 (1.527)
Epoch: [60][105/200]	Time 0.521 (0.605)	Total loss 1.707 (1.529)
Epoch: [60][110/200]	Time 0.521 (0.601)	Total loss 1.712 (1.530)
Epoch: [60][115/200]	Time 0.508 (0.598)	Total loss 1.362 (1.531)
Epoch: [60][120/200]	Time 0.639 (0.596)	Total loss 1.649 (1.529)
Epoch: [60][125/200]	Time 0.522 (0.592)	Total loss 1.301 (1.525)
Epoch: [60][130/200]	Time 0.518 (0.591)	Total loss 1.675 (1.524)
Epoch: [60][135/200]	Time 0.507 (0.588)	Total loss 1.978 (1.529)
Epoch: [60][140/200]	Time 0.532 (0.587)	Total loss 1.764 (1.532)
Epoch: [60][145/200]	Time 0.540 (0.586)	Total loss 1.706 (1.531)
Epoch: [60][150/200]	Time 0.526 (0.584)	Total loss 1.464 (1.529)
Epoch: [60][155/200]	Time 0.511 (0.582)	Total loss 1.577 (1.531)
Epoch: [60][160/200]	Time 0.647 (0.581)	Total loss 1.619 (1.531)
Epoch: [60][165/200]	Time 0.507 (0.579)	Total loss 1.165 (1.522)
Epoch: [60][170/200]	Time 0.532 (0.578)	Total loss 1.569 (1.522)
Epoch: [60][175/200]	Time 0.528 (0.577)	Total loss 1.546 (1.521)
Epoch: [60][180/200]	Time 0.509 (0.576)	Total loss 1.539 (1.522)
Epoch: [60][185/200]	Time 0.525 (0.582)	Total loss 1.449 (1.517)
Epoch: [60][190/200]	Time 0.530 (0.580)	Total loss 1.594 (1.516)
Epoch: [60][195/200]	Time 0.517 (0.580)	Total loss 1.188 (1.516)
Epoch: [60][200/200]	Time 0.677 (0.579)	Total loss 1.667 (1.518)
==> start training epoch 61 	 ==> learning rate = 3.500000000000001e-06
Epoch: [61][5/200]	Time 1.771 (1.507)	Total loss 1.231 (1.316)
Epoch: [61][10/200]	Time 0.513 (1.036)	Total loss 1.336 (1.435)
Epoch: [61][15/200]	Time 0.535 (0.862)	Total loss 1.480 (1.449)
Epoch: [61][20/200]	Time 0.505 (0.781)	Total loss 1.821 (1.481)
Epoch: [61][25/200]	Time 0.486 (0.733)	Total loss 1.614 (1.488)
Epoch: [61][30/200]	Time 0.514 (0.694)	Total loss 1.289 (1.481)
Epoch: [61][35/200]	Time 0.504 (0.674)	Total loss 1.487 (1.486)
Epoch: [61][40/200]	Time 0.638 (0.657)	Total loss 1.619 (1.492)
Epoch: [61][45/200]	Time 0.560 (0.644)	Total loss 1.360 (1.478)
Epoch: [61][50/200]	Time 0.528 (0.634)	Total loss 1.277 (1.473)
Epoch: [61][55/200]	Time 0.570 (0.625)	Total loss 1.491 (1.475)
Epoch: [61][60/200]	Time 0.547 (0.619)	Total loss 1.752 (1.481)
Epoch: [61][65/200]	Time 0.495 (0.612)	Total loss 1.497 (1.490)
Epoch: [61][70/200]	Time 0.479 (0.604)	Total loss 1.150 (1.485)
Epoch: [61][75/200]	Time 0.534 (0.599)	Total loss 1.491 (1.485)
Epoch: [61][80/200]	Time 0.668 (0.607)	Total loss 1.280 (1.489)
Epoch: [61][85/200]	Time 0.471 (0.600)	Total loss 1.225 (1.496)
Epoch: [61][90/200]	Time 0.512 (0.610)	Total loss 1.285 (1.493)
Epoch: [61][95/200]	Time 0.484 (0.605)	Total loss 1.975 (1.495)
Epoch: [61][100/200]	Time 0.492 (0.602)	Total loss 1.618 (1.493)
Epoch: [61][105/200]	Time 0.489 (0.599)	Total loss 1.481 (1.493)
Epoch: [61][110/200]	Time 0.512 (0.596)	Total loss 1.194 (1.487)
Epoch: [61][115/200]	Time 0.520 (0.594)	Total loss 1.467 (1.489)
Epoch: [61][120/200]	Time 0.710 (0.602)	Total loss 1.087 (1.483)
Epoch: [61][125/200]	Time 0.504 (0.599)	Total loss 1.302 (1.478)
Epoch: [61][130/200]	Time 0.514 (0.596)	Total loss 1.292 (1.475)
Epoch: [61][135/200]	Time 0.490 (0.593)	Total loss 1.543 (1.476)
Epoch: [61][140/200]	Time 0.531 (0.591)	Total loss 1.679 (1.479)
Epoch: [61][145/200]	Time 0.513 (0.589)	Total loss 1.827 (1.478)
Epoch: [61][150/200]	Time 0.527 (0.587)	Total loss 1.279 (1.472)
Epoch: [61][155/200]	Time 0.511 (0.585)	Total loss 1.305 (1.472)
Epoch: [61][160/200]	Time 0.646 (0.584)	Total loss 1.550 (1.473)
Epoch: [61][165/200]	Time 0.482 (0.581)	Total loss 1.252 (1.474)
Epoch: [61][170/200]	Time 1.702 (0.586)	Total loss 1.790 (1.477)
Epoch: [61][175/200]	Time 0.500 (0.584)	Total loss 1.634 (1.478)
Epoch: [61][180/200]	Time 0.529 (0.584)	Total loss 1.425 (1.479)
Epoch: [61][185/200]	Time 0.503 (0.583)	Total loss 1.344 (1.479)
Epoch: [61][190/200]	Time 0.512 (0.581)	Total loss 1.392 (1.480)
Epoch: [61][195/200]	Time 0.486 (0.580)	Total loss 1.514 (1.481)
Epoch: [61][200/200]	Time 0.620 (0.579)	Total loss 1.488 (1.480)
Extract Features: [50/53]	Time 0.076 (0.129)	Data 0.009 (0.064)	
Mean AP: 37.4%
CMC Scores:
  top-1          39.1%
  top-5          58.5%
  top-10         69.1%

 * Finished epoch  61  model mAP: 37.4%  best: 38.2%

==> start training epoch 62 	 ==> learning rate = 3.500000000000001e-06
Epoch: [62][5/200]	Time 0.724 (1.179)	Total loss 1.496 (1.325)
Epoch: [62][10/200]	Time 0.532 (0.859)	Total loss 1.405 (1.415)
Epoch: [62][15/200]	Time 0.534 (0.757)	Total loss 1.753 (1.471)
Epoch: [62][20/200]	Time 0.523 (0.695)	Total loss 1.677 (1.460)
Epoch: [62][25/200]	Time 0.496 (0.664)	Total loss 1.733 (1.471)
Epoch: [62][30/200]	Time 0.517 (0.640)	Total loss 1.418 (1.461)
Epoch: [62][35/200]	Time 0.524 (0.660)	Total loss 1.437 (1.474)
Epoch: [62][40/200]	Time 0.515 (0.641)	Total loss 1.225 (1.453)
Epoch: [62][45/200]	Time 0.537 (0.630)	Total loss 1.466 (1.452)
Epoch: [62][50/200]	Time 0.552 (0.620)	Total loss 1.352 (1.465)
Epoch: [62][55/200]	Time 0.503 (0.614)	Total loss 1.491 (1.475)
Epoch: [62][60/200]	Time 0.475 (0.605)	Total loss 1.452 (1.482)
Epoch: [62][65/200]	Time 0.523 (0.616)	Total loss 1.348 (1.478)
Epoch: [62][70/200]	Time 0.477 (0.608)	Total loss 1.518 (1.480)
Epoch: [62][75/200]	Time 0.549 (0.603)	Total loss 1.863 (1.493)
Epoch: [62][80/200]	Time 0.514 (0.599)	Total loss 1.511 (1.481)
Epoch: [62][85/200]	Time 0.515 (0.597)	Total loss 1.158 (1.486)
Epoch: [62][90/200]	Time 0.519 (0.594)	Total loss 1.311 (1.485)
Epoch: [62][95/200]	Time 0.630 (0.591)	Total loss 1.450 (1.480)
Epoch: [62][100/200]	Time 0.515 (0.587)	Total loss 1.678 (1.479)
Epoch: [62][105/200]	Time 0.497 (0.585)	Total loss 1.343 (1.477)
Epoch: [62][110/200]	Time 0.528 (0.583)	Total loss 1.273 (1.475)
Epoch: [62][115/200]	Time 0.542 (0.580)	Total loss 1.457 (1.476)
Epoch: [62][120/200]	Time 0.563 (0.578)	Total loss 1.551 (1.479)
Epoch: [62][125/200]	Time 0.623 (0.578)	Total loss 1.347 (1.482)
Epoch: [62][130/200]	Time 0.526 (0.576)	Total loss 1.345 (1.482)
Epoch: [62][135/200]	Time 0.537 (0.576)	Total loss 1.535 (1.482)
Epoch: [62][140/200]	Time 0.492 (0.573)	Total loss 1.504 (1.488)
Epoch: [62][145/200]	Time 1.938 (0.590)	Total loss 1.589 (1.490)
Epoch: [62][150/200]	Time 0.510 (0.588)	Total loss 1.777 (1.493)
Epoch: [62][155/200]	Time 0.577 (0.586)	Total loss 1.114 (1.494)
Epoch: [62][160/200]	Time 0.512 (0.592)	Total loss 1.384 (1.490)
Epoch: [62][165/200]	Time 0.657 (0.590)	Total loss 1.532 (1.491)
Epoch: [62][170/200]	Time 0.512 (0.588)	Total loss 1.591 (1.494)
Epoch: [62][175/200]	Time 0.490 (0.587)	Total loss 1.252 (1.488)
Epoch: [62][180/200]	Time 0.483 (0.585)	Total loss 1.273 (1.483)
Epoch: [62][185/200]	Time 0.534 (0.584)	Total loss 1.368 (1.483)
Epoch: [62][190/200]	Time 0.521 (0.583)	Total loss 1.518 (1.487)
Epoch: [62][195/200]	Time 0.476 (0.580)	Total loss 1.451 (1.489)
Epoch: [62][200/200]	Time 0.508 (0.579)	Total loss 1.531 (1.489)
==> start training epoch 63 	 ==> learning rate = 3.500000000000001e-06
Epoch: [63][5/200]	Time 0.662 (0.745)	Total loss 1.563 (1.508)
Epoch: [63][10/200]	Time 0.510 (0.625)	Total loss 1.607 (1.514)
Epoch: [63][15/200]	Time 0.557 (0.601)	Total loss 1.244 (1.498)
Epoch: [63][20/200]	Time 0.496 (0.576)	Total loss 1.674 (1.513)
Epoch: [63][25/200]	Time 0.514 (0.569)	Total loss 1.516 (1.505)
Epoch: [63][30/200]	Time 0.510 (0.564)	Total loss 1.281 (1.486)
Epoch: [63][35/200]	Time 0.472 (0.555)	Total loss 1.648 (1.484)
Epoch: [63][40/200]	Time 0.488 (0.555)	Total loss 1.325 (1.486)
Epoch: [63][45/200]	Time 0.621 (0.552)	Total loss 1.473 (1.476)
Epoch: [63][50/200]	Time 0.496 (0.569)	Total loss 1.359 (1.466)
Epoch: [63][55/200]	Time 0.539 (0.566)	Total loss 1.627 (1.469)
Epoch: [63][60/200]	Time 0.502 (0.581)	Total loss 1.555 (1.479)
Epoch: [63][65/200]	Time 0.510 (0.578)	Total loss 1.676 (1.477)
Epoch: [63][70/200]	Time 0.466 (0.574)	Total loss 1.360 (1.479)
Epoch: [63][75/200]	Time 0.526 (0.569)	Total loss 1.466 (1.490)
Epoch: [63][80/200]	Time 0.501 (0.569)	Total loss 1.188 (1.489)
Epoch: [63][85/200]	Time 0.700 (0.568)	Total loss 1.614 (1.482)
Epoch: [63][90/200]	Time 0.507 (0.566)	Total loss 1.493 (1.478)
Epoch: [63][95/200]	Time 0.512 (0.565)	Total loss 1.721 (1.481)
Epoch: [63][100/200]	Time 0.523 (0.562)	Total loss 1.407 (1.482)
Epoch: [63][105/200]	Time 0.536 (0.562)	Total loss 1.430 (1.483)
Epoch: [63][110/200]	Time 0.533 (0.562)	Total loss 1.788 (1.484)
Epoch: [63][115/200]	Time 0.524 (0.560)	Total loss 2.015 (1.484)
Epoch: [63][120/200]	Time 0.519 (0.561)	Total loss 1.197 (1.483)
Epoch: [63][125/200]	Time 0.695 (0.560)	Total loss 1.527 (1.487)
Epoch: [63][130/200]	Time 0.484 (0.558)	Total loss 1.560 (1.490)
Epoch: [63][135/200]	Time 0.531 (0.559)	Total loss 1.490 (1.484)
Epoch: [63][140/200]	Time 0.515 (0.557)	Total loss 1.518 (1.485)
Epoch: [63][145/200]	Time 0.532 (0.567)	Total loss 1.973 (1.485)
Epoch: [63][150/200]	Time 0.539 (0.566)	Total loss 1.534 (1.486)
Epoch: [63][155/200]	Time 0.512 (0.564)	Total loss 1.299 (1.484)
Epoch: [63][160/200]	Time 0.508 (0.562)	Total loss 1.600 (1.482)
Epoch: [63][165/200]	Time 0.652 (0.562)	Total loss 1.519 (1.482)
Epoch: [63][170/200]	Time 1.776 (0.567)	Total loss 1.430 (1.486)
Epoch: [63][175/200]	Time 0.522 (0.567)	Total loss 1.498 (1.487)
Epoch: [63][180/200]	Time 0.512 (0.566)	Total loss 1.237 (1.485)
Epoch: [63][185/200]	Time 0.530 (0.566)	Total loss 1.505 (1.487)
Epoch: [63][190/200]	Time 0.514 (0.565)	Total loss 1.611 (1.493)
Epoch: [63][195/200]	Time 0.511 (0.564)	Total loss 1.302 (1.490)
Epoch: [63][200/200]	Time 0.491 (0.563)	Total loss 1.552 (1.489)
Extract Features: [50/53]	Time 0.051 (0.128)	Data 0.000 (0.065)	
Mean AP: 37.6%
CMC Scores:
  top-1          39.8%
  top-5          60.1%
  top-10         68.8%

 * Finished epoch  63  model mAP: 37.6%  best: 38.2%

==> start training epoch 64 	 ==> learning rate = 3.500000000000001e-06
Epoch: [64][5/200]	Time 0.535 (1.457)	Total loss 1.658 (1.282)
Epoch: [64][10/200]	Time 0.525 (1.010)	Total loss 1.589 (1.402)
Epoch: [64][15/200]	Time 0.694 (0.859)	Total loss 1.359 (1.425)
Epoch: [64][20/200]	Time 0.535 (0.779)	Total loss 1.670 (1.457)
Epoch: [64][25/200]	Time 0.555 (0.737)	Total loss 1.702 (1.477)
Epoch: [64][30/200]	Time 0.519 (0.705)	Total loss 1.186 (1.480)
Epoch: [64][35/200]	Time 1.843 (0.718)	Total loss 1.521 (1.481)
Epoch: [64][40/200]	Time 0.521 (0.697)	Total loss 1.508 (1.482)
Epoch: [64][45/200]	Time 0.532 (0.681)	Total loss 1.460 (1.476)
Epoch: [64][50/200]	Time 0.523 (0.666)	Total loss 1.615 (1.482)
Epoch: [64][55/200]	Time 0.519 (0.656)	Total loss 1.494 (1.481)
Epoch: [64][60/200]	Time 0.699 (0.650)	Total loss 1.752 (1.488)
Epoch: [64][65/200]	Time 0.526 (0.640)	Total loss 1.344 (1.472)
Epoch: [64][70/200]	Time 0.522 (0.634)	Total loss 1.791 (1.480)
Epoch: [64][75/200]	Time 0.532 (0.628)	Total loss 1.460 (1.485)
Epoch: [64][80/200]	Time 0.513 (0.623)	Total loss 1.357 (1.488)
Epoch: [64][85/200]	Time 0.508 (0.633)	Total loss 1.400 (1.484)
Epoch: [64][90/200]	Time 0.493 (0.626)	Total loss 1.596 (1.481)
Epoch: [64][95/200]	Time 0.535 (0.624)	Total loss 1.510 (1.476)
Epoch: [64][100/200]	Time 0.672 (0.620)	Total loss 1.567 (1.478)
Epoch: [64][105/200]	Time 0.515 (0.615)	Total loss 1.448 (1.472)
Epoch: [64][110/200]	Time 0.528 (0.613)	Total loss 1.717 (1.484)
Epoch: [64][115/200]	Time 0.528 (0.609)	Total loss 1.193 (1.484)
Epoch: [64][120/200]	Time 0.495 (0.607)	Total loss 1.603 (1.485)
Epoch: [64][125/200]	Time 0.528 (0.605)	Total loss 1.589 (1.488)
Epoch: [64][130/200]	Time 0.510 (0.611)	Total loss 1.847 (1.487)
Epoch: [64][135/200]	Time 0.531 (0.609)	Total loss 1.721 (1.485)
Epoch: [64][140/200]	Time 0.702 (0.608)	Total loss 1.411 (1.487)
Epoch: [64][145/200]	Time 0.511 (0.604)	Total loss 1.210 (1.483)
Epoch: [64][150/200]	Time 0.515 (0.603)	Total loss 1.442 (1.481)
Epoch: [64][155/200]	Time 0.574 (0.601)	Total loss 1.285 (1.480)
Epoch: [64][160/200]	Time 0.528 (0.600)	Total loss 1.479 (1.480)
Epoch: [64][165/200]	Time 0.511 (0.598)	Total loss 1.226 (1.474)
Epoch: [64][170/200]	Time 0.512 (0.596)	Total loss 1.413 (1.478)
Epoch: [64][175/200]	Time 0.505 (0.595)	Total loss 1.699 (1.478)
Epoch: [64][180/200]	Time 0.672 (0.594)	Total loss 1.671 (1.479)
Epoch: [64][185/200]	Time 0.517 (0.592)	Total loss 1.438 (1.479)
Epoch: [64][190/200]	Time 0.523 (0.591)	Total loss 1.480 (1.480)
Epoch: [64][195/200]	Time 0.530 (0.589)	Total loss 1.536 (1.484)
Epoch: [64][200/200]	Time 0.505 (0.595)	Total loss 1.146 (1.483)
==> start training epoch 65 	 ==> learning rate = 3.500000000000001e-06
Epoch: [65][5/200]	Time 0.531 (1.069)	Total loss 1.542 (1.630)
Epoch: [65][10/200]	Time 0.526 (0.795)	Total loss 1.388 (1.558)
Epoch: [65][15/200]	Time 0.504 (0.711)	Total loss 1.501 (1.577)
Epoch: [65][20/200]	Time 0.685 (0.670)	Total loss 1.477 (1.566)
Epoch: [65][25/200]	Time 0.580 (0.688)	Total loss 1.578 (1.576)
Epoch: [65][30/200]	Time 0.506 (0.669)	Total loss 1.424 (1.565)
Epoch: [65][35/200]	Time 0.548 (0.648)	Total loss 1.446 (1.551)
Epoch: [65][40/200]	Time 0.528 (0.637)	Total loss 1.621 (1.536)
Epoch: [65][45/200]	Time 0.541 (0.629)	Total loss 2.022 (1.547)
Epoch: [65][50/200]	Time 0.510 (0.618)	Total loss 1.468 (1.530)
Epoch: [65][55/200]	Time 0.524 (0.611)	Total loss 1.635 (1.526)
Epoch: [65][60/200]	Time 0.677 (0.629)	Total loss 1.367 (1.516)
Epoch: [65][65/200]	Time 0.528 (0.620)	Total loss 1.089 (1.507)
Epoch: [65][70/200]	Time 0.528 (0.617)	Total loss 1.565 (1.522)
Epoch: [65][75/200]	Time 0.515 (0.610)	Total loss 1.413 (1.517)
Epoch: [65][80/200]	Time 0.555 (0.608)	Total loss 1.391 (1.518)
Epoch: [65][85/200]	Time 0.519 (0.605)	Total loss 1.898 (1.517)
Epoch: [65][90/200]	Time 0.552 (0.601)	Total loss 1.770 (1.513)
Epoch: [65][95/200]	Time 0.504 (0.600)	Total loss 1.379 (1.511)
Epoch: [65][100/200]	Time 0.719 (0.598)	Total loss 1.428 (1.507)
Epoch: [65][105/200]	Time 0.502 (0.594)	Total loss 1.281 (1.508)
Epoch: [65][110/200]	Time 0.501 (0.603)	Total loss 1.370 (1.504)
Epoch: [65][115/200]	Time 0.583 (0.611)	Total loss 1.128 (1.498)
Epoch: [65][120/200]	Time 0.534 (0.609)	Total loss 1.563 (1.495)
Epoch: [65][125/200]	Time 0.523 (0.607)	Total loss 1.372 (1.494)
Epoch: [65][130/200]	Time 0.522 (0.604)	Total loss 1.358 (1.488)
Epoch: [65][135/200]	Time 0.553 (0.603)	Total loss 1.598 (1.490)
Epoch: [65][140/200]	Time 0.712 (0.602)	Total loss 1.687 (1.490)
Epoch: [65][145/200]	Time 0.502 (0.599)	Total loss 1.572 (1.487)
Epoch: [65][150/200]	Time 0.516 (0.597)	Total loss 1.281 (1.482)
Epoch: [65][155/200]	Time 0.547 (0.595)	Total loss 1.720 (1.480)
Epoch: [65][160/200]	Time 0.520 (0.594)	Total loss 1.894 (1.480)
Epoch: [65][165/200]	Time 0.515 (0.593)	Total loss 1.962 (1.484)
Epoch: [65][170/200]	Time 0.528 (0.590)	Total loss 1.421 (1.485)
Epoch: [65][175/200]	Time 0.521 (0.590)	Total loss 1.517 (1.484)
Epoch: [65][180/200]	Time 0.679 (0.589)	Total loss 1.551 (1.479)
Epoch: [65][185/200]	Time 0.557 (0.587)	Total loss 1.470 (1.480)
Epoch: [65][190/200]	Time 0.547 (0.586)	Total loss 1.235 (1.479)
Epoch: [65][195/200]	Time 0.515 (0.585)	Total loss 1.157 (1.477)
Epoch: [65][200/200]	Time 0.535 (0.584)	Total loss 1.473 (1.478)
Extract Features: [50/53]	Time 0.107 (0.135)	Data 0.044 (0.064)	
Mean AP: 37.2%
CMC Scores:
  top-1          39.3%
  top-5          58.7%
  top-10         68.3%

 * Finished epoch  65  model mAP: 37.2%  best: 38.2%

==> start training epoch 66 	 ==> learning rate = 3.500000000000001e-06
Epoch: [66][5/200]	Time 0.491 (0.664)	Total loss 1.385 (1.424)
Epoch: [66][10/200]	Time 0.473 (0.721)	Total loss 1.760 (1.475)
Epoch: [66][15/200]	Time 0.509 (0.650)	Total loss 1.244 (1.461)
Epoch: [66][20/200]	Time 0.519 (0.626)	Total loss 1.699 (1.464)
Epoch: [66][25/200]	Time 0.514 (0.661)	Total loss 1.895 (1.485)
Epoch: [66][30/200]	Time 0.704 (0.644)	Total loss 1.156 (1.477)
Epoch: [66][35/200]	Time 0.503 (0.628)	Total loss 1.575 (1.495)
Epoch: [66][40/200]	Time 0.527 (0.616)	Total loss 1.258 (1.466)
Epoch: [66][45/200]	Time 0.503 (0.608)	Total loss 1.563 (1.465)
Epoch: [66][50/200]	Time 0.518 (0.597)	Total loss 1.459 (1.469)
Epoch: [66][55/200]	Time 0.496 (0.595)	Total loss 1.205 (1.460)
Epoch: [66][60/200]	Time 0.532 (0.594)	Total loss 1.362 (1.472)
Epoch: [66][65/200]	Time 0.528 (0.590)	Total loss 1.614 (1.485)
Epoch: [66][70/200]	Time 0.516 (0.587)	Total loss 1.493 (1.496)
Epoch: [66][75/200]	Time 0.680 (0.585)	Total loss 1.704 (1.504)
Epoch: [66][80/200]	Time 0.510 (0.582)	Total loss 1.347 (1.494)
Epoch: [66][85/200]	Time 0.540 (0.581)	Total loss 1.757 (1.500)
Epoch: [66][90/200]	Time 0.527 (0.577)	Total loss 1.468 (1.500)
Epoch: [66][95/200]	Time 0.483 (0.575)	Total loss 1.644 (1.504)
Epoch: [66][100/200]	Time 1.859 (0.587)	Total loss 1.342 (1.507)
Epoch: [66][105/200]	Time 0.522 (0.583)	Total loss 2.066 (1.511)
Epoch: [66][110/200]	Time 0.551 (0.583)	Total loss 1.363 (1.509)
Epoch: [66][115/200]	Time 0.733 (0.595)	Total loss 1.426 (1.507)
Epoch: [66][120/200]	Time 0.517 (0.593)	Total loss 1.702 (1.509)
Epoch: [66][125/200]	Time 0.580 (0.592)	Total loss 1.312 (1.504)
Epoch: [66][130/200]	Time 0.541 (0.590)	Total loss 1.579 (1.505)
Epoch: [66][135/200]	Time 1.864 (0.599)	Total loss 1.307 (1.503)
Epoch: [66][140/200]	Time 0.506 (0.598)	Total loss 1.373 (1.502)
Epoch: [66][145/200]	Time 0.538 (0.595)	Total loss 1.661 (1.500)
Epoch: [66][150/200]	Time 0.508 (0.594)	Total loss 1.137 (1.497)
Epoch: [66][155/200]	Time 0.676 (0.593)	Total loss 1.874 (1.503)
Epoch: [66][160/200]	Time 0.512 (0.591)	Total loss 1.446 (1.500)
Epoch: [66][165/200]	Time 0.538 (0.590)	Total loss 1.435 (1.503)
Epoch: [66][170/200]	Time 0.516 (0.588)	Total loss 1.641 (1.503)
Epoch: [66][175/200]	Time 0.548 (0.587)	Total loss 1.358 (1.500)
Epoch: [66][180/200]	Time 0.516 (0.587)	Total loss 1.734 (1.501)
Epoch: [66][185/200]	Time 0.514 (0.585)	Total loss 1.795 (1.500)
Epoch: [66][190/200]	Time 0.493 (0.584)	Total loss 1.582 (1.504)
Epoch: [66][195/200]	Time 0.718 (0.590)	Total loss 1.569 (1.504)
Epoch: [66][200/200]	Time 0.515 (0.589)	Total loss 1.490 (1.504)
==> start training epoch 67 	 ==> learning rate = 3.500000000000001e-06
Epoch: [67][5/200]	Time 0.515 (1.357)	Total loss 1.375 (1.450)
Epoch: [67][10/200]	Time 0.491 (0.941)	Total loss 1.396 (1.486)
Epoch: [67][15/200]	Time 0.554 (0.815)	Total loss 1.388 (1.474)
Epoch: [67][20/200]	Time 0.559 (0.753)	Total loss 1.897 (1.514)
Epoch: [67][25/200]	Time 0.519 (0.709)	Total loss 1.292 (1.515)
Epoch: [67][30/200]	Time 0.513 (0.684)	Total loss 1.378 (1.514)
Epoch: [67][35/200]	Time 0.650 (0.667)	Total loss 1.581 (1.503)
Epoch: [67][40/200]	Time 0.538 (0.650)	Total loss 1.410 (1.508)
Epoch: [67][45/200]	Time 0.517 (0.640)	Total loss 1.613 (1.514)
Epoch: [67][50/200]	Time 0.531 (0.654)	Total loss 1.560 (1.505)
Epoch: [67][55/200]	Time 0.511 (0.646)	Total loss 1.458 (1.509)
Epoch: [67][60/200]	Time 0.516 (0.639)	Total loss 1.731 (1.504)
Epoch: [67][65/200]	Time 0.538 (0.630)	Total loss 1.679 (1.511)
Epoch: [67][70/200]	Time 0.534 (0.626)	Total loss 1.453 (1.524)
Epoch: [67][75/200]	Time 0.676 (0.621)	Total loss 1.556 (1.528)
Epoch: [67][80/200]	Time 0.536 (0.616)	Total loss 1.643 (1.525)
Epoch: [67][85/200]	Time 0.509 (0.612)	Total loss 1.395 (1.517)
Epoch: [67][90/200]	Time 0.550 (0.622)	Total loss 1.429 (1.507)
Epoch: [67][95/200]	Time 0.477 (0.617)	Total loss 1.315 (1.502)
Epoch: [67][100/200]	Time 0.495 (0.613)	Total loss 0.920 (1.494)
Epoch: [67][105/200]	Time 0.534 (0.608)	Total loss 1.896 (1.497)
Epoch: [67][110/200]	Time 0.522 (0.606)	Total loss 1.369 (1.488)
Epoch: [67][115/200]	Time 0.663 (0.603)	Total loss 1.657 (1.488)
Epoch: [67][120/200]	Time 0.489 (0.599)	Total loss 1.592 (1.494)
Epoch: [67][125/200]	Time 0.500 (0.597)	Total loss 1.799 (1.498)
Epoch: [67][130/200]	Time 0.583 (0.595)	Total loss 1.282 (1.501)
Epoch: [67][135/200]	Time 0.558 (0.593)	Total loss 2.058 (1.503)
Epoch: [67][140/200]	Time 0.559 (0.593)	Total loss 1.086 (1.499)
Epoch: [67][145/200]	Time 0.543 (0.590)	Total loss 1.902 (1.499)
Epoch: [67][150/200]	Time 0.526 (0.589)	Total loss 1.532 (1.499)
Epoch: [67][155/200]	Time 0.678 (0.588)	Total loss 1.263 (1.495)
Epoch: [67][160/200]	Time 0.521 (0.586)	Total loss 1.293 (1.499)
Epoch: [67][165/200]	Time 0.543 (0.594)	Total loss 1.401 (1.498)
Epoch: [67][170/200]	Time 0.562 (0.600)	Total loss 1.452 (1.498)
Epoch: [67][175/200]	Time 0.521 (0.600)	Total loss 1.723 (1.499)
Epoch: [67][180/200]	Time 0.493 (0.605)	Total loss 1.388 (1.498)
Epoch: [67][185/200]	Time 0.516 (0.603)	Total loss 1.324 (1.497)
Epoch: [67][190/200]	Time 0.510 (0.601)	Total loss 1.697 (1.497)
Epoch: [67][195/200]	Time 0.693 (0.600)	Total loss 1.408 (1.498)
Epoch: [67][200/200]	Time 0.503 (0.598)	Total loss 1.456 (1.497)
Extract Features: [50/53]	Time 0.066 (0.132)	Data 0.000 (0.066)	
Mean AP: 37.8%
CMC Scores:
  top-1          40.4%
  top-5          59.0%
  top-10         68.9%

 * Finished epoch  67  model mAP: 37.8%  best: 38.2%

==> start training epoch 68 	 ==> learning rate = 3.500000000000001e-06
Epoch: [68][5/200]	Time 0.525 (1.152)	Total loss 1.362 (1.322)
Epoch: [68][10/200]	Time 0.507 (0.850)	Total loss 1.273 (1.416)
Epoch: [68][15/200]	Time 0.510 (0.746)	Total loss 1.915 (1.491)
Epoch: [68][20/200]	Time 0.688 (0.697)	Total loss 1.889 (1.533)
Epoch: [68][25/200]	Time 0.532 (0.660)	Total loss 1.620 (1.523)
Epoch: [68][30/200]	Time 0.526 (0.644)	Total loss 1.169 (1.523)
Epoch: [68][35/200]	Time 0.697 (0.630)	Total loss 1.327 (1.517)
Epoch: [68][40/200]	Time 0.505 (0.617)	Total loss 1.340 (1.506)
Epoch: [68][45/200]	Time 0.513 (0.609)	Total loss 1.357 (1.526)
Epoch: [68][50/200]	Time 0.698 (0.603)	Total loss 1.256 (1.527)
Epoch: [68][55/200]	Time 0.516 (0.596)	Total loss 1.422 (1.521)
Epoch: [68][60/200]	Time 0.532 (0.593)	Total loss 1.409 (1.528)
Epoch: [68][65/200]	Time 0.534 (0.587)	Total loss 1.395 (1.521)
Epoch: [68][70/200]	Time 0.515 (0.583)	Total loss 1.723 (1.534)
Epoch: [68][75/200]	Time 0.529 (0.613)	Total loss 1.310 (1.517)
Epoch: [68][80/200]	Time 0.516 (0.607)	Total loss 1.140 (1.511)
Epoch: [68][85/200]	Time 0.500 (0.603)	Total loss 1.644 (1.521)
Epoch: [68][90/200]	Time 0.692 (0.600)	Total loss 1.790 (1.524)
Epoch: [68][95/200]	Time 0.514 (0.596)	Total loss 1.523 (1.523)
Epoch: [68][100/200]	Time 0.510 (0.594)	Total loss 1.352 (1.520)
Epoch: [68][105/200]	Time 0.497 (0.590)	Total loss 1.189 (1.515)
Epoch: [68][110/200]	Time 0.515 (0.588)	Total loss 1.687 (1.513)
Epoch: [68][115/200]	Time 0.500 (0.586)	Total loss 1.251 (1.511)
Epoch: [68][120/200]	Time 0.530 (0.584)	Total loss 1.386 (1.513)
Epoch: [68][125/200]	Time 0.509 (0.582)	Total loss 1.307 (1.511)
Epoch: [68][130/200]	Time 0.684 (0.581)	Total loss 1.582 (1.510)
Epoch: [68][135/200]	Time 0.492 (0.578)	Total loss 1.255 (1.505)
Epoch: [68][140/200]	Time 0.529 (0.577)	Total loss 1.661 (1.505)
Epoch: [68][145/200]	Time 0.506 (0.576)	Total loss 1.360 (1.511)
Epoch: [68][150/200]	Time 0.495 (0.575)	Total loss 1.457 (1.509)
Epoch: [68][155/200]	Time 0.526 (0.574)	Total loss 1.146 (1.506)
Epoch: [68][160/200]	Time 0.510 (0.572)	Total loss 1.487 (1.507)
Epoch: [68][165/200]	Time 1.778 (0.578)	Total loss 1.387 (1.507)
Epoch: [68][170/200]	Time 0.684 (0.577)	Total loss 1.435 (1.504)
Epoch: [68][175/200]	Time 0.508 (0.575)	Total loss 1.564 (1.504)
Epoch: [68][180/200]	Time 0.517 (0.574)	Total loss 1.366 (1.502)
Epoch: [68][185/200]	Time 0.538 (0.573)	Total loss 1.507 (1.499)
Epoch: [68][190/200]	Time 0.521 (0.579)	Total loss 1.478 (1.503)
Epoch: [68][195/200]	Time 0.520 (0.578)	Total loss 1.504 (1.504)
Epoch: [68][200/200]	Time 0.511 (0.577)	Total loss 1.605 (1.502)
==> start training epoch 69 	 ==> learning rate = 3.500000000000001e-06
Epoch: [69][5/200]	Time 0.504 (0.820)	Total loss 1.282 (1.459)
Epoch: [69][10/200]	Time 0.703 (0.684)	Total loss 1.291 (1.487)
Epoch: [69][15/200]	Time 0.542 (0.635)	Total loss 1.444 (1.491)
Epoch: [69][20/200]	Time 0.506 (0.613)	Total loss 1.276 (1.483)
Epoch: [69][25/200]	Time 2.065 (0.658)	Total loss 1.722 (1.489)
Epoch: [69][30/200]	Time 0.541 (0.643)	Total loss 1.479 (1.481)
Epoch: [69][35/200]	Time 0.515 (0.632)	Total loss 1.590 (1.476)
Epoch: [69][40/200]	Time 0.508 (0.618)	Total loss 1.204 (1.462)
Epoch: [69][45/200]	Time 0.530 (0.611)	Total loss 1.695 (1.467)
Epoch: [69][50/200]	Time 0.723 (0.606)	Total loss 1.622 (1.498)
Epoch: [69][55/200]	Time 0.494 (0.597)	Total loss 1.312 (1.495)
Epoch: [69][60/200]	Time 0.574 (0.615)	Total loss 1.427 (1.490)
Epoch: [69][65/200]	Time 0.544 (0.610)	Total loss 1.490 (1.484)
Epoch: [69][70/200]	Time 0.531 (0.606)	Total loss 1.248 (1.483)
Epoch: [69][75/200]	Time 0.506 (0.602)	Total loss 1.188 (1.478)
Epoch: [69][80/200]	Time 0.512 (0.597)	Total loss 1.641 (1.488)
Epoch: [69][85/200]	Time 0.521 (0.595)	Total loss 1.435 (1.492)
Epoch: [69][90/200]	Time 0.685 (0.592)	Total loss 1.845 (1.492)
Epoch: [69][95/200]	Time 0.505 (0.588)	Total loss 1.223 (1.489)
Epoch: [69][100/200]	Time 1.896 (0.601)	Total loss 1.463 (1.495)
Epoch: [69][105/200]	Time 0.532 (0.597)	Total loss 1.880 (1.502)
Epoch: [69][110/200]	Time 0.554 (0.596)	Total loss 1.600 (1.503)
Epoch: [69][115/200]	Time 0.544 (0.594)	Total loss 1.347 (1.502)
Epoch: [69][120/200]	Time 0.538 (0.591)	Total loss 1.840 (1.506)
Epoch: [69][125/200]	Time 0.542 (0.590)	Total loss 1.435 (1.504)
Epoch: [69][130/200]	Time 0.700 (0.589)	Total loss 1.531 (1.506)
Epoch: [69][135/200]	Time 0.511 (0.586)	Total loss 1.327 (1.508)
Epoch: [69][140/200]	Time 0.518 (0.586)	Total loss 1.548 (1.503)
Epoch: [69][145/200]	Time 0.487 (0.583)	Total loss 1.468 (1.498)
Epoch: [69][150/200]	Time 0.527 (0.582)	Total loss 1.352 (1.496)
Epoch: [69][155/200]	Time 0.525 (0.589)	Total loss 1.323 (1.498)
Epoch: [69][160/200]	Time 0.514 (0.587)	Total loss 1.603 (1.499)
Epoch: [69][165/200]	Time 0.525 (0.586)	Total loss 1.339 (1.496)
Epoch: [69][170/200]	Time 0.691 (0.585)	Total loss 1.352 (1.493)
Epoch: [69][175/200]	Time 0.530 (0.583)	Total loss 1.244 (1.493)
Epoch: [69][180/200]	Time 0.541 (0.583)	Total loss 1.105 (1.495)
Epoch: [69][185/200]	Time 0.530 (0.581)	Total loss 1.289 (1.496)
Epoch: [69][190/200]	Time 0.525 (0.580)	Total loss 1.437 (1.495)
Epoch: [69][195/200]	Time 0.527 (0.580)	Total loss 1.419 (1.495)
Epoch: [69][200/200]	Time 0.519 (0.578)	Total loss 1.302 (1.492)
Extract Features: [50/53]	Time 0.219 (0.132)	Data 0.142 (0.062)	
Mean AP: 37.9%
CMC Scores:
  top-1          40.0%
  top-5          59.5%
  top-10         68.8%

 * Finished epoch  69  model mAP: 37.9%  best: 38.2%

==> Test with the best model:
=> Loaded checkpoint 'logs/Released/msmt17v1+market1501+dukemtmc->cuhk03/IL_released/model_best.pth.tar'
Extract Features: [50/53]	Time 0.053 (0.134)	Data 0.000 (0.064)	
Mean AP: 38.2%
CMC Scores:
  top-1          40.7%
  top-5          59.6%
  top-10         68.6%
Total running time:  2:25:40.236646
